<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Intel® oneAPI Programming Guide</title><meta name="author" content="Intel Corporation"/><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 h2 { color: #075FA7; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 22pt; }
 .s1 { color: #075FA7; font-family:"Courier New", monospace; font-style: normal; font-weight: bold; text-decoration: none; font-size: 18pt; vertical-align: 6pt; }
 .s2 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s3 { color: black; font-family:"Courier New", monospace; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: 2pt; }
 .s4 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 26pt; }
 .s5 { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 11pt; }
 .s6 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; vertical-align: 1pt; }
 .s7 { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s8 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s9 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; vertical-align: 1pt; }
 .s11 { color: #FFF; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 52pt; }
 h1 { color: black; font-family:Calibri, sans-serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 26pt; }
 .p, p { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; margin:0pt; }
 .a, a { color: #075FA7; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s12 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7.5pt; vertical-align: 2pt; }
 h3 { color: #075FA7; font-family:Calibri, sans-serif; font-style: normal; font-weight: bold; text-decoration: underline; font-size: 18pt; }
 .s13 { color: #075FA7; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s14 { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 h4 { color: #075FA7; font-family:Calibri, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 12pt; }
 .s15 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: bold; text-decoration: none; font-size: 7.5pt; vertical-align: 2pt; }
 .s16 { color: #075FA7; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7.5pt; vertical-align: 2pt; }
 .s17 { color: #075FA7; font-family:Calibri, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 11pt; }
 .s18 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s19 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s20 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s21 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s22 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; vertical-align: 2pt; }
 .s23 { color: #075FA7; font-family:"Courier New", monospace; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9.5pt; }
 .s24 { color: black; font-family:"Courier New", monospace; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7.5pt; vertical-align: 2pt; }
 .s25 { color: #075FA7; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 .s26 { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 .s27 { color: #075FA7; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s28 { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s29 { color: #075FA7; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s30 { color: #075FA7; font-family:Calibri, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 .s31 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s32 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 9.5pt; }
 .s34 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7.5pt; vertical-align: 2pt; }
 .s35 { color: #075FA7; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7.5pt; vertical-align: 2pt; }
 .s37 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s38 { color: black; font-family:"Courier New", monospace; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7.5pt; vertical-align: 2pt; }
 .s39 { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s40 { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 8pt; }
 .s41 { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s42 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: 2pt; }
 .s43 { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: 3pt; }
 .s44 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; vertical-align: 2pt; }
 .s45 { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 .s46 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 9.5pt; }
 .s47 { color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l1 {padding-left: 0pt; }
 #l1> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l2 {padding-left: 0pt; }
 #l2> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l3 {padding-left: 0pt; }
 #l3> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l4 {padding-left: 0pt; }
 #l4> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l5 {padding-left: 0pt; }
 #l5> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l6 {padding-left: 0pt; }
 #l6> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l7 {padding-left: 0pt; }
 #l7> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l8 {padding-left: 0pt; }
 #l8> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l9 {padding-left: 0pt; }
 #l9> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l10 {padding-left: 0pt; }
 #l10> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l11 {padding-left: 0pt; }
 #l11> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l12 {padding-left: 0pt; }
 #l12> li>*:first-child:before {content: "> "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 li {display: block; }
 #l13 {padding-left: 0pt; }
 #l13> li>*:first-child:before {content: "> "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 li {display: block; }
 #l14 {padding-left: 0pt; }
 #l14> li>*:first-child:before {content: "> "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 li {display: block; }
 #l15 {padding-left: 0pt; }
 #l15> li>*:first-child:before {content: "> "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 li {display: block; }
 #l16 {padding-left: 0pt; }
 #l16> li>*:first-child:before {content: "> "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 li {display: block; }
 #l17 {padding-left: 0pt; }
 #l17> li>*:first-child:before {content: "> "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 li {display: block; }
 #l18 {padding-left: 0pt; }
 #l18> li>*:first-child:before {content: "> "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 li {display: block; }
 #l19 {padding-left: 0pt; }
 #l19> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l20 {padding-left: 0pt; }
 #l20> li>*:first-child:before {content: "> "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 li {display: block; }
 #l21 {padding-left: 0pt; }
 #l21> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l22 {padding-left: 0pt; }
 #l22> li>*:first-child:before {content: "> "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 li {display: block; }
 #l23 {padding-left: 0pt; }
 #l23> li>*:first-child:before {content: "> "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 li {display: block; }
 #l24 {padding-left: 0pt; }
 #l24> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l25 {padding-left: 0pt; }
 #l25> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l26 {padding-left: 0pt; }
 #l26> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l27 {padding-left: 0pt; }
 #l27> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l28 {padding-left: 0pt; }
 #l28> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l29 {padding-left: 0pt; }
 #l29> li>*:first-child:before {content: "> "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 li {display: block; }
 #l30 {padding-left: 0pt; }
 #l30> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l31 {padding-left: 0pt; }
 #l31> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l32 {padding-left: 0pt; }
 #l32> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l33 {padding-left: 0pt; }
 #l33> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l34 {padding-left: 0pt; }
 #l34> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l35 {padding-left: 0pt; }
 #l35> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l36 {padding-left: 0pt; }
 #l36> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l37 {padding-left: 0pt; }
 #l37> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l38 {padding-left: 0pt; }
 #l38> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l39 {padding-left: 0pt;counter-reset: s1 1; }
 #l39> li>*:first-child:before {counter-increment: s1; content: counter(s1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l39> li:first-child>*:first-child:before {counter-increment: s1 0;  }
 li {display: block; }
 #l40 {padding-left: 0pt;counter-reset: s1 4; }
 #l40> li>*:first-child:before {counter-increment: s1; content: counter(s1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l40> li:first-child>*:first-child:before {counter-increment: s1 0;  }
 li {display: block; }
 #l41 {padding-left: 0pt; }
 #l41> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l42 {padding-left: 0pt;counter-reset: u1 1; }
 #l42> li>*:first-child:before {counter-increment: u1; content: counter(u1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l42> li:first-child>*:first-child:before {counter-increment: u1 0;  }
 li {display: block; }
 #l43 {padding-left: 0pt;counter-reset: v1 1; }
 #l43> li>*:first-child:before {counter-increment: v1; content: counter(v1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l43> li:first-child>*:first-child:before {counter-increment: v1 0;  }
 li {display: block; }
 #l44 {padding-left: 0pt;counter-reset: w1 1; }
 #l44> li>*:first-child:before {counter-increment: w1; content: counter(w1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l44> li:first-child>*:first-child:before {counter-increment: w1 0;  }
 #l45 {padding-left: 0pt;counter-reset: w2 1; }
 #l45> li>*:first-child:before {counter-increment: w2; content: counter(w2, lower-latin)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l45> li:first-child>*:first-child:before {counter-increment: w2 0;  }
 li {display: block; }
 #l46 {padding-left: 0pt; }
 #l46> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l47 {padding-left: 0pt;counter-reset: y1 1; }
 #l47> li>*:first-child:before {counter-increment: y1; content: counter(y1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l47> li:first-child>*:first-child:before {counter-increment: y1 0;  }
 #l48 {padding-left: 0pt; }
 #l48> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l49 {padding-left: 0pt; }
 #l49> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l50 {padding-left: 0pt;counter-reset: z1 1; }
 #l50> li>*:first-child:before {counter-increment: z1; content: counter(z1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l50> li:first-child>*:first-child:before {counter-increment: z1 0;  }
 li {display: block; }
 #l51 {padding-left: 0pt;counter-reset: z1 3; }
 #l51> li>*:first-child:before {counter-increment: z1; content: counter(z1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l51> li:first-child>*:first-child:before {counter-increment: z1 0;  }
 li {display: block; }
 #l52 {padding-left: 0pt; }
 #l52> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l53 {padding-left: 0pt; }
 #l53> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; }
 li {display: block; }
 #l54 {padding-left: 0pt; }
 #l54> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 li {display: block; }
 #l55 {padding-left: 0pt; }
 #l55> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l56 {padding-left: 0pt; }
 #l56> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; }
 li {display: block; }
 #l57 {padding-left: 0pt; }
 #l57> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l58 {padding-left: 0pt; }
 #l58> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l59 {padding-left: 0pt;counter-reset: f1 1; }
 #l59> li>*:first-child:before {counter-increment: f1; content: counter(f1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l59> li:first-child>*:first-child:before {counter-increment: f1 0;  }
 #l60 {padding-left: 0pt; }
 #l60> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l61 {padding-left: 0pt;counter-reset: f1 4; }
 #l61> li>*:first-child:before {counter-increment: f1; content: counter(f1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l61> li:first-child>*:first-child:before {counter-increment: f1 0;  }
 li {display: block; }
 #l62 {padding-left: 0pt; }
 #l62> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l63 {padding-left: 0pt; }
 #l63> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l64 {padding-left: 0pt; }
 #l64> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l65 {padding-left: 0pt; }
 #l65> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l66 {padding-left: 0pt; }
 #l66> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l67 {padding-left: 0pt; }
 #l67> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l68 {padding-left: 0pt; }
 #l68> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l69 {padding-left: 0pt; }
 #l69> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l70 {padding-left: 0pt; }
 #l70> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l71 {padding-left: 0pt; }
 #l71> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l72 {padding-left: 0pt; }
 #l72> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l73 {padding-left: 0pt;counter-reset: m1 1; }
 #l73> li>*:first-child:before {counter-increment: m1; content: counter(m1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l73> li:first-child>*:first-child:before {counter-increment: m1 0;  }
 li {display: block; }
 #l74 {padding-left: 0pt;counter-reset: m1 3; }
 #l74> li>*:first-child:before {counter-increment: m1; content: counter(m1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l74> li:first-child>*:first-child:before {counter-increment: m1 0;  }
 li {display: block; }
 #l75 {padding-left: 0pt; }
 #l75> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l76 {padding-left: 0pt; }
 #l76> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l77 {padding-left: 0pt;counter-reset: o1 1; }
 #l77> li>*:first-child:before {counter-increment: o1; content: counter(o1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l77> li:first-child>*:first-child:before {counter-increment: o1 0;  }
 #l78 {padding-left: 0pt; }
 #l78> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l79 {padding-left: 0pt; }
 #l79> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l80 {padding-left: 0pt; }
 #l80> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; vertical-align: 1pt; }
 li {display: block; }
 #l81 {padding-left: 0pt; }
 #l81> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; vertical-align: 1pt; }
 #l82 {padding-left: 0pt; }
 #l82> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l83 {padding-left: 0pt; }
 #l83> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 li {display: block; }
 #l84 {padding-left: 0pt; }
 #l84> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l85 {padding-left: 0pt; }
 #l85> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 li {display: block; }
 #l86 {padding-left: 0pt; }
 #l86> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l87 {padding-left: 0pt; }
 #l87> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 li {display: block; }
 #l88 {padding-left: 0pt; }
 #l88> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 li {display: block; }
 #l89 {padding-left: 0pt; }
 #l89> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l90 {padding-left: 0pt; }
 #l90> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l91 {padding-left: 0pt; }
 #l91> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l92 {padding-left: 0pt;counter-reset: v1 2; }
 #l92> li>*:first-child:before {counter-increment: v1; content: counter(v1, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l92> li:first-child>*:first-child:before {counter-increment: v1 0;  }
 #l93 {padding-left: 0pt;counter-reset: v2 1; }
 #l93> li>*:first-child:before {counter-increment: v2; content: counter(v1, decimal)"."counter(v2, decimal)" "; color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8.5pt; }
 #l93> li:first-child>*:first-child:before {counter-increment: v2 0;  }
 li {display: block; }
 #l94 {padding-left: 0pt; }
 #l94> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l95 {padding-left: 0pt;counter-reset: x1 1; }
 #l95> li>*:first-child:before {counter-increment: x1; content: counter(x1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l95> li:first-child>*:first-child:before {counter-increment: x1 0;  }
 li {display: block; }
 #l96 {padding-left: 0pt;counter-reset: x1 2; }
 #l96> li>*:first-child:before {counter-increment: x1; content: counter(x1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l96> li:first-child>*:first-child:before {counter-increment: x1 0;  }
 #l97 {padding-left: 0pt; }
 #l97> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l98 {padding-left: 0pt; }
 #l98> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l99 {padding-left: 0pt; }
 #l99> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l100 {padding-left: 0pt; }
 #l100> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l101 {padding-left: 0pt; }
 #l101> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l102 {padding-left: 0pt; }
 #l102> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l103 {padding-left: 0pt; }
 #l103> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l104 {padding-left: 0pt; }
 #l104> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l105 {padding-left: 0pt;counter-reset: d1 1; }
 #l105> li>*:first-child:before {counter-increment: d1; content: counter(d1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l105> li:first-child>*:first-child:before {counter-increment: d1 0;  }
 #l106 {padding-left: 0pt; }
 #l106> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l107 {padding-left: 0pt; }
 #l107> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l108 {padding-left: 0pt;counter-reset: e1 1; }
 #l108> li>*:first-child:before {counter-increment: e1; content: counter(e1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l108> li:first-child>*:first-child:before {counter-increment: e1 0;  }
 li {display: block; }
 #l109 {padding-left: 0pt;counter-reset: f1 1; }
 #l109> li>*:first-child:before {counter-increment: f1; content: counter(f1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l109> li:first-child>*:first-child:before {counter-increment: f1 0;  }
 li {display: block; }
 #l110 {padding-left: 0pt;counter-reset: g1 1; }
 #l110> li>*:first-child:before {counter-increment: g1; content: counter(g1, decimal)". "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 #l110> li:first-child>*:first-child:before {counter-increment: g1 0;  }
 #l111 {padding-left: 0pt; }
 #l111> li>*:first-child:before {content: "• "; color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 table, tbody {vertical-align: top; overflow: visible; }
</style></head><body><h2 style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Intel<span class="s1">® </span>oneAPI Programming Guide</h2><p class="s2" style="padding-top: 4pt;padding-bottom: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Intel<span class="s3">® </span>oneAPI Programming Guide</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s4" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark0">&zwnj;</a>Contents</p><p style="padding-top: 28pt;padding-left: 63pt;text-indent: 0pt;text-align: left;"><a href="#bookmark84" class="s5">Chapter 1: Intel</a><a href="#bookmark84" class="s6">® </a><a href="#bookmark84" class="s5">oneAPI Programming Guide</a></p><p style="padding-left: 93pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark85" class="s7">Introduction to oneAPI Programming</a><a href="#bookmark85" class="s8">                            </a><a href="#bookmark85" class="s7">4</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark86" class="s7">Intel oneAPI Programming Overview</a><a href="#bookmark86" class="s8">                        </a><a href="#bookmark86" class="s7">5</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark87" class="s7">Intel</a><a href="#bookmark87" class="s9">® </a><a href="#bookmark87" class="s7">oneAPI Toolkit Distribution</a><a href="#bookmark87" class="s8">                          </a><a href="#bookmark87" class="s7">7</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark89" class="s7">Related Documentation</a><a href="#bookmark89" class="s8">                                </a><a href="#bookmark89" class="s7">7</a></p><p style="padding-left: 93pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark90" class="s7">oneAPI Programming Model</a><a href="#bookmark90" class="s8">                                 </a><a href="#bookmark90" class="s7">7</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark92" class="s7">Data Parallelism in C++ Using SYCL*</a><a href="#bookmark92" class="s8">                       </a><a href="#bookmark92" class="s7">8</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark93" class="s7">C/C++ or Fortran with OpenMP* Offload Programming Model</a><a href="#bookmark93" class="s8">       </a><a href="#bookmark93" class="s7">10</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark94" class="s7">Device Selection</a><a href="#bookmark94" class="s8">                                    </a><a href="#bookmark94" class="s7">13</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark95" class="s7">SYCL* Execution and Memory Hierarchy</a><a href="#bookmark95" class="s8">                     </a><a href="#bookmark95" class="s7">15</a></p><p style="padding-left: 93pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark96" class="s7">oneAPI Development Environment Setup</a><a href="#bookmark96" class="s8">                        </a><a href="#bookmark96" class="s7">17</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark97" class="s7">Use the setvars and oneapi-vars Scripts with Windows*</a><a href="#bookmark97" class="s8">           </a><a href="#bookmark97" class="s7">19</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark99" class="s7">Use a Config File for setvars.bat on Windows*</a><a href="#bookmark99" class="s8">             </a><a href="#bookmark99" class="s7">24</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark100" class="s7">Automate the setvars.bat Script with Microsoft Visual Studio*</a><a href="#bookmark100" class="s8">   </a><a href="#bookmark100" class="s7">28</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark102" class="s7">Use the setvars and oneapi-vars Scripts with Linux*</a><a href="#bookmark102" class="s8">             </a><a href="#bookmark102" class="s7">29</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark103" class="s7">Use a Config File for setvars.sh on Linux</a><a href="#bookmark103" class="s8">                 </a><a href="#bookmark103" class="s7">34</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark105" class="s7">Automate the setvars.sh Script with Eclipse*</a><a href="#bookmark105" class="s8">              </a><a href="#bookmark105" class="s7">38</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark106" class="s7">Use Environment Modulefiles with Linux*</a><a href="#bookmark106" class="s8">                    </a><a href="#bookmark106" class="s7">39</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark107" class="s7">Use CMake with oneAPI Applications</a><a href="#bookmark107" class="s8">                       </a><a href="#bookmark107" class="s7">45</a></p><p style="padding-left: 93pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark108" class="s7">Compile and Run oneAPI Programs</a><a href="#bookmark108" class="s8">                            </a><a href="#bookmark108" class="s7">46</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark110" class="s7">Single-Source Compilation</a><a href="#bookmark110" class="s8">                              </a><a href="#bookmark110" class="s7">46</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark111" class="s7">Invoke the Compiler</a><a href="#bookmark111" class="s8">                                  </a><a href="#bookmark111" class="s7">47</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark112" class="s7">Standard Intel</a><a href="#bookmark112" class="s9">® </a><a href="#bookmark112" class="s7">oneAPI DPC++/C++ Compiler Options</a><a href="#bookmark112" class="s8">           </a><a href="#bookmark112" class="s7">47</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark113" class="s7">Example Compilation</a><a href="#bookmark113" class="s8">                                 </a><a href="#bookmark113" class="s7">48</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark114" class="s7">Compilation Flow Overview</a><a href="#bookmark114" class="s8">                             </a><a href="#bookmark114" class="s7">50</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark115" class="s7">CPU Flow</a><a href="#bookmark115" class="s8">                                         </a><a href="#bookmark115" class="s7">55</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark116" class="s7">Traditional CPU Flow</a><a href="#bookmark116" class="s8">                             </a><a href="#bookmark116" class="s7">55</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark117" class="s7">CPU Offload Flow</a><a href="#bookmark117" class="s8">                                </a><a href="#bookmark117" class="s7">55</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark121" class="s7">GPU Flow</a><a href="#bookmark121" class="s8">                                         </a><a href="#bookmark121" class="s7">63</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark122" class="s7">GPU Offload Flow</a><a href="#bookmark122" class="s8">                                </a><a href="#bookmark122" class="s7">64</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark123" class="s7">Example GPU Commands</a><a href="#bookmark123" class="s8">                          </a><a href="#bookmark123" class="s7">69</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark124" class="s7">Ahead-of-Time Compilation for GPU</a><a href="#bookmark124" class="s8">                    </a><a href="#bookmark124" class="s7">70</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark125" class="s7">FPGA Flow</a><a href="#bookmark125" class="s8">                                        </a><a href="#bookmark125" class="s7">70</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark126" class="s7">Why is FPGA Compilation Different?</a><a href="#bookmark126" class="s8">                    </a><a href="#bookmark126" class="s7">70</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark127" class="s7">Types of SYCL* FPGA Compilation</a><a href="#bookmark127" class="s8">                     </a><a href="#bookmark127" class="s7">71</a></p><p style="padding-left: 93pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark128" class="s7">API-Based Programming</a><a href="#bookmark128" class="s8">                                   </a><a href="#bookmark128" class="s7">74</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark129" class="s7">Intel</a><a href="#bookmark129" class="s9">® </a><a href="#bookmark129" class="s7">oneAPI DPC++ Library (oneDPL)</a><a href="#bookmark129" class="s8">                     </a><a href="#bookmark129" class="s7">75</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark131" class="s7">oneDPL Library Usage</a><a href="#bookmark131" class="s8">                             </a><a href="#bookmark131" class="s7">75</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark132" class="s7">oneDPL Code Samples</a><a href="#bookmark132" class="s8">                            </a><a href="#bookmark132" class="s7">75</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark133" class="s7">Intel</a><a href="#bookmark133" class="s9">® </a><a href="#bookmark133" class="s7">oneAPI Math Kernel Library (oneMKL)</a><a href="#bookmark133" class="s8">                  </a><a href="#bookmark133" class="s7">76</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark134" class="s7">oneMKL Usage</a><a href="#bookmark134" class="s8">                                 </a><a href="#bookmark134" class="s7">77</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark135" class="s7">oneMKL Code Sample</a><a href="#bookmark135" class="s8">                             </a><a href="#bookmark135" class="s7">77</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark136" class="s7">Intel</a><a href="#bookmark136" class="s9">® </a><a href="#bookmark136" class="s7">oneAPI Threading Building Blocks (oneTBB)</a><a href="#bookmark136" class="s8">              </a><a href="#bookmark136" class="s7">81</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark137" class="s7">oneTBB Usage</a><a href="#bookmark137" class="s8">                                  </a><a href="#bookmark137" class="s7">81</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark138" class="s7">oneTBB Code Sample</a><a href="#bookmark138" class="s8">                             </a><a href="#bookmark138" class="s7">81</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark139" class="s7">Intel</a><a href="#bookmark139" class="s9">® </a><a href="#bookmark139" class="s7">oneAPI Data Analytics Library (oneDAL)</a><a href="#bookmark139" class="s8">                 </a><a href="#bookmark139" class="s7">82</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark140" class="s7">oneDAL Usage</a><a href="#bookmark140" class="s8">                                 </a><a href="#bookmark140" class="s7">82</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark141" class="s7">oneDAL Code Sample</a><a href="#bookmark141" class="s8">                             </a><a href="#bookmark141" class="s7">83</a></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="padding-top: 38pt;padding-left: 123pt;text-indent: 0pt;text-align: left;"><a href="#bookmark142" class="s7">Intel</a><a href="#bookmark142" class="s9">® </a><a href="#bookmark142" class="s7">oneAPI Collective Communications Library (oneCCL)</a><a href="#bookmark142" class="s8">         </a><a href="#bookmark142" class="s7">83</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark144" class="s7">oneCCL Usage</a><a href="#bookmark144" class="s8">                                  </a><a href="#bookmark144" class="s7">83</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark145" class="s7">oneCCL Code Sample</a><a href="#bookmark145" class="s8">                             </a><a href="#bookmark145" class="s7">84</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark146" class="s7">Intel</a><a href="#bookmark146" class="s9">® </a><a href="#bookmark146" class="s7">oneAPI Deep Neural Network Library (oneDNN)</a><a href="#bookmark146" class="s8">            </a><a href="#bookmark146" class="s7">84</a></p><p style="padding-left: 153pt;text-indent: 0pt;text-align: left;"><a href="#bookmark147" class="s7">Intel</a><a href="#bookmark147" class="s9">® </a><a href="#bookmark147" class="s7">oneAPI Deep Neural Network Library (oneDNN) Usage</a><a href="#bookmark147" class="s8">    </a><a href="#bookmark147" class="s7">84</a></p><p style="padding-left: 167pt;text-indent: -14pt;text-align: left;"><a href="#bookmark148" class="s7">Intel</a><a href="#bookmark148" class="s9">® </a><a href="#bookmark148" class="s7">oneAPI Deep Neural Network Library (oneDNN) Code  Sample</a><a href="#bookmark148" class="s8">                                    </a><a href="#bookmark148" class="s7">86</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark149" class="s7">Other Libraries</a><a href="#bookmark149" class="s8">                                     </a><a href="#bookmark149" class="s7">86</a></p><p style="padding-left: 93pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark150" class="s7">Software Development Process</a><a href="#bookmark150" class="s8">                              </a><a href="#bookmark150" class="s7">87</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark151" class="s7">Migrating Code to SYCL* and DPC++</a><a href="#bookmark151" class="s8">                       </a><a href="#bookmark151" class="s7">87</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark152" class="s7">Migrating from C++ to SYCL*</a><a href="#bookmark152" class="s8">                        </a><a href="#bookmark152" class="s7">87</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark153" class="s7">Migrating from CUDA* to SYCL* for the oneAPI DPC++ Compiler</a><a href="#bookmark153" class="s8">  </a><a href="#bookmark153" class="s7">88</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark154" class="s7">Migrating from OpenCL Code to SYCL*</a><a href="#bookmark154" class="s8">                  </a><a href="#bookmark154" class="s7">88</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark155" class="s7">Migrating Between CPU, GPU, and FPGA</a><a href="#bookmark155" class="s8">                 </a><a href="#bookmark155" class="s7">89</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark156" class="s7">Composability</a><a href="#bookmark156" class="s8">                                      </a><a href="#bookmark156" class="s7">91</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark157" class="s7">C/C++ OpenMP* and SYCL* Composability</a><a href="#bookmark157" class="s8">               </a><a href="#bookmark157" class="s7">91</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark158" class="s7">OpenCL</a><a href="#bookmark158" class="s9">™ </a><a href="#bookmark158" class="s7">Code Interoperability</a><a href="#bookmark158" class="s8">                       </a><a href="#bookmark158" class="s7">93</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark159" class="s7">Debugging the DPC++ and OpenMP* Offload Process</a><a href="#bookmark159" class="s8">            </a><a href="#bookmark159" class="s7">93</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark160" class="s7">oneAPI Debug Tools for SYCL* and OpenMP* Development</a><a href="#bookmark160" class="s8">     </a><a href="#bookmark160" class="s7">94</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark161" class="s7">Trace the Offload Process</a><a href="#bookmark161" class="s8">                          </a><a href="#bookmark161" class="s7">104</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark162" class="s7">Debug the Offload Process</a><a href="#bookmark162" class="s8">                         </a><a href="#bookmark162" class="s7">106</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark163" class="s7">Optimize Offload Performance</a><a href="#bookmark163" class="s8">                       </a><a href="#bookmark163" class="s7">120</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark164" class="s7">Performance Tuning Cycle</a><a href="#bookmark164" class="s8">                             </a><a href="#bookmark164" class="s7">122</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark165" class="s7">Establish Baseline</a><a href="#bookmark165" class="s8">                              </a><a href="#bookmark165" class="s7">123</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark166" class="s7">Identify Kernels to Offload</a><a href="#bookmark166" class="s8">                         </a><a href="#bookmark166" class="s7">123</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark167" class="s7">Offload Kernels</a><a href="#bookmark167" class="s8">                                </a><a href="#bookmark167" class="s7">123</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark168" class="s7">Optimize Your SYCL* Applications</a><a href="#bookmark168" class="s8">                    </a><a href="#bookmark168" class="s7">123</a></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark169" class="s7">Recompile, Run, Profile, and Repeat</a><a href="#bookmark169" class="s8">                   </a><a href="#bookmark169" class="s7">125</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark170" class="s7">oneAPI Library Compatibility</a><a href="#bookmark170" class="s8">                           </a><a href="#bookmark170" class="s7">125</a></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark171" class="s7">SYCL* Extensions</a><a href="#bookmark171" class="s8">                                  </a><a href="#bookmark171" class="s7">126</a></p><p style="padding-left: 93pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark172" class="s7">Glossary</a><a href="#bookmark172" class="s8">                                            </a><a href="#bookmark172" class="s7">126</a></p><p style="padding-left: 93pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><a href="#bookmark177" class="s7">Notices and Disclaimers.</a><a href="#bookmark177" class="s8">                                  </a><a href="#bookmark177" class="s7">128</a></p><div class="textbox" style="background:#000000;display:block;min-height:67.4pt;width:89.8pt;"><p class="s11" style="padding-left: 26pt;text-indent: 0pt;line-height: 62pt;text-align: left;">1</p></div><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span/></p><h1 style="padding-top: 28pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark1">&zwnj;</a>Intel® oneAPI Programming Guide<a name="bookmark84">&zwnj;</a></h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Use this guide to learn about:</p><ul id="l1"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><span style=" color: #075FA7;">Introduction to oneAPI Programming</span>: A basic overview of oneAPI, Intel<span class="s12">® </span>oneAPI Toolkits, and related resources.</p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;text-align: left;">oneAPI Programming Model<span style=" color: #000;">: An introduction to the oneAPI programming model for SYCL* and OpenMP* offload for C, C++, and Fortran.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;text-align: left;">oneAPI Development Environment Setup<span style=" color: #000;">: Instructions on how to set up the oneAPI application development environment.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Compile and Run oneAPI Programs<span style=" color: #000;">: Details about how to compile code for various accelerators (CPU, FPGA, etc.).</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;text-align: left;">API-Based Programming<span style=" color: #000;">: A brief introduction to common APIs and related libraries as well as details on buffer usage.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Software Development Process<span style=" color: #000;">: An overview of the software development process using various oneAPI tools, such as debuggers and performance analyzers, and optimizing code for a specific accelerator (CPU, FPGA, etc.).</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark2">&zwnj;</a>Introduction &nbsp;&nbsp;&nbsp; to &nbsp;&nbsp;&nbsp; oneAPI &nbsp;&nbsp;&nbsp; Programming &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a name="bookmark85">&zwnj;</a></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Obtaining high compute performance on today’s modern computer architectures requires code that is optimized, power-efficient, and scalable. The demand for high performance continues to increase due to needs in AI, video analytics, data analytics, and in traditional high-performance computing (HPC).</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Central Processing Units (CPUs) and Graphics Processing Units (GPUs) are fundamental computing engines. But as computing demands evolve, it is not always clear what the differences are between CPUs and GPUs and which workloads are best suited to each.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="#bookmark173" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Modern workload diversity has resulted in a need for architectural diversity; no single architecture is best for every workload. A mix of scalar, vector, matrix, and spatial (SVMS) architectures deployed in CPU, GPU, AI, and FPGA </a>accelerators <span style=" color: #000;">is required to extract the needed performance.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Today, coding for CPUs and accelerators (such as GPUs) requires different languages, libraries, and tools. That means each hardware platform requires separate software investments and provides limited application code reusability across different target architectures.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The oneAPI programming model simplifies the programming of CPUs and accelerators using modern C++ features to express parallelism using SYCL*. SYCL enables code reuse for the host (such as a CPU) and accelerators (such as a GPU) using a single source language, with execution and memory dependencies</p><p style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">clearly communicated. Mapping within the SYCL code can be used to transition the application to run on the hardware, or set of hardware, that best accelerates the workload. A host is available to simplify development and debugging of device code, even on platforms that do not have an accelerator available.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">oneAPI also supports programming on CPUs and accelerators using the OpenMP* offload feature with existing C/C++ or Fortran code.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/products/docs/processors/cpu-vs-gpu.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For more information on determining whether or not to use a CPU or GPU, see </a><a href="https://www.intel.com/content/www/us/en/products/docs/processors/cpu-vs-gpu.html" class="a" target="_blank">CPU vs. GPU: Making the Most </a>of Both<span style=" color: #000;">.</span></p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi/optimization-guide-gpu/2025-0/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Once you have gained an understanding of the oneAPI programming model, see the </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi/optimization-guide-gpu/2025-0/" class="a" target="_blank">oneAPI GPU </a>Optimization Guide <span style=" color: #000;">for information on how to optimize your software.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">Not all programs can benefit from the single programming model offered by oneAPI. It is important to understand how to design, implement, and use the oneAPI programming model for your program.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.oneapi.com/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Learn more about the oneAPI initiative and programming model at </a>oneapi.com<span style=" color: #000;">. The site includes the oneAPI Specification, SYCL Language Guide and API Reference, and other resources.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark3">&zwnj;</a>Intel oneAPI Programming Overview<a name="bookmark86">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The oneAPI programming model provides a comprehensive and unified portfolio of developer tools that can be used across hardware targets, including a range of performance libraries spanning several workload domains. The libraries include functions custom-coded for each target architecture, so the same function call delivers optimized performance across supported architectures.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The oneAPI programming model</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">As shown in the figure above, applications that take advantage of the oneAPI programming model can run on multiple target hardware platforms ranging from CPU to FPGA. Intel offers oneAPI products as part of a set of toolkits. The Intel<span class="s12">® </span>oneAPI Base Toolkit, Intel<span class="s12">® </span>HPC Toolkit, and several other toolkits feature complementary tools based on specific developer workload needs. For example, the Intel oneAPI Base Toolkit includes the Intel<span class="s12">® </span>oneAPI DPC++/C++ Compiler, the Intel<span class="s12">® </span>DPC++ Compatibility Tool, select libraries, and analysis tools.</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Developers who want to migrate existing CUDA* code to SYCL* for compilation with the Intel<span class="s12">® </span>oneAPI DPC++ Compiler can use the <b>Intel</b><span class="s15">® </span><b>DPC++ Compatibility Tool </b>to help migrate their existing projects to SYCL* using DPC++.</p></li><li data-list-text="•"><p class="s14" style="padding-left: 19pt;text-indent: -14pt;text-align: left;"><span class="p">The </span>Intel<span class="s15">® </span>oneAPI DPC++/C++ Compiler <span class="p">supports direct programming of code targeting accelerators. Direct programming is coding for performance when APIs are not available for the algorithms expressed in user code. It supports online and offline compilation for CPU and GPU targets and offline compilation for FPGA targets.</span></p></li><li data-list-text="•"><p class="s14" style="padding-left: 19pt;text-indent: -14pt;text-align: left;"><span class="p">API-based programming is supported via sets of optimized libraries. The library functions provided in the oneAPI product are pre-tuned for use with any supported target architecture, eliminating the need for developer intervention. For example, the BLAS routine available from </span>Intel<span class="s15">® </span>oneAPI Math Kernel Library <span class="p">is just as optimized for a GPU target as a CPU target.</span></p></li><li data-list-text="•"><p class="s14" style="padding-left: 19pt;text-indent: -14pt;text-align: left;"><span class="p">Finally, the compiled SYCL application can be analyzed and debugged to ensure performance, stability, and energy efficiency goals are achieved using tools such as </span>Intel<span class="s15">® </span>VTune<span class="s15">™ </span>Profiler <span class="p">or </span>Intel<span class="s15">® </span>Advisor<span class="p">.</span></p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The Intel oneAPI Base Toolkit is available as a free download from the </a>Intel Developer Zone<span style=" color: #000;">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Users familiar with Intel<span class="s12">® </span>Parallel Studio and Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/hpc-toolkit.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">System Studio may be interested in the </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/hpc-toolkit.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/hpc-toolkit.html" class="s16" target="_blank">® </a><span style=" color: #075FA7;">HPC Toolkit</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark4">&zwnj;</a>Intel® oneAPI Toolkit Distribution<a name="bookmark87">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark88">&zwnj;</a>oneAPI Toolkits are available via multiple distribution channels:</p></li><li data-list-text="•"><p class="s13" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/toolkits.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Local product installation: install the oneAPI toolkits from the </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/toolkits.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/toolkits.html" class="s16" target="_blank">® </a>Developer Zone<a href="https://www.intel.com/content/www/us/en/developer/articles/guide/installation-guide-for-oneapi-toolkits.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">. Refer to the </a>Installation Guides <span style=" color: #000;">for specific install information.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/articles/guide/installation-guide-for-oneapi-toolkits.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Install from containers or repositories: install the oneAPI toolkits from one of several supported containers or repositories. Instructions for each are available from the </a>Installation Guides<span style=" color: #000;">.</span></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Pre-installed in the Intel<span class="s12">® </span><a href="https://devcloud.intel.com/oneapi/get_started/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">DevCloud: use a free development sandbox for access to the latest Intel hardware and select oneAPI tools. </a><a href="https://devcloud.intel.com/oneapi/get_started/" target="_blank">Learn more about Intel DevCloud and sign up for free access.</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark5">&zwnj;</a>Related Documentation<a name="bookmark89">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The following documents are useful starting points for developers getting started with oneAPI projects.</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Get started guides for select Intel<span class="s12">® </span>oneAPI toolkits:</p><ul id="l2"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">Get Started with Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-base-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI Base Toolkit for </a><span style=" color: #075FA7;">Linux* </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-base-windows/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">| </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-base-windows/top.html" target="_blank">Windows*</a></p></li><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;text-align: left;">Get Started with Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-hpc-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">HPC Toolkit for </a><span style=" color: #075FA7;">Linux* </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-hpc-windows/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">| </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-hpc-windows/top.html" target="_blank">Windows*</a></p></li></ul></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Release notes for select Intel<span class="s12">® </span>oneAPI toolkits:</p><ul id="l3"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 34pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/articles/intel-oneapi-toolkit-release-notes.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/develop/articles/intel-oneapi-toolkit-release-notes.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/develop/articles/intel-oneapi-toolkit-release-notes.html" target="_blank">oneAPI Base Toolkit</a></p></li><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/articles/intel-oneapi-hpc-toolkit-release-notes.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/develop/articles/intel-oneapi-hpc-toolkit-release-notes.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/develop/articles/intel-oneapi-hpc-toolkit-release-notes.html" target="_blank">HPC Toolkit</a></p></li></ul></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Language reference material:</p><ul id="l4"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 34pt;text-indent: -14pt;text-align: left;"><a href="https://github.khronos.org/SYCL_Reference/">Khronos SYCL Reference</a></p></li><li data-list-text="•"><p class="s13" style="padding-left: 34pt;text-indent: -14pt;text-align: left;"><a href="https://www.khronos.org/registry/SYCL/specs/sycl-1.2.1.pdf" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">SYCL* Specification (PDF) </a>1.2.1 <a href="https://www.khronos.org/registry/SYCL/specs/sycl-2020/pdf/sycl-2020.pdf" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">| </a><a href="https://www.khronos.org/registry/SYCL/specs/sycl-2020/pdf/sycl-2020.pdf" target="_blank">2020</a></p></li><li data-list-text="•"><p class="s13" style="padding-left: 34pt;text-indent: -14pt;text-align: left;"><a href="https://link.springer.com/book/10.1007%2F978-1-4842-5574-2" class="a" target="_blank">Data Parallel C++: Mastering DPC++ for Programming of Heterogeneous Systems using C++ and </a>SYCL <a href="https://creativecommons.org/licenses/by/4.0/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">(book by James Reinders, Ben Ashbaugh, James Broadman, Michael Kinsner, John Pennycook, and Xinmin Tian, parts of this book were reused under the </a>Creative Commons license<span style=" color: #000;">.)</span></p></li><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;text-align: left;"><a href="https://openmp.llvm.org/docs/design/Runtimes.html">LLVM/OpenMP* Documentation</a></p></li><li data-list-text="•"><p class="s13" style="padding-left: 34pt;text-indent: -14pt;text-align: left;">OpenMP* Specifications <span style=" color: #000;">(examples documents recommended)</span></p></li></ul></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark6">&zwnj;</a>oneAPI &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Programming &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Model &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a name="bookmark90">&zwnj;</a></h3><p style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="#bookmark175" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">In heterogenous computing, the </a>host <a href="#bookmark174" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">processor takes advantage of accelerator </a>devices <span style=" color: #000;">to execute code more efficiently.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The oneAPI programming model supports two important portable methods of heterogenous computing: Data Parallel C++ with SYCL* and OpenMP* for C, C++, and Fortran.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">SYCL is a cross-platform abstraction layer that enables code for heterogeneous processors to be written using standard ISO C++ with the host and kernel code for an application contained in the same source file. The DPC++ open source project is adding SYCL support to the LLVM C++ compiler. The Intel<span class="s12">® </span>oneAPI DPC+</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">+/C++ Compiler is available as part of the Intel<span class="s12">® </span>oneAPI Base Toolkit.</p><p style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark91">&zwnj;</a>SYCL Kernel Compatibility</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">In accordance with the SYCL 2020 specification, DPC++ will detect uses of optional kernel features in SYCL kernels. A kernel is only considered compatible with a device if that device reports true in <span class="s18">device::has() </span>for all aspects required by the kernel. Effectively, this means that a <span class="s18">kernel_bundle </span>created with a given device will not contain kernels that have requirements that the device does not support and attempting to launch kernels on a device that they are not compatible with will result in a <span class="s18">sycl::exception </span>being thrown.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">As determining the origin of a requirement in a kernel can be difficult, the user can add the <span class="s18">sycl::device_has </span>attribute to the kernels. The compiler will warn the user of any aspect requirements deduced for the kernel that do not appear in the kernel’s <span class="s18">sycl::device_has </span>attribute. Note that this behavior is required by the SYCL 2020 specification.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">OpenMP*</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">OpenMP has been a standard programming language for over 20 years, and Intel implements version 5 of the OpenMP standard. The Intel oneAPI DPC++/C++ Compiler with OpenMP offload support is available as part of the Intel oneAPI Base Toolkit, and Intel<span class="s12">® </span>HPC Toolkit. The Intel<span class="s12">® </span>Fortran Compiler Classic and Intel<span class="s12">® </span>Fortran Compiler with OpenMP offload support is available as part of the Intel<span class="s12">® </span>HPC Toolkit.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 1pt;padding-bottom: 3pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">OpenMP is not supported for FPGA devices.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The next sections briefly describe each language and provide pointers to more information.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark7">&zwnj;</a>Data Parallelism in C++ Using SYCL*<a name="bookmark92">&zwnj;</a></h4><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Open, multivendor, multiarchitecture support for productive data parallel programming in C++ is accomplished via standard C++ with support for SYCL. SYCL (pronounced ‘sickle’) is a royalty-free, cross- platform abstraction layer that enables code for heterogeneous processors to be written using standard ISO C++ with the host and kernel code for an application contained in the same source file. The DPC++ open- source project is adding SYCL support to the LLVM C++ compiler.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Simple Sample Code Using Queue Lambda by Reference</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The best way to introduce SYCL is through an example. Since SYCL is based on modern C++, this example uses several features that have been added to C++ in recent years, such as lambda functions and uniform initialization. Even if developers are not familiar with these features, their semantics will become clear from the context of the example. After gaining some experience with SYCL, these newer C++ features will become second nature.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The following application sets each element of an array to the value of its index, so that a[0] = 0, a[1] = 1, etc.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:235.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#include &lt;CL/sycl.hpp&gt; #include &lt;iostream&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">constexpr int num=16; using namespace sycl;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">int main() {</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">auto r = range{num}; buffer&lt;int&gt; a{r};</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: -10pt;text-align: left;">queue{}.submit([&amp;](handler&amp; h) { accessor out{a, h}; h.parallel_for(r, [=](item&lt;1&gt; idx) {</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">out[idx] = idx;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">});</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">host_accessor result{a}; for (int i=0; i&lt;num; ++i)</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; result[i] &lt;&lt; &quot;\n&quot;;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;"><a href="#bookmark176" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">The first thing to notice is that there is just one source file: both the host code and the offloaded accelerator code are combined in a </a><span style=" color: #075FA7;">single source </span>file. The second thing to notice is that the syntax is standard C++: there aren’t any new keywords or pragmas used to express the parallelism. Instead, the parallelism is expressed through C++ classes. For example, the <span class="s18">buffer </span>class on line 9 represents data that will be offloaded to the device, and the <span class="s18">queue </span>class on line 11 represents a connection from the host to the accelerator.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The logic of the example works as follows. Lines 8 and 9 create a buffer of 16 <span class="s18">int </span>elements, which have no initial value. This buffer acts like an array. Line 11 constructs a <span class="s18">queue</span>, which is a connection to an accelerator device. This simple example asks the SYCL runtime to choose a default accelerator device, but a more robust application would probably examine the topology of the system and choose a particular accelerator. Once the queue is created, the example calls the <span class="s18">submit() </span>member function to submit work to the accelerator. The parameter to this <span class="s18">submit() </span>function is a lambda function, which executes immediately on the host. The lambda function does two things. First, it creates an <span class="s18">accessor </span>on line 12, which can write elements in the buffer. Second, it calls the <span class="s18">parallel_for() </span>function on line 13 to execute code on the accelerator.</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The call to <span class="s18">parallel_for() </span>takes two parameters. One parameter is a lambda function, and the other is the <span class="s18">range </span>object “<span class="s18">r</span>” that represents the number of elements in the buffer. SYCL arranges for this lambda to be called on the accelerator once for each index in that range, i.e. once for each element of the buffer. The lambda simply assigns a value to the buffer element by using the <span class="s18">out </span>accessor that was created on line 12. In this simple example, there are no dependencies between the invocations of the lambda, so the program is free to execute them in parallel in whatever way is most efficient for this accelerator.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">After calling <span class="s18">parallel_for()</span>, the host part of the code continues running without waiting for the work to complete on the accelerator. However, the next thing the host does is to create a <span class="s18">host_accessor </span>on line 18, which reads the elements of the buffer. The SYCL runtime knows this buffer is written by the accelerator, so the <span class="s18">host_accessor </span>constructor (line 18) is blocked until the work submitted by the <span class="s18">parallel_for() </span>is complete. Once the accelerator work completes, the host code continues past line 18, and it uses the <span class="s18">out </span>accessor to read values from the buffer.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Additional Resources</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">This introduction to SYCL is not meant to be a complete tutorial. Rather, it just gives you a flavor of the language. There are many more features to learn, including features that allow you to take advantage of common accelerator hardware such as local memory, barriers, and SIMD. There are also features that let you submit work to many accelerator devices at once, allowing a single application to run work in parallel on many devices simultaneously.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following resources are useful to learning and mastering SYCL with oneAPI:</p><ul id="l5"><li data-list-text="•"><p class="s13" style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Explore SYCL with Samples from Intel <span style=" color: #000;">provides an overview and links to simple sample applications available from GitHub*.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/articles/dpcpp-foundations-code-sample.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The </a>DPC++ Foundations Code Sample Walk-Through <span style=" color: #000;">is a detailed examination of the Vector Add sample code, the DPC++ equivalent to a basic Hello World application.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://github.khronos.org/SYCL_Reference/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The Khronos* </a>SYCL Reference <span style=" color: #000;">contains information about SYCL class member functions and usage examples.</span></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/tools/oneapi/training/dpc-essentials.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The </a><span style=" color: #075FA7;">DPC++ Essentials training course </span>is a guided learning path for SYCL using Jupyter* Notebooks on Intel<span class="s12">® </span>DevCloud.</p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Data Parallel C++ Mastering DPC++ for Programming of Heterogeneous Systems using C++ and SYCL <span style=" color: #000;">is a comprehensive book that introduces and explains key programming concepts and language details about SYCL and Heterogeneous programming.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark8">&zwnj;</a>C/C++ or Fortran with OpenMP* Offload Programming Model<a name="bookmark93">&zwnj;</a></h4><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The Intel<span class="s12">® </span>oneAPI DPC++/C++ Compiler and the Intel<span class="s12">® </span>Fortran Compiler enable software developers to use OpenMP* directives to offload work to Intel accelerators to improve the performance of applications.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/dpcpp-cpp-compiler/developer-guide-reference/2025-0/openmp-support.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">This section describes the use of OpenMP directives to target computations to the accelerator. Developers unfamiliar with OpenMP directives can find basic usage information documented in the OpenMP Support sections of the </a><a href="https://www.intel.com/content/www/us/en/docs/dpcpp-cpp-compiler/developer-guide-reference/2025-0/openmp-support.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/docs/dpcpp-cpp-compiler/developer-guide-reference/2025-0/openmp-support.html" class="s16" target="_blank">® </a>oneAPI DPC++/C++ Compiler Developer Guide and Reference <a href="https://www.intel.com/content/www/us/en/docs/fortran-compiler/developer-guide-reference/2025-0/openmp-support.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">or </a><a href="https://www.intel.com/content/www/us/en/docs/fortran-compiler/developer-guide-reference/2025-0/openmp-support.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/docs/fortran-compiler/developer-guide-reference/2025-0/openmp-support.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/docs/fortran-compiler/developer-guide-reference/2025-0/openmp-support.html" class="a" target="_blank">Fortran </a>Compiler Developer Guide and Reference<span style=" color: #000;">.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">OpenMP is not supported for FPGA devices.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Basic OpenMP Target Construct</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The OpenMP target construct is used to transfer control from the host to the target device. Variables are mapped between the host and the target device. The host thread waits until the offloaded computations are complete. Other OpenMP tasks may be used for asynchronous execution on the host; use the <span class="s18">nowait </span>clause to specify that the encountering thread does not wait for the target region to complete.</p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">C/C++</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The C++ code snippet below targets a SAXPY computation to the accelerator.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#pragma omp target map(tofrom:fa), map(to:fb,a) #pragma omp parallel for firstprivate(a) for(k=0; k&lt;FLOPS_ARRAY_SIZE; k++)</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">fa[k] = a * fa[k] + fb[k]</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Array <span class="s18">fa </span>is mapped both to and from the accelerator since <span class="s18">fa </span>is both input to and output from the calculation. Array <span class="s18">fb </span>and the variable <span class="s18">a </span>are required as input to the calculation and are not modified, so there is no need to copy them out. The variable <span class="s18">FLOPS_ARRAY_SIZE </span>is implicitly mapped to the accelerator. The loop index <span class="s18">k </span>is implicitly private according to the OpenMP specification.</p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Fortran</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">This Fortran code snippet targets a matrix multiply to the accelerator.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:123.3pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">!$omp target map(to: a, b ) map(tofrom: c )</p><p class="s19" style="padding-left: 29pt;text-indent: -29pt;text-align: left;">!$omp parallel do private(j,i,k) do j=1,n</p><p class="s19" style="padding-left: 44pt;text-indent: 0pt;text-align: left;">do i=1,n</p><p class="s19" style="padding-left: 59pt;text-indent: 0pt;text-align: left;">do k=1,n</p><p class="s19" style="padding-left: 59pt;text-indent: 14pt;text-align: left;">c(i,j) = c(i,j) + a(i,k) * b(k,j) enddo</p><p class="s19" style="padding-left: 29pt;text-indent: 14pt;text-align: left;">enddo enddo</p><p class="s19" style="text-indent: 0pt;text-align: left;">!$omp end parallel do</p><p class="s19" style="text-indent: 0pt;text-align: left;">!$omp end target</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Arrays <span class="s18">a </span>and <span class="s18">b </span>are mapped to the accelerator, while array <span class="s18">c </span>is both input to and output from the accelerator. The variable <span class="s18">n </span>is implicitly mapped to the accelerator. The private clause is optional since loop indices are automatically private according to the OpenMP specification.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Map Variables</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">To optimize data sharing between the host and the accelerator, the target data directive maps variables to the accelerator and the variables remain in the target data region for the extent of that region. This feature is useful when mapping variables across multiple target regions.</p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">C/C++</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="padding-left: 4pt;text-indent: -5pt;text-align: left;">#pragma omp target data [clause[[,] clause],...] structured-block</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Fortran</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">!$omp target data [clause[[,] clause],...] structured-block</p><p class="s19" style="text-indent: 0pt;text-align: left;">!$omp end target data</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Clauses</p><p class="s13" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/fortran-compiler-oneapi-dev-guide-and-reference/top/language-reference/a-to-z-reference/t-to-z/target-data.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The clauses can be one or more of the following. See </a>TARGET DATA <span style=" color: #000;">for more information.</span></p><ul id="l6"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">DEVICE (integer-expression)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">IF ([TARGET DATA:] scalar-logical-expression)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">MAP ([[map-type-modifier[,]] map-type: ] list)</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 1pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">Map type can be one or more of the following:</span></p><ul id="l7"><li data-list-text="•"><p class="s18" style="padding-top: 6pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">alloc</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">to</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">from</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">tofrom</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">delete</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-bottom: 3pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">release</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p></li></ul></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">SUBDEVICE ([integer-constant ,] integer-expression [ : integer-expression [ : integer-expression]])</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">USE_DEVICE_ADDR (list) // available only in <span class="s18">ifx</span></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">USE_DEVICE_PTR (ptr-list)</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 1pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">The SUBDEVICE clause is ignored in the following cases:</span></p><ul id="l8"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">If ZE_FLAT_DEVICE_HIERARCHY is set to FLAT or COMBINED.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">If env LIBOMPTARGET_DEVICES is set to SUBDEVICE/SUBSUBDEVICE</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-bottom: 3pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">If env ONEAPI_DEVICE_SELECTOR is used to select devices.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:78.5pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">DEVICE (integer-expression)</p><p class="s19" style="text-indent: 0pt;text-align: left;">IF ([TARGET DATA:] scalar-logical-expression)</p><p class="s19" style="text-indent: 0pt;text-align: left;">MAP ([[map-type-modifier[,]] map-type: alloc | to | from | tofrom | delete | release] list) SUBDEVICE ([integer-constant ,] integer-expression [ : integer-expression [ : integer- expression]])</p><p class="s19" style="text-indent: 0pt;text-align: left;">USE_DEVICE_ADDR (list) // available only in ifx USE_DEVICE_PTR (ptr-list)</p></div></li></ul></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Use the target update directive or <i>always </i>map-type-modifier in map clause to synchronize an original variable in the host with the corresponding variable in the device.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Compile to Use OpenMP TARGET</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following example commands illustrate how to compile an application using OpenMP target.</p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">C/C++</p><ul id="l9"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Linux:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icx     -fiopenmp     -fopenmp-targets=spir64     code.c              </span></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Windows (you can use <span class="s18">icx </span>or <span class="s18">icpx</span>):</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icx     /Qiopenmp     /Qopenmp-targets=spir64     code.c              </span></p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Fortran</p></li><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Linux:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">ifx     -fiopenmp     -fopenmp-targets=spir64     code.f90              </span></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Windows:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">ifx     /Qiopenmp     /Qopenmp-targets=spir64     code.f90              </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Additional OpenMP Offload Resources</p><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Intel offers code samples that demonstrate using OpenMP directives to target accelerators at </a><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming" class="a" target="_blank">https:// </a>github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming<span style=" color: #000;">. Specific samples include:</span></p></li><li data-list-text="•"><p class="s13" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Matrix Multiplication <span style=" color: #000;">is a simple program that multiplies together two large matrices and verifies the results. This program is implemented using two ways: SYCL* and OpenMP.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming/C%2B%2B/StructuredGrids/iso3dfd_omp_offload" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The </a>ISO3DFD OpenMP Offload <span style=" color: #000;">sample references three-dimensional finite-difference wave propagation in isotropic media. ISO3DFD is a three-dimensional stencil to simulate a wave propagating in a 3D isotropic medium and shows some common challenges and techniques when targeting OpenMP Offload devices in more complex applications to achieve good performance.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><span style=" color: #075FA7;">openmp_reduction </span>is a simple program that calculates pi. This program is implemented using C++ and OpenMP for CPUs and accelerators based on Intel<span class="s12">® </span>Architecture.</p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">LLVM/OpenMP Runtimes <span style=" color: #000;">describes the distinct types of runtimes available and can be helpful when debugging OpenMP offload.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi/optimization-guide-gpu/2025-0/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The </a>oneAPI GPU Optimization Guide <span style=" color: #000;">gives extensive tips for getting the best GPU performance for oneAPI programs.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Offload and Optimize OpenMP* Applications with Intel Tools <span style=" color: #000;">describes how to use OpenMP* directives to add parallelism to your application.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://www.openmp.org/wp-content/uploads/openmp-examples-4.5.0.pdf" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">openmp.org has an examples document: </a><a href="https://www.openmp.org/wp-content/uploads/openmp-examples-4.5.0.pdf" class="a" target="_blank">https://www.openmp.org/wp-content/uploads/openmp- </a>examples-4.5.0.pdf<span style=" color: #000;">. Chapter 4 of the examples document focuses on accelerator devices and the target construct.</span></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://www.openmp.org/resources/openmp-books" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">There are a number of useful OpenMP books. See the listing at: </a><a href="https://www.openmp.org/resources/openmp-books" class="a" target="_blank">https://www.openmp.org/resources/ </a><a href="https://www.openmp.org/resources/openmp-books" target="_blank">openmp-books</a></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Details on using Intel compilers with OpenMP offload, including lists of supported options and example code, is available in the compiler developer guides:</p><ul id="l10"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 34pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/dpcpp-cpp-compiler/developer-guide-reference/2025-0/openmp-support.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/docs/dpcpp-cpp-compiler/developer-guide-reference/2025-0/openmp-support.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/docs/dpcpp-cpp-compiler/developer-guide-reference/2025-0/openmp-support.html" target="_blank">oneAPI DPC++/C++ Compiler Developer Guide and Reference</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 34pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/fortran-compiler/developer-guide-reference/2025-0/openmp-support.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/docs/fortran-compiler/developer-guide-reference/2025-0/openmp-support.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/docs/fortran-compiler/developer-guide-reference/2025-0/openmp-support.html" target="_blank">Fortran Compiler Developer Guide and Reference</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark9">&zwnj;</a>Device Selection<a name="bookmark94">&zwnj;</a></h4><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="#bookmark174" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Offloading code to a </a>device <span style=" color: #000;">(such as a CPU, GPU, or FPGA) is available for both DPC++ and OpenMP* applications.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">DPC++ Device Selection in the Host Code</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Host code can explicitly select a device type. To do select a device, select a queue and initialize its device with one of the following:</p></li></ul></li><li data-list-text="•"><p class="s18" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">default_selector</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">cpu_selector</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">gpu_selector</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">accelerator_selector</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">If <span class="s18">default_selector </span>is used, the kernel runs based on a heuristic that chooses from available compute devices (all, or a subset based on the value of the <span class="s18">ONEAPI_DEVICE_SELECTOR </span>environment variable).</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">If a specific device type (such as <span class="s18">cpu_selector </span>or <span class="s18">gpu_selector</span>) is used, then it is expected that the specified device type is available in the platform or included in the filter specified by <span class="s18">ONEAPI_DEVICE_SELECTOR</span>. If such a device is not available, then the runtime system throws an exception indicating that the requested device is not available. This error can be thrown in the situation where an ahead-of-time (AOT) compiled binary is run on a platform that does not contain the specified device type.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 110%;text-align: left;">NOTE <span class="p">While DPC++ applications can run on any supported target hardware, tuning is required to derive the best performance advantage on a given target architecture. For example, code tuned for a CPU likely will not run as fast on a GPU accelerator without modification.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">ONEAPI_DEVICE_SELECTOR <span class="p">is a complex environment variable that allows you to limit the runtimes, compute device types, and compute device IDs that may be used by the DPC++ runtime to a subset of all available combinations. The compute device IDs correspond to those returned by the SYCL API, </span>clinfo<span class="p">, or </span>sycl-ls <span class="p">(with the numbering starting at 0). They have no relation to whether the device with that ID is of a certain type or supports a specific runtime. Using a programmatic special selector (like </span>gpu_selector<span class="p">) to request a</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">filtered out device will cause an exception to be thrown. Refer to the environment variable description in GitHub for details on use and example values: </a><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md" class="a" target="_blank">https://github.com/intel/llvm/blob/sycl/sycl/doc/ </a>EnvironmentVariables.md<span style=" color: #000;">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The <span class="s18">sycl-ls </span>tool enumerates a list of devices available in the system. It is strongly recommended to run this tool before running any SYCL or DPC++ programs to make sure the system is configured properly. As a part of enumeration, <span class="s18">sycl-ls </span>prints the <span class="s18">ONEAPI_DEVICE_SELECTOR </span>string as a prefix of each device listing. The format of the <span class="s18">sycl-ls </span>output is <span class="s18">[ONEAPI_DEVICE_SELECTOR] Platform_name, Device_name, Device_version [driver_version]</span>. In the following example, the string enclosed in the bracket ([ ]) at the beginning of each line is the <span class="s18">ONEAPI_DEVICE_SELECTOR </span>string used to designate the specific device on which the program will run.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Device Selection Example</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:78.5pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ sycl-ls</p><p class="s19" style="text-indent: 0pt;line-height: 11pt;text-align: left;">[opencl:acc:0] Intel<span class="s22">® </span>FPGA Emulation Platform for OpenCL<span class="s22">™ </span>software, Intel<span class="s22">® </span>FPGA Emulation Device</p><p class="s19" style="text-indent: 0pt;line-height: 11pt;text-align: left;">1.2 [2021.12.9.0.24_005321]</p><p class="s19" style="text-indent: 0pt;text-align: left;">[opencl:gpu:1] Intel<span class="s22">® </span>OpenCL HD Graphics, Intel<span class="s22">® </span>UHD Graphics 630 [0x3e92] 3.0 [21.37.20939] [opencl:cpu:2] Intel<span class="s22">® </span>OpenCL, Intel<span class="s22">® </span>Core<span class="s22">™ </span>i7-8700 CPU @ 3.20GHz 3.0 [2021.12.9.0.24_005321] [level_zero:gpu:0] Intel<span class="s22">® </span>oneAPI Level Zero, Intel<span class="s22">® </span>UHD Graphics 630 [0x3e92] 1.1 [1.2.20939] [host:host:0] SYCL host platform, SYCL host device 1.2 [1.2]</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://github.khronos.org/SYCL_Reference/iface/device-selector.html#device-selector" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Additional information about device selection is available from the Khronos* </a>SYCL Reference<span style=" color: #000;">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">OpenMP* Device Query and Selection in the Host Code</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">OpenMP provides a set of APIs for developers to query and set device for running code on the device. Host code can explicitly select and set a device number. For each offloading region, a programmer can also use a <b>device </b>clause to specify the target device that is to be used for executing that particular offload region.</p><ul id="l11"><li data-list-text="•"><p class="s18" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">int omp_get_num_procs (void) <span class="p">routine returns the number of processors available to the device.</span></p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;">void omp_set_default_device(int device_num) <span class="p">routine controls the default target device for offloading code or data.</span></p></li><li data-list-text="•"><p class="s18" style="padding-left: 19pt;text-indent: -14pt;text-align: left;">int omp_get_default_device(void) <span class="p">routine returns the default target device.</span></p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;">int omp_get_num_devices(void) <span class="p">routine returns the number of non-host devices available for offloading code or data.</span></p></li><li data-list-text="•"><p class="s18" style="padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;">int omp_get_device_num(void) <span class="p">routine returns the device number of the device on which the calling thread is executing.</span></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;"><span class="s18">int omp_is_initial_device(int device_num) </span>routine returns <i>true </i>if the current task is executing on the host device; otherwise, it returns <i>false</i>.</p></li><li data-list-text="•"><p class="s18" style="padding-left: 19pt;text-indent: -14pt;text-align: left;">int omp_get_initial_device(void) <span class="p">routine returns a device number that represents the host device.</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">A programmer can also use the environment variable <span class="s18">LIBOMPTARGET_DEVICETYPE = [ CPU | GPU ] </span>to perform a device type selection. If a specific device type such as CPU or GPU is specified, then it is expected that the specified device type is available in the platform. If such a device is not available, then the runtime system throws an error that the requested device type is not available if the environment variable <span class="s18">OMP_TARGET_OFFLOAD </span>has the value <span class="s18">=mandatory</span><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">, otherwise, the execution will have a fallback execution on its initial device. Additional information about device selection is available from the OpenMP 5.2 specification. Details about environment variables are available from GitHub: </a><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md" class="a" target="_blank">https://github.com/intel/llvm/blob/sycl/ </a><span style=" color: #075FA7;">sycl/doc/EnvironmentVariables.md</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark10">&zwnj;</a>SYCL* Execution and Memory Hierarchy<a name="bookmark95">&zwnj;</a></h4><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Execution Hierarchy</p><p style="padding-top: 4pt;padding-bottom: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The SYCL* execution model exposes an abstract view of GPU execution. The SYCL execution hierarchy consists of a 1-, 2-, or 3-dimensional grid of work-items. These work-items are grouped into equal-sized groups called work-groups. Work-items in a work-group are further divided into equal-sized groups called sub-groups.</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span/></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;">To learn more about how this hierarchy works with a GPUor a CPU with Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/docs/oneapi/optimization-guide-gpu/2024-1/thread-mapping.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">UHD Graphics, see </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi/optimization-guide-gpu/2024-1/thread-mapping.html" class="a" target="_blank">SYCL* </a><span style=" color: #075FA7;">Mapping and GPU Occupancy </span>in the oneAPI GPU Optimization Guide.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Optimizing Memory Access</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;">Using Intel<span class="s12">® </span>VTune Profiler, you can identify memory bottlenecks that are hindering performance. For more information, see the Memory Allocation APIs section of the Intel VTune User Guide.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">Once the problem areas are identified, utilize the tools described in the Intel<span class="s12">® </span>oneAPI GPU Optimization Guide to learn how work-items in a kernel can synchronize to exchange data, update data, or cooperate with each other to accomplish a task. For more information, see these sections in the GPU Optimization Guide:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi/optimization-guide-gpu/2024-1/kernel-sync.html">Synchronization among Work-items in a Kernel</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi/optimization-guide-gpu/2024-1/slm.html">Shared Local Memory</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi/optimization-guide-gpu/2024-1/usm-allocation.html">Unified Shared Memory Allocations</a></p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Memory Hierarchy</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The General Purpose GPU (GPGPU) compute model consists of a host connected to one or more compute devices. Each compute device consists of many GPU Compute Engines (CE), also known as Execution Units (EU) or Xe Vector Engines (XVE). The compute devices may also include caches, shared local memory (SLM), high-bandwidth memory (HBM), and so on, as shown in the figure below. Applications are then built as a combination of host software (per the host framework) and kernels submitted by the host to run on the VEs with a predefined decoupling point.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">In some cases, a <span class="s18">kernel_bundle </span><a href="#bookmark91" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">created with a given device will not contain kernels that are compatible, due to behavior required in the SYCL 2020 specification. For more information, see </a><a href="#bookmark91" class="a">SYCL Kernel </a><span style=" color: #075FA7;">Compatibility</span>.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi/optimization-guide-gpu/2025-0/execution-model-overview.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To learn more about memory hierarchy within the General Purpose GPU (GPGPU) compute model, see </a>Execution Model Overview <span style=" color: #000;">in the oneAPI GPU Optimization Guide.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Using Data Prefetching to Reduce Memory Latency in GPUs</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Utilizing data prefetching can reduce the amount of write backs, reduce latency, and improve performance in Intel<span class="s12">® </span>GPUs.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi/optimization-guide-gpu/2024-1/openmp-bp-prefetch.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To learn more about how prefetching works with oneAPI, see </a>Prefetching <span style=" color: #000;">in the oneAPI GPU Optimization Guide.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark11">&zwnj;</a>oneAPI &nbsp;&nbsp; Development &nbsp;&nbsp; Environment &nbsp;&nbsp; Setup &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a name="bookmark96">&zwnj;</a></h3><p style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span style=" color: #000;">The Intel</span><span class="s12">® </span><a href="#bookmark88" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">oneAPI tools are available in several convenient forms, as detailed in </a>oneAPI Toolkit Distribution <a href="https://www.intel.com/content/www/us/en/developer/articles/guide/installation-guide-for-oneapi-toolkits.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">earlier in this guide. Follow the instructions in the </a><a href="https://www.intel.com/content/www/us/en/developer/articles/guide/installation-guide-for-oneapi-toolkits.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/developer/articles/guide/installation-guide-for-oneapi-toolkits.html" class="s16" target="_blank">® </a>oneAPI Toolkit Installation Guide <span style=" color: #000;">to obtain and install the tools.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Installation Directories</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">On a Windows* system, the Intel oneAPI development toolkits (Base, HPC, Rendering, etc.) are typically installed in the <span class="s18">C:\Program Files (x86)\Intel\oneAPI\ </span>directory which is known as the Component Directory Layout. When installing a toolkit, a Unified Directory Layout is also created and linked to the Component Directory Layout in the <span class="s18">C:\Program Files (x86)\Intel\oneAPI\&lt;toolkit-version&gt; </span>folder.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">On a Linux* system, the Intel oneAPI development toolkits (Base, HPC, Rendering, etc.) are typically installed in the <span class="s18">/opt/intel/oneapi/ </span>directory which is known as the Component Directory Layout. When installing a toolkit, a Unified Directory Layout is also created and linked to the Component Directory Layout in the <span class="s18">/opt/intel/oneapi/&lt;toolkit-version&gt;/ </span>folder.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="#bookmark98" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">To learn more about the differences between the Component Directory Layout and Unified Directory Layout, see </a>Use the setvars and oneapi-vars scripts with Windows <a href="#bookmark102" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">or </a><a href="#bookmark102" class="a">Use the setvars and oneapi-vars scripts with </a><a href="#bookmark102">Linux</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 111%;text-align: left;"><b>NOTE </b>Starting with the 2024.0 release, macOS is no longer supported in Intel<span class="s12">® </span>oneAPI Toolkits and components. Several Intel-led open source developer tool projects will continue supporting macOS on Apple Silicon including oneAPI Threading Building Blocks (oneTBB) and Intel<span class="s12">® </span>Implicit SPMD Program Compiler. We welcome the opportunity to work with contributors to expand support to additional tools in the future.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">These are the default locations; the precise location can be changed during installation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Within the oneAPI installation directory are a collection of folders that contain the compilers, libraries, analyzers, and other tools installed on the development system. The precise list depends on the toolkit(s) installed and the options selected during installation. Most of the folders within the oneAPI installation directory have obvious names. For example, the mkl folder contains the Intel<span class="s12">® </span>oneAPI Math Kernel Library (oneMKL), the ipp folder contains the Intel<span class="s12">® </span>Integrated Performance Primitives (Intel<span class="s12">® </span>IPP) library, and so on.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Environment Variables</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Some of the tools in the Intel oneAPI toolkits depend on environment variables to:</p></li><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Assist the compilation and link process (e.g., PATH, CPATH, INCLUDE, etc.)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Locate debuggers, analyzers, and local help files (e.g., PATH, MANPATH)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Identify tool-specific parameters and dynamic (shared) link libraries (e.g., LD_LIBRARY_PATH, CONDA_*, etc.)</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">setvars, oneapi-vars, and vars Files</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Every installation of the Intel oneAPI toolkits includes a single top-level “setvars” script and multiple tool- specific “vars” scripts (<span class="s18">setvars.sh </span>and <span class="s18">env/vars.sh </span>on Linux; <span class="s18">setvars.bat </span>and <span class="s18">env\vars.bat </span>on Windows). When executed (sourced), these scripts configure the local environment variables to reflect the needs of the installed Intel oneAPI development tools.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The Unified Directory Layout was implemented in 2024.0. It utilizes a top-level <span class="s18">oneapi-vars </span>script to initialize the common environment variables and relies on optional <span class="s18">etc/*/vars.sh </span>(on Linux) and <span class="s18">etc\*</span></p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">\vars.bat <span class="p">(on Windows) scripts to initialize component-specific environment variables that are not addressed by the </span>oneapi-vars <span class="p">script.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The following sections provide detailed instructions on how to use the setvars, oneapi-vars, and vars scripts to initialize the oneAPI development environment:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="#bookmark98">Use the setvars and oneapi-vars Scripts with Windows*</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="#bookmark102">Use the setvars and oneapi-vars Scripts with Linux*</a></p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Install GPU Drivers or Plugins (Optional)</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 159%;text-align: left;">You can develop oneAPI applications using C++ and SYCL* that will run on Intel, AMD*, or NVIDIA* GPUs. To develop and run applications for specific GPUs you must first install the corresponding drivers or plugins:</p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://dgpu-docs.intel.com/installation-guides/index.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To use an Intel GPU, install the </a>latest Intel GPU drivers<span style=" color: #000;">.</span></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;line-height: 112%;text-align: left;">To use an AMD* GPU with the Intel<span class="s12">® </span><a href="https://developer.codeplay.com/products/oneapi/amd/guides/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI DPC++ Compiler, install the </a><span style=" color: #075FA7;">oneAPI for AMD GPUs plugin </span>from Codeplay (Linux only).</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 112%;text-align: left;">To use an NVIDIA* GPU with the Intel<span class="s12">® </span><a href="https://developer.codeplay.com/products/oneapi/nvidia/guides/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI DPC++ Compiler, install the </a><a href="https://developer.codeplay.com/products/oneapi/nvidia/guides/" class="a" target="_blank">oneAPI for NVIDIA GPUs </a><span style=" color: #075FA7;">plugin </span>from Codeplay (Linux and Windows).</p></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Modulefiles (Linux only)</p><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="http://modules.sourceforge.net/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Users of </a>Environment Modules <span style=" color: #000;">and Lmod can use the modulefiles included with the oneAPI toolkit installation to initialize their development environment variables. The oneAPI modulefile scripts are only supported on Linux and are provided as an alternative to using the setvars, oneapi-vars, and vars scripts referenced above. In general, users should not mix modulefiles with the setvars or oneapi-vars environment scripts.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="#bookmark106" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">See </a>Use Modulefiles with Linux* <span style=" color: #000;">for detailed instructions on how to use the oneAPI modulefiles to initialize the oneAPI development environment.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark12">&zwnj;</a>Use the setvars and oneapi-vars Scripts with Windows*<a name="bookmark97">&zwnj;</a></h4><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark98">&zwnj;</a>The Unified Directory Layout was implemented in 2024.0. If you have multiple toolkit versions installed, the Unified layout adds the ability to ensure your development environment contains the component versions that were released as part of that specific toolkit version and it shortens the PATH names to help fix problems with long PATH names.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">With the new Unified Directory Layout, you will see components installed together in a collection of common folders (eg., bin, lib, include, share, etc.). These common folders are located in a top-level folder that is named for the toolkit version number. For example:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:56.0pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">&quot;C:\Program Files(x86)\Intel\oneAPI\2024.0\&quot;</p><p class="s19" style="text-indent: 0pt;text-align: left;">|-- bin</p><p class="s19" style="text-indent: 0pt;text-align: left;">|-- lib</p><p class="s19" style="text-indent: 0pt;text-align: left;">|-- include</p><p class="s19" style="text-indent: 0pt;text-align: left;">...etc...</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The directory layout that was used prior to 2024.0 is still supported on new and existing installations. This prior layout is called the Component Directory Layout. Now you have the option to use the Component Directory Layout or the Unified Directory Layout.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Differences in Component Directory Layout and Unified Directory Layout</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Most of the oneAPI component tool folders contain an environment script named <span class="s18">env\vars.bat </span>that configures the environment variables needed by that component to support oneAPI development work. For example, in a default installation, the Intel<span class="s12">® </span>Integrated Performance Primitives (Intel<span class="s12">® </span>IPP) vars script on Windows is located at <span class="s18">C:\Program Files (x86)\Intel\oneAPI\ipp\latest\env\vars.bat </span>in the Component Directory Layout. This pattern is shared by all oneAPI components that include an <span class="s18">env\vars </span>setup script.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: justify;">In the Component Directory Layout, the component <span class="s18">env\vars </span>scripts can be called directly or collectively. To call them collectively, a script named <span class="s18">setvars.bat </span>is provided in the oneAPI installation folder. For example, in a default Component Directory Layout installation: <span class="s18">C:\Program Files (x86)\Intel\oneAPI</span></p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">\setvars.bat<span class="p">. The Unified Directory Layout does not use the </span>env\vars.sh <span class="p">scripts to initialize the development environment. Instead, each component is “corralled” into shared folders that are common to the components. In other words, each component contributes its header files to a single common </span>include <span class="p">folder, its library files to a single common </span>lib <span class="p">folder, and so on.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">Advantages of the Unified Directory Layout</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The Unified Directory Layout makes it much easier to switch between different toolkit versions without having to build and maintain setvars config files or play games with installation of multiple Intel<span class="s12">® </span>oneAPI toolkits. It is also useful for limiting the length of environment variables, especially the PATH variable, on Windows development systems, a troublesome issue for some Windows developers.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The Unified Directory Layout environment variables can only be setup collectively. To initialize the development environment variables run the script named <span class="s18">oneapi-vars.bat</span>. In a default Unified Directory Layout installation, on a Windows machine, that script is located here: <span class="s18">C:\Program Files (x86)\Intel</span></p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">\oneAPI\&lt;toolkit-version&gt;\oneapi-vars.bat<span class="p">. The </span>&lt;toolkit-version&gt; <span class="p">corresponds to the version number of the oneAPI toolkit that you installed. For example: </span>C:\Program Files (x86)\Intel\oneAPI</p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">\2024.0\oneapi-vars.bat <span class="p">or </span>C:\Program Files (x86)\Intel\oneAPI\\2024.1\oneapi-vars.bat<span class="p">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Running the <span class="s18">setvars.bat </span>script without any arguments causes it to locate and run all <span class="s18">&lt;component&gt;</span></p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">\latest\env\vars.bat <span class="p">scripts in the Component Directory Layout installation. Changes made to the environment by these scripts can be seen by running the Windows </span>set <span class="p">command after running </span>setvars.bat<span class="p">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Running the <span class="s18">oneapi-vars.bat </span>script without any arguments causes it to configure the environment for the specific toolkit version in which that <span class="s18">oneapi-vars.bat </span>script is located. It will also run any optional <span class="s18">C:\Program Files (x86)\Intel\oneAPI\&lt;toolkit-version&gt;\etc\&lt;component&gt;\vars.sh </span>scripts that are part of that Unified Directory installation. Changes made to the environment by these scripts can be seen by running the Windows <span class="s18">set env </span>command after running the <span class="s18">oneapi-vars.bat </span>script.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">To learn more about how <span class="s18">oneapi-vars.bat </span>works, see <span style=" color: #075FA7;">Environment Initialization in the Unified Directory Layout</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Visual Studio Code Extension</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Visual Studio Code* developers can install a oneAPI environment extension to run the <span class="s18">setvars.bat </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/using-vs-code-with-intel-oneapi/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">within Visual Studio Code. Learn more in </a><span style=" color: #075FA7;">Using Visual Studio Code with Intel oneAPI Toolkits</span>.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 108%;text-align: left;"><b>NOTE </b>Changes to your environment made by running the <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>script (or the individual <span class="s18">vars.bat </span>scripts) are not permanent. Those changes only apply to the <span class="s18">cmd.exe </span>session in which the <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>environment script was executed.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Command-Line Arguments</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>script supports several command-line arguments, which are displayed using the <span class="s18">--help </span>option. For example:</p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Component Directory Layout</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">&quot;C:\Program    Files    (x86)\Intel\oneAPI\setvars.bat&quot;    --help           </span></p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Unified Directory Layout</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">&quot;C:\Program  Files  (x86)\Intel\oneAPI\&lt;toolkit-version&gt;\oneapi-vars.bat&quot;  --help      </span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The <span class="s18">--config=file </span>argument and the ability to include arguments that will be passed to the <span class="s18">vars.bat </span>scripts that are called by the <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>script can be used to customize the environment setup. The <span class="s18">--config=file </span>option is only supported by the <span class="s18">setvars.bat </span>script.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The <span class="s18">--config=file </span>argument provides the ability to limit environment initialization to a specific set of oneAPI components. It also provides a way to initialize the environment for specific component versions. For example, to limit environment setup to just the Intel<span class="s12">® </span>IPP library and the Intel<span class="s12">® </span>oneAPI Math Kernel Library (oneMKL), pass a config file that tells the <span class="s18">setvars.bat </span>script to only call the <span class="s18">vars.bat </span><a href="#bookmark99" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">environment scripts for those two oneAPI components. More details and examples are provided in </a><a href="#bookmark99" class="a">Use a Config File for </a><span style=" color: #075FA7;">setvars.bat on Windows</span>.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Any extra arguments passed on the <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>command line that are not described in the <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>help message will be passed to every called <span class="s18">vars.bat </span>script. That is, if the <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>script does not recognize an argument, it assumes the argument is meant for use by one or more component vars scripts and passes those extra arguments to every component <span class="s18">vars.bat </span>script that it calls. The most common extra arguments are <span class="s18">ia32 </span>and <span class="s18">intel64</span>, which are used by the Intel compilers and the Intel<span class="s12">® </span>IPP, oneMKL, and Intel<span class="s12">® </span>Threading Building Blocks (Intel<span class="s12">® </span>TBB) libraries to specify the application target architecture.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">If more than one version of Microsoft Visual Studio* is installed on your system, you can specify which Visual Studio environment should be initialized as part of the oneAPI <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>environment initialization by adding the <span class="s18">vs2017</span>, <span class="s18">vs2019</span>, or <span class="s18">vs2022 </span>argument to the <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>command line. By default, the most recent version of Visual Studio is located and initialized.</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Inspect the individual <span class="s18">vars.bat </span>scripts to determine which, if any, command-line arguments they accept.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">How to Run</p><p class="s14" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Component Directory Layout</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">&lt;install-dir&gt;\setvars.bat                   </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To run <span class="s18">setvars.bat </span>or a <span class="s18">vars.bat </span>script in a PowerShell window, use the following:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">cmd.exe  &quot;/K&quot;  &#39;&quot;C:\Program  Files  (x86)\Intel\oneAPI\setvars.bat&quot;  &amp;&amp;  powershell&#39;      </span></p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Unified Directory Layout</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">&lt;install-dir&gt;\&lt;toolkit-version&gt;\oneapi-vars.bat              </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To run <span class="s18">oneapi-vars.bat </span>or a <span class="s18">vars.bat </span>script in a PowerShell window, use the following:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">cmd.exe &quot;/K&quot; &#39;&quot;C:\Program Files (x86)\Intel\oneAPI\&lt;toolkit-version&gt;\oneapi-vars.bat&quot; &amp;&amp; powershell&#39;</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s17" style="padding-top: 12pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">How to Verify</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">After executing <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat</span>, verify success by searching for the SETVARS_COMPLETED environment variable. If <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>was successful the SETVARS_COMPLETED environment variable will have a value of 1:</p><p style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">set       |       find       &quot;SETVARS_COMPLETED&quot;                  </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Return value</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">SETVARS_COMPLETED=1                     </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">If the return value is anything other than <span class="s18">SETVARS_COMPLETED=1 </span>the test failed and <span class="s18">oneapi-vars.bat </span>did not complete properly.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Using the VS####INSTALLDIR environment variables</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">If you installed Visual Studio in a non-standard location, or you installed only the Visual Studio Build Tools (not the full Visual Studio IDE) you may experience an issue where the <span class="s18">setvars.bat </span>script cannot locate the Visual Studio <span class="s18">vcvarsall.bat </span>script. In such a case you can use the <span class="s18">VS####INSTALLDIR </span>environment variables to locate the appropriate Visual Studio installation. For example, if only the Visual Studio Build Tools are installed, you would need to do the following to make <span class="s18">setvars.bat </span>work:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><ul id="l12"><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;line-height: 10pt;text-align: left;">set &quot;VS2022INSTALLDIR=%ProgramFiles(x86)%\Microsoft Visual Studio\2022\BuildTools&quot;</p></li><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;text-align: left;">&quot;%ProgramFiles(x86)%\Intel\oneAPI\setvars.bat&quot;</p></li></ul></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">You can also use the <span class="s18">VS####INSTALLDIR </span>environment variables to force <span class="s18">setvars.bat </span>to configure the environment for a specific installation of Visual Studio, especially if you have multiple copies of Visual Studio installed on your system.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Multiple Runs</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Because many of the individual <span class="s18">env\vars.bat </span>scripts make significant changes to PATH, CPATH, and other environment variables, the top-level <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>script will not allow multiple invocations of itself in the same session. This is done to ensure that your environment variables do not</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">exceed the maximum provided environment space, especially the <span class="s18">%PATH% </span>environment variable. Exceeding the available environment space results in unpredictable behavior in your terminal session and should be avoided.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: justify;">This behavior can be overridden by passing <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>the <span class="s18">--force </span>flag. In this example, the user tries to run <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>twice. The second instance is stopped because <span class="s18">setvars.bat </span>| <span class="s18">oneapi-vars.bat </span>has already been run.</p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">Component Directory Layout</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><ul id="l13"><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;line-height: 10pt;text-align: left;">&lt;install-dir&gt;\setvars.bat</p></li></ul><p class="s19" style="text-indent: 0pt;text-align: left;">:: initializing oneAPI environment ... (SNIP: lot of output)</p><p class="s19" style="text-indent: 0pt;text-align: left;">:: oneAPI environment initialized</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><ul id="l14"><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;line-height: 10pt;text-align: left;">&lt;install-dir&gt;\setvars.bat</p></li></ul><p class="s19" style="text-indent: 0pt;text-align: left;">.. code-block:: WARNING: setvars.bat has already been run. Skipping re-execution.</p><p class="s19" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">To force a re-execution of setvars.bat, use the &#39;--force&#39; option.</p><p class="s19" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">Using &#39;--force&#39; can result in excessive use of your environment variables.</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">In the third instance, the user runs <span class="s18">&lt;install-dir&gt;\setvars.bat --force </span>and the initialization is successful.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><ul id="l15"><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;line-height: 10pt;text-align: left;">&lt;install-dir&gt;\setvars.bat --force</p></li></ul><p class="s19" style="text-indent: 0pt;text-align: left;">:: initializing oneAPI environment ... (SNIP: lot of output)</p><p class="s19" style="text-indent: 0pt;text-align: left;">:: oneAPI environment initialized</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Unified Directory Layout</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><ul id="l16"><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;line-height: 10pt;text-align: left;">&lt;install-dir&gt;\&lt;toolkit-version&gt;oneapi-vars.bat</p></li></ul><p class="s19" style="text-indent: 0pt;text-align: left;">:: initializing oneAPI environment ... (SNIP: lot of output)</p><p class="s19" style="text-indent: 0pt;text-align: left;">:: oneAPI environment initialized</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><ul id="l17"><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;line-height: 10pt;text-align: left;">&lt;install-dir&gt;\&lt;toolkit-version&gt;\oneapi-vars.bat</p></li></ul><p class="s19" style="text-indent: 0pt;text-align: left;">.. code-block:: WARNING: oneapi-vars.bat has already been run. Skipping re-execution.</p><p class="s19" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">To force a re-execution of oneapi-vars.bat, use the &#39;--force&#39; option. Using &#39;--force&#39; can result in excessive use of your environment variables.</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">In the third instance, the user runs <span class="s18">&lt;install-dir&gt;\&lt;toolkit-version&gt;\oneapi-vars.bat --force </span>and the initialization is successful.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><ul id="l18"><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;line-height: 10pt;text-align: left;">&lt;install-dir&gt;\&lt;toolkit-version&gt;\oneapi-vars.bat --force</p></li></ul><p class="s19" style="text-indent: 0pt;text-align: left;">:: initializing oneAPI environment ... (SNIP: lot of output)</p><p class="s19" style="text-indent: 0pt;text-align: left;">:: oneAPI environment initialized</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Environment Initialization in the Unified Directory Layout</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Initializing the environment for the Unified Directory Layout is done by the <span class="s18">oneapi-vars.bat </span>script, not the</p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">setvars.bat <span class="p">script. The usage of oneapi-vars is similar to setvars, but there are some subtle differences.</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The key difference between the setvars script and the oneapi-vars script is that the setvars script does not define any environment variables (other than ONEAPI_ROOT) and the oneapi-vars script defines the common environment variables.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">In the Component Directory Layout, each component is responsible for defining the environment variables needed in order to function. For example, in the Component Directory Layout each component adds its linkable library folders to <span class="s18">LD_LIBRARY_PATH </span>and include headers to <span class="s18">CPATH</span>, etc. The components do this via their individual vars scripts, which are always located in:</p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 6pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">%ONEAPI_ROOT%\&lt;toolkit-version&gt;\opt\&lt;component-name&gt;\latest\env\vars.bat       </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The Unified Directory Layout combines the externally facing include, lib, and bin folders into a set of common folders. In this scenario, the top-level oneapi-vars script defines the environment variables that are needed to locate these common folders. For example, setvars will define LD_LIBRARY_PATH as $ONEAPI_ROOT\lib and CPATH as $ONEAPI_ROOT\include and so on.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">ONEAPI_ROOT Environment Variable</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The <span class="s18">ONEAPI_ROOT </span>variable is set by the top-level <span class="s18">setvars.bat </span>and <span class="s18">oneapi-vars.bat </span>scripts when either script is run. If there is already a <span class="s18">ONEAPI_ROOT </span>environment variable defined, <span class="s18">setvars.bat </span>| <span class="s18">oneapi- vars.bat </span>overwrites it in the <span class="s18">cmd.exe </span>session in which you ran the <span class="s18">setvars.bat </span>or <span class="s18">oneapi-vars.bat </span>script. This variable is primarily used by the <span class="s18">oneapi-cli </span>sample browser and the Microsoft Visual Studio and Visual Studio Code* sample browsers to help them locate oneAPI tools and components, especially for locating the <span class="s18">setvars.bat </span>or <span class="s18">oneapi-vars.bat </span>script if the <span class="s18">SETVARS_CONFIG </span>feature has been enabled. For more information about the <span class="s18">SETVARS_CONFIG </span><a href="#bookmark101" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">feature, see </a><a href="#bookmark101" class="a">Automate the setvars.bat Script with Microsoft Visual </a><span style=" color: #075FA7;">Studio*</span>.</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">With the 2024.0 release, the installer does not add the <span class="s18">ONEAPI_ROOT </span>variable to the environment. To add it to your default environment, define the variable in your local shell initialization file(s) or in the system environment variables.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Customizing the Call to the Microsoft Visual Studio* vcvarsall.bat Configuration Script</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The Intel oneAPI development environment includes support for working with your Visual Studio project at the command prompt. For example, see the “Windows Start Menu &gt; All apps &gt; Visual Studio 2022” folder which typically contains shortcuts to multiple preconfigured Visual Studio setup scripts, such as the “Developer Command Prompt for VS 2022” shortcut. These shortcuts call a Microsoft Visual Studio configuration batch file named <span class="s18">vcvarsall.bat </span>which is typically found in the “%ProgramFiles%\Microsoft Visual Studio\2022\Professional\VC\Auxiliary\Build\” directory.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">If you call the Intel oneAPI environment setup script (<span class="s18">setvars.bat</span>) at a command prompt, it will call the Visual Studio <span class="s18">vcvarsall.bat </span>script as part of the oneAPI environment setup process. Normally, the <span class="s18">vcvarsall.bat </span>environment setup is configured to match the <span class="s18">setvars.bat </span>environment setup. For example, it insures that the Visual Studio <span class="s18">vcvarsall.bat </span>is setup for 64-bit application development if <span class="s18">setvars.bat </span>is setup for a 64-bit oneAPI development environment (the default case).</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">If <span class="s18">setvars.bat </span>(or the compiler’s <span class="s18">env\vars.bat</span>) detects that the Visual Studio <span class="s18">vcvarsall.bat </span>has already been run, the <span class="s18">vcvarsall.bat </span>will <b>not </b>be run a second time. In other words, the <span class="s18">setvars.bat </span>script will honor the pre-existing Visual Studio <span class="s18">vcvarsall.bat </span>environment and configure itself to match (64-bit with 64-bit or 32-bit with 32-bit).</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Other than the 32-bit or 64-bit arguments, the <span class="s18">setvars.bat </span>and compiler’s <span class="s18">env\vars.bat </span>scripts do not pass any arguments to the <span class="s18">vcvarsall.bat </span>script. If you wish to further customize the Visual Studio environment, you must do so before running <span class="s18">setvars.bat </span>or the compiler’s <span class="s18">env\vars.bat </span>script. For example:</p><ul id="l19"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">run <span class="s18">vcvarsall.bat </span>directly with the necessary arguments</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">run setvars.bat (or the compiler’s <span class="s18">env\vars.bat</span>) script</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">At which point, your command prompt development environment will be configured.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The available <span class="s18">vcvarsall.bat </span>arguments for a Visual Studio 2022 Professional installation can be reviewed by typing:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><ul id="l20"><li data-list-text="&gt;"><p class="s19" style="text-indent: 0pt;text-align: left;">&quot;%ProgramFiles%\Microsoft Visual Studio\2022\Professional\VC\Auxiliary\Build\vcvarsall.bat&quot; help</p></li></ul></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">at your Windows command prompt.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Using the VS2022INSTALLDIR and VS2019INSTALLDIR Environment Variables</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">If you see a message similar to the following, when running setvars.bat or oneapi-vars.bat or the compiler</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">\&lt;version&gt;\env\vars.bat script:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:56.0pt;width:486.6pt;"><p class="s19" style="padding-left: 9pt;text-indent: -10pt;text-align: left;">WARNING: Visual Studio was not found in a standard install location: &quot;%ProgramFiles%\\Microsoft Visual Studio\\&lt;Year&gt;\\&lt;Edition&gt;&quot; or &quot;%ProgramFiles(x86)%\\Microsoft Visual Studio\\&lt;Year&gt;\\&lt;Edition&gt;&quot;</p><p class="s19" style="text-indent: 0pt;text-align: left;">Set the VS2019INSTALLDIR or VS2022INSTALLDIR</p><p class="s19" style="text-indent: 0pt;text-align: left;">environment variable to point to your install location and try again.</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">It likely means one of the following is true:</p><ul id="l21"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Microsoft Visual Studio* has not been installed.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Microsoft Visual Studio has been installed in a non-standard location.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Only the Microsoft Build Tools* have been installed.</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">In the case of the first bulleted item, install Microsoft Visual Studio. Once installed, try running the env scripts again.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">In case of the second bulleted item, configure the <span class="s18">VS2022INSTALLDIR </span>environment variable (or <span class="s18">VS2019INSTALLDIR </span>if you are using Visual Studio 2019) to point to the non-standard location of your Microsoft Visual Studio installation, prior to running the environment setup script. For example, assume a non-standard location of Visual Studio 2022 Professional and <span class="s18">setvars.bat</span>:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><ul id="l22"><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;line-height: 10pt;text-align: left;">set &quot;VS2022INSTALLDIR=C:\my\custom\install\path\Microsoft Visual Studio\2022\Professional&quot;</p></li><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;text-align: left;">&quot;%ProgramFiles(x86)%\Intel\oneAPI\setvars.bat&quot;</p></li></ul></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Or, if you have installed the Visual Studio 2022 Build Tools into their standard location you must set</p><p class="s18" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">VS2022INSTALLDIR <span class="p">to point to that install location. For example, using </span>setvars.bat<span class="p">:</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><ul id="l23"><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;line-height: 10pt;text-align: left;">set &quot;VS2022INSTALLDIR=%ProgramFiles(x86)%\Microsoft Visual Studio\2022\BuildTools&quot;</p></li><li data-list-text="&gt;"><p class="s19" style="padding-left: 9pt;text-indent: -9pt;text-align: left;">&quot;%ProgramFiles(x86)%\Intel\oneAPI\setvars.bat&quot;</p></li></ul></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark13">&zwnj;</a>Use a Config File for setvars bat on Windows*<a name="bookmark99">&zwnj;</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The <span class="s18">setvars.bat </span>script sets environment variables for use with the Intel<span class="s12">® </span>oneAPI toolkits by executing each of the <span class="s18">&lt;install-dir&gt;\latest\env\vars.bat </span>scripts found in the respective oneAPI folders. Unless you configure your Windows system to run the <span class="s18">setvars.bat </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-base-windows/top/before-you-begin.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">script automatically, it must be executed every time a new terminal window is opened for command line development, or prior to launching Visual Studio Code, Sublime Text, or any other C/C++ editor you use. For more information, see </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-base-windows/top/before-you-begin.html" class="a" target="_blank">Configure Your </a><span style=" color: #075FA7;">System</span>.</p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;"><b>NOTE </b>Configuration files can only be used with <span class="s18">setvars.bat </span>in the Component Directory Layout. The Unified Directory Layout utilizes <span class="s18">oneapi-vars.bat</span><a href="#bookmark98" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">, which does not support configuration files. To learn more about the layouts, see </a><a href="#bookmark98">Use the setvars and oneapi-vars Scripts with Windows*</a></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The procedure below describes how to use a configuration file to manage environment variables.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Versions and Configurations</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Some oneAPI tools support installation of multiple versions. For those tools that do support multiple versions, the directory is organized like this (assuming a default installation and using the compiler as an example):</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">Program Files (x86)\\Intel\\oneAPI\\compiler\\</p><p class="s19" style="text-indent: 0pt;text-align: left;">|-- 2021.1.1</p><p class="s19" style="text-indent: 0pt;text-align: left;">|-- 2021.2.0</p><p class="s19" style="text-indent: 0pt;text-align: left;">`-- latest -&gt; 2021.2.0</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For example:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">For all tools, there is a symbolic link named <span class="s18">latest </span>that points to the latest installed version of that component; and the <span class="s18">vars.bat </span>script located in the <span class="s18">latest\env\ </span>folder is what the <span class="s18">setvars.bat </span>executes by default.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">If required, <span class="s18">setvars.bat </span>can be customized to point to a specific directory by using a configuration file.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">–config Parameter</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The top level <span class="s18">setvars.bat </span>script accepts a <span class="s18">--config </span>parameter that identifies your custom <b>config.txt </b>file.</p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 6pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">&lt;install-dir&gt;\setvars.bat          --config=&quot;path\to\your\config.txt&quot;          </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The name of your configuration file can have any name you choose. You can create many config files to setup a variety of development or test environments. For example, you might want to test the latest version of a library with an older version of a compiler; use a setvars config file to manage such a setup.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Config File Sample</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The examples below show a simple example of the config file:</p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Load Latest of Everything but…</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">mkl=1.1 dldt=exclude</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Exclude Everything but…</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">default=exclude mkl=1.0 ipp=latest</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The configuration text file must follow these requirements:</p><ul id="l24"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">a newline delimited text file</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">each line consists of a single <span class="s18">&quot;key=value&quot; </span>pair</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">&quot;key&quot; <span class="p">names a component folder in the top-level set of oneAPI directories (the folders found in the</span></p><p class="s18" style="padding-left: 19pt;text-indent: 0pt;line-height: 108%;text-align: left;">%ONEAPI_ROOT% <span class="p">directory). If a </span>&quot;key&quot; <span class="p">appears more than once in a config file, the last </span>&quot;key&quot; <span class="p">wins and any prior keys with the same name are ignored.</span></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;">“<span class="s18">value</span>” names a version directory that is found at the top-level of the component directory. This includes any symbolic links (such as <span class="s18">latest</span>) that might be present at that level in the component directory.</p><ul id="l25"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 34pt;text-indent: -14pt;line-height: 108%;text-align: left;">OR <span class="s18">&quot;value&quot; </span>can be <span class="s18">&quot;exclude&quot;</span>, which means the named key will NOT have its <span class="s18">vars.bat </span>script executed by the <span class="s18">setvars.bat </span>script.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The <span class="s18">&quot;key=value&quot; </span>pair <span class="s18">&quot;default=exclude&quot; </span>is a special case. When included, it will exclude executing ALL</p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">env\vars.bat <span class="p">scripts, except those that are listed in the config file. See the examples below.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Further Customization of Config Files</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The config file can be used to exclude specific components, include specific component versions or only include specific component versions that are named after a <span class="s18">&quot;default=exclude&quot; </span>statement.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">By default, <span class="s18">setvars.bat </span>will process the <span class="s18">latest </span>version of each <span class="s18">env\vars.bat </span>script.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The sample below shows two versions of Intel<span class="s12">® </span>oneAPI Math Kernel Library (oneMKL) installed: 2021.1.1 and 2021.2.0. The <span class="s18">latest </span>shortcut points to the 2021.2.0 folder because it is the latest version installed. By default, <span class="s18">setvars.bat </span>will execute the 2021.2.0 <span class="s18">vars.bat </span>script in the mkl folder because that is the folder that <span class="s18">latest </span>points to.</p><p style="padding-top: 4pt;text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Two versions of oneMKL and config files</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Specify a Specific Version</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To direct <span class="s18">setvars.bat </span>to execute the <span class="s18">&lt;install-dir&gt;\mkl\2021.1.1\env\vars.bat </span>script, add</p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">mkl=2021.1.1 <span class="p">to your config file.</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">This instructs <span class="s18">setvars.bat </span>to execute the <span class="s18">env\vars.bat </span>script located in the <span class="s18">2021.1.1 </span>version folder inside the mkl directory. For other installed components, <span class="s18">setvars.bat </span>will execute the <span class="s18">env\vars.bat </span>script located in the latest version folder.</p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Exclude Specific Components</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To exclude a component, use the following syntax:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">&lt;key&gt;=exclude                       </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;">For example, to exclude Intel<span class="s12">® </span>Integrated Performance Primitives (Intel<span class="s12">® </span>IPP), but include the 2021.1.1 version of Intel<span class="s12">® </span>oneAPI Math Kernel Library (oneMKL):</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">mkl=2021.1.1</p><p class="s19" style="text-indent: 0pt;text-align: left;">ipp=exclude</p></div></li></ul></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">In this example:</p><ul id="l26"><li data-list-text="•"><p class="s18" style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">setvars.bat <span class="p">WILL execute the oneMKL 2021.1.1 </span>env\vars.bat <span class="p">script</span></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><span class="s18">setvars.bat </span>WILL NOT execute Intel<span class="s12">® </span>IPP <span class="s18">env\vars.bat </span>script files</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">setvars.bat <span class="p">WILL execute the latest version of the remaining </span>env\vars.bat <span class="p">script files</span></p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Include Specific Components</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">To execute a specific list of component <span class="s18">env\vars.bat </span>scripts, you must first exclude all <span class="s18">env\vars.bat </span>scripts. Then add back the list of components to be executed by <span class="s18">setvars.bat</span>. Use the following syntax to exclude all component <span class="s18">env\vars.bat </span>scripts from being executed:</p><p style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">default=exclude                      </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For example, to have <span class="s18">setvars.bat </span>execute only the oneMKL and Intel IPP component <span class="s18">env\vars.bat</span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">scripts, use this config file:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">default=exclude mkl=2021.1.1</p><p class="s19" style="text-indent: 0pt;text-align: left;">ipp=latest</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">In this example:</p><ul id="l27"><li data-list-text="•"><p class="s18" style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">setvars.bat <span class="p">WILL execute the oneMKL 2021.1.1 </span>env\vars.bat <span class="p">script</span></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><span class="s18">setvars.bat </span>WILL execute the latest version of the Intel<span class="s12">® </span>IPP <span class="s18">env\vars.bat </span>script</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">setvars.bat <span class="p">WILL NOT execute the </span>env\vars.bat <span class="p">script for any other components</span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark14">&zwnj;</a>Automate the setvars bat Script with Microsoft Visual Studio*<a name="bookmark100">&zwnj;</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark101">&zwnj;</a>The <span class="s18">setvars.bat </span>script sets up the environment variables needed to use the Intel<span class="s12">® </span>oneAPI toolkits. This script must be run every time a new terminal window is opened for command-line development. The setvars.bat script can also be run automatically when Microsoft Visual Studio is started. You can configure this feature to instruct the setvars.bat script to set up a specific set of oneAPI tools by using the <span class="s18">SETVARS_CONFIG </span>environment variable.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To learn more about how <span class="s18">setvars.sh </span><a href="#bookmark98" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">set environment variables, see </a><a href="#bookmark98" class="a">Use the setvars and oneapi-vars </a><a href="#bookmark98">Scripts with Windows*</a></p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">SETVARS_CONFIG Environment Variable States</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">The SETVARS_CONFIG environment variable enables automatic configuration of the oneAPI development environment when you start your instance of Microsoft Visual Studio. The variable has three conditions or states:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Undefined (the <span class="s18">SETVARS_CONFIG </span>environment variable does not exist)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Defined but empty (the value contains nothing or only whitespace)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Defined and points to a <span class="s18">setvars.bat </span>configuration file</p></li></ul><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">If <span class="s18">SETVARS_CONFIG </span>is undefined there will be no attempt to automatically run <span class="s18">setvars.bat </span>when Visual Studio is started. This is the default case, since the <span class="s18">SETVARS_CONFIG </span>variable is not defined by the oneAPI installer.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">If <span class="s18">SETVARS_CONFIG </span>is defined and has no value (or contains only whitespace), the <span class="s18">setvars.bat </span>script will be automatically run when Visual Studio is started. In this case, the setvars.bat or script initializes the environment for <i>all </i>oneAPI tools that are installed on your system. For more information about running the <span class="s18">setvars.bat </span><a href="https://www.intel.com/content/www/us/en/docs/oneapi-base-toolkit/get-started-guide-windows/2025-0/run-project-visual-studio-command-line.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">script, see </a><span style=" color: #075FA7;">Build and Run a Sample Project Using the Visual Studio* Command Line</span>.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">When <span class="s18">SETVARS_CONFIG </span>is defined with the absolute pathname to a <span class="s18">setvars </span>configuration file, the <span class="s18">setvars.bat </span>script will be automatically run when Visual Studio is started. In this case, the <span class="s18">setvars.bat </span>script initializes the environment for only those oneAPI tools that are defined in the <span class="s18">setvars </span><a href="#bookmark99" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">configuration file. For more information about how to create a setvars config file, see </a><span style=" color: #075FA7;">Using a Config File with setvars.bat</span>.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">A <span class="s18">setvars </span>configuration file can have any name and can be saved to any location on your hard disk, as long as that location and the file are accessible and readable by Visual Studio. (A plug-in that was added to Visual Studio when you installed the oneAPI tools on your Windows system performs the SETVARS_CONFIG actions; that is why Visual Studio must have access to the location and contents of the <span class="s18">setvars </span>configuration file.)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">If you leave the <span class="s18">setvars </span>config file empty, the <span class="s18">setvars.bat </span>script will initialize your environment for <i>all </i>oneAPI tools that are installed on your system. This is equivalent to defining the <span class="s18">SETVARS_CONFIG </span><a href="#bookmark99" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">variable with an empty string. See </a><span style=" color: #075FA7;">Using a Config File with setvars.bat </span>for details regarding what to put inside of your setvars config file.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Define the SETVARS_CONFIG Environment Variable</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Since the <span class="s18">SETVARS_CONFIG </span>environment variable is not automatically defined during installation, you must add it to your environment before starting Visual Studio (per the rules above). You can define the <span class="s18">SETVARS_CONFIG </span>environment variable using the Windows SETX command or in the Windows GUI tool by typing <span class="s18">“rundll32.exe sysdm.cpl,EditEnvironmentVariables” </span>into the <span class="s18">“Win+R” </span>dialog (use “Win+R” to bring up the dialog).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark15">&zwnj;</a>Use the setvars and oneapi-vars Scripts with Linux*<a name="bookmark102">&zwnj;</a></h4><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The Unified Directory Layout was implemented in 2024.0. If you have multiple toolkit versions installed, the Unified layout adds the ability to ensure your development environment contains the component versions that were released as part of that specific toolkit version.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">With the new Unified Directory Layout, you will see components installed together in a collection of common folders (e.g., bin, lib, include, share, etc.). These common folders are located in a top-level folder that is named for the toolkit version number. For example:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:56.0pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">/opt/intel/oneapi/2024.0/</p><p class="s19" style="text-indent: 0pt;text-align: left;">|-- bin</p><p class="s19" style="text-indent: 0pt;text-align: left;">|-- lib</p><p class="s19" style="text-indent: 0pt;text-align: left;">|-- include</p><p class="s19" style="text-indent: 0pt;text-align: left;">...etc...</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The directory layout that was used prior to 2024.0 is still supported on new and existing installations. This prior layout is called the Component Directory Layout. Now you have the option to use the Component Directory Layout or the Unified Directory Layout.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Differences in Component Directory Layout and Unified Directory Layout</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Most of the component tool folders contain an environment script named <span class="s18">env/vars.sh </span>that configures the environment variables needed by that component to support oneAPI development work. For example, in a default installation, the Intel<span class="s12">® </span>Integrated Performance Primitives (Intel<span class="s12">® </span>IPP) env/vars script on Linux is located at: <span class="s18">/opt/intel/oneapi/ipp/latest/env/vars.sh </span>in the Component Directory Layout. This pattern is shared by all oneAPI components that include an <span class="s18">env\vars </span>setup script.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">In the Component Directory Layout the component <span class="s18">env/vars </span>scripts can be called directly or collectively. To call them collectively, a script named <span class="s18">setvars.sh </span>is provided in the oneAPI installation folder. For example, in a default Component Directory Layout installation on a Linux machine: <span class="s18">/opt/intel/oneapi/setvars.sh</span>. The Unified Directory Layout does not use the <span class="s18">env/vars.sh </span>scripts to initialize the development environment. Instead, each component is “corralled” into shared folders that are common to the components. In other words, each component contributes its header files to a single common <span class="s18">include </span>folder, its library files to a single common <span class="s18">lib </span>folder, and so on.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Advantages of the Unified Directory Layout</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The Unified Directory Layout makes it much easier to switch between different toolkit versions without having to build and maintain <span class="s18">setvars </span>config files or play games with installation of multiple Intel<span class="s12">® </span>oneAPI toolkits. It is also useful for limiting the length of environment variables, especially the PATH variable, on Windows development systems, a troublesome issue for some Windows developers.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The Unified Directory Layout environment variables can only be setup collectively. To initialize the development environment variables a script named <span class="s18">oneapi-vars.sh</span>. In a default Unified Directory Layout installation, on a Linux machine, that script is located here: <span class="s18">/opt/intel/oneapi/&lt;toolkit-version&gt;/ oneapi-vars.sh</span>. The <span class="s18">&lt;toolkit-version&gt; </span>corresponds to the version number of the oneAPI toolkit that you installed.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Example:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">/opt/intel/oneapi/2024.0/oneapi-vars.sh</p><p class="s19" style="text-indent: 0pt;text-align: left;">/opt/intel/oneapi/2024.1/oneapi-vars.sh</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Sourcing the <span class="s18">setvars.sh </span>script without any arguments causes it to locate and source all <span class="s18">&lt;component&gt;/ latest/env/vars.sh </span>scripts in the Component Directory Layout installation. Changes made to the environment by these scripts can be seen by running the <span class="s18">env </span>command after running the environment setup scripts.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Sourcing the <span class="s18">oneapi-vars.sh </span>script without any arguments causes it to configure the environment for the specific toolkit version in which that <span class="s18">oneapi-vars.sh </span>script is located. It will also source any optional <span class="s18">/opt/ intel/oneapi/&lt;toolkit-version&gt;/etc/&lt;component&gt;/vars.sh </span>scripts that are part of that Unified Directory installation. Changes made to the environment by these scripts can be seen by running the env command after sourcing the <span class="s18">oneapi-vars.sh </span>script.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 108%;text-align: left;"><b>NOTE </b>Changes to your environment made by sourcing the <span class="s18">setvars.sh</span>/ <span class="s18">oneapi-vars.sh </span>script (or the individual <span class="s18">env/vars.sh </span>scripts) are not permanent. Those changes only apply to the terminal session in which the <span class="s18">setvars.sh </span>/ <span class="s18">oneapi-vars.sh </span>environment script was sourced.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">To learn more about the differences in setvars and oneapi-vars, see <span style=" color: #075FA7;">Environment Initialization in the Unified Directory Layout</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Command-Line Arguments</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The <span class="s18">setvars.sh </span>/ <span class="s18">oneapi-vars </span>script supports several command-line arguments, which are displayed using the <span class="s18">--help </span>option. For example:</p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Component Directory Layout</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For system-wide installations:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">.        /opt/intel/oneapi/setvars.sh        --help                </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For private installations:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">.         ~/intel/oneapi/setvars.sh         --help                 </span></p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Unified Directory Layout</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For system-wide installations:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">.       /opt/intel/oneapi/&lt;version&gt;/oneapi-vars.sh       --help             </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For private installations:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">.       ~/intel/oneapi/&lt;version&gt;/oneapi-vars.sh       --help             </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The <span class="s18">--config=file </span>argument and the ability to include arguments that will be passed to the <span class="s18">vars.sh </span>scripts that are called by the <span class="s18">setvars.sh </span>/ <span class="s18">oneapi-vars.sh </span>script can be used to customize the environment setup. The <span class="s18">--config=file </span>option is only supported by the <span class="s18">setvars.sh </span>script.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The <span class="s18">--config=file </span>argument provides the ability to limit environment initialization to a specific set of oneAPI components. It also provides a way to initialize the environment for specific component versions. For example, to limit environment setup to just the Intel<span class="s12">® </span>IPP library and the Intel<span class="s12">® </span>oneAPI Math Kernel Library (oneMKL), pass a config file that tells the <span class="s18">setvars.sh </span>/ <span class="s18">oneapi-vars </span>script to only call the <span class="s18">vars.sh </span><a href="#bookmark104" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">environment scripts for those two oneAPI components. More details and examples are provided in </a><a href="#bookmark104" class="a">Use a </a><span style=" color: #075FA7;">Config File for setvars.sh on Linux</span>.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Any extra arguments passed on the <span class="s18">setvars.sh </span>/ <span class="s18">oneapi-vars </span>command line that are not described in the <span class="s18">setvars.sh </span>/ <span class="s18">oneapi-vars </span>help message will be passed to every called <span class="s18">vars.sh </span>script. That is, if the <span class="s18">setvars.sh </span>/ <span class="s18">oneapi-vars </span>script does not recognize an argument, it assumes the argument is meant for use by one or more component scripts and passes those extra arguments to every component <span class="s18">vars.sh </span>script that it calls. The most common extra arguments are <span class="s18">ia32 </span>and <span class="s18">intel64</span>, which are used by the Intel compilers and the Intel<span class="s12">® </span>IPP, oneMKL, and Intel<span class="s12">® </span>oneAPI Threading Building Blocks libraries to specify the application target architecture.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Inspect the individual <span class="s18">vars.sh </span>scripts to determine which, if any, command-line arguments they accept.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">How to Run</p><p class="s14" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Component Directory Layout</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">source                  &lt;install-dir&gt;/setvars.sh                  </span></p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Unified Directory Layout</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">source            &lt;install-dir&gt;/&lt;toolkit-version&gt;/oneapi-vars.sh            </span></p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 1pt;padding-bottom: 3pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">If you are using a non-POSIX shell, such as csh, use the following command:</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Component Directory Layout</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">$  bash  -c  &#39;source  &lt;install-dir&gt;/setvars.sh  ;  exec  csh&#39;            </span></p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Unified Directory Layout</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">$  bash  -c  &#39;source  &lt;install-dir&gt;/&lt;toolkit-version&gt;/oneapi-vars.sh  ;  exec  csh&#39;      </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">If environment variables are set correctly, you will see a confirmation message similar to this:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span/></p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;">If you receive an error message, troubleshoot using the Diagnostics Utility for Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/diagnostic-utility-user-guide/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI Toolkits, which provides system checks to find missing dependencies and permissions errors. </a><span style=" color: #075FA7;">Learn more</span>.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="#bookmark106" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Alternatively, use the </a>modulefiles scripts <span style=" color: #000;">to set up your development environment. The modulefiles scripts work with all Linux shells.</span></p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-programming-guide/top/oneapi-development-environment-setup/use-the-setvars-and-oneapi-vars-scripts-with-linux/use-a-config-file-for-setvars-sh-on-linux-or-macos.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">If you wish to fine tune the list of components and the version of those components, use a </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-programming-guide/top/oneapi-development-environment-setup/use-the-setvars-and-oneapi-vars-scripts-with-linux/use-a-config-file-for-setvars-sh-on-linux-or-macos.html" class="a" target="_blank">setvars config </a>file <span style=" color: #000;">to set up your development environment.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Multiple Runs</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Because many of the individual <span class="s18">env/vars.sh </span>scripts make significant changes to PATH, CPATH, and other environment variables, the top-level <span class="s18">setvars.sh </span>/ <span class="s18">oneapi-vars </span>script will not allow multiple invocations of itself in the same session. This is done to ensure that your environment variables do not become too long due to redundant path references, especially the <span class="s18">$PATH </span>environment variable.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">This behavior can be overridden by passing <span class="s18">setvars.sh </span>/ <span class="s18">oneapi-vars </span>the <span class="s18">--force </span>flag. In this example, the user tries to run <span class="s18">setvars.sh </span>/ <span class="s18">oneapi-vars </span>twice. The second instance is stopped because <span class="s18">setvars.sh </span>/ <span class="s18">oneapi-vars </span>has already been run.</p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Component Directory Layout</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">$ source &lt;install-dir&gt;/setvars.sh initializing oneAPI environment ... (SNIP: lot of output)</p><p class="s19" style="text-indent: 0pt;text-align: left;">oneAPI environment initialized ::</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ source &lt;install-dir&gt;/setvars.sh</p><p class="s19" style="text-indent: 0pt;text-align: left;">WARNING: setvars.sh has already been run. Skipping re-execution. To force a re-execution of setvars.sh, use the &#39;--force&#39; option.</p><p class="s19" style="text-indent: 0pt;text-align: left;">Using &#39;--force&#39; can result in excessive use of your environment variables</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">In the third instance, the user runs <span class="s18">setvars.sh --force </span>and the initialization is successful.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">$ source &lt;install-dir&gt;/setvars.sh --force initializing oneAPI environment ... (SNIP: lot of output)</p><p class="s19" style="text-indent: 0pt;text-align: left;">code-block:: oneAPI environment initialized ::</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Sourcing setvars.sh with the –force argument may lead to argument pollution with bash version 3.x and 4.x, as shown below:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:89.7pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">source &lt;install-dir&gt;/setvars.sh --force initializing oneAPI environment ... (SNIP: lot of output)</p><p class="s19" style="text-indent: 0pt;text-align: left;">oneAPI environment initialized ::</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ echo ${@}</p><p class="s19" style="text-indent: 0pt;text-align: left;">advisor=latest ccl=latest compiler=latest dal=latest debugger=latest dev-utilities=latest dnnl=latest dpcpp-ct=latest dpl=latest ipp=latest ippcp=latest mkl=latest mpi=latest tbb=latest vtune=latest</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><b>Note</b>: This is not an issue when <span class="s18">setvars.sh </span>is sourced with bash version 5.x, zsh, ksh or dash.</p><p style="padding-top: 6pt;padding-bottom: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 153%;text-align: left;">To work around this issue pass the shell command-line options via the <span class="s18">SETVARS_ARGS </span>environment variable. For example:</p><div class="textbox" style="background:#F0F0F0;display:block;min-height:67.3pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">$ SETVARS_ARGS=&quot;--force&quot; source &lt;install-dir&gt;/setvars.sh initializing oneAPI environment ...</p><p class="s19" style="text-indent: 0pt;text-align: left;">(SNIP: lot of output)</p><p class="s19" style="text-indent: 0pt;text-align: left;">oneAPI environment initialized ::</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ echo ${@}</p><p class="s19" style="text-indent: 0pt;text-align: left;">$</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Unified Directory Layout</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">$ source &lt;install-dir&gt;/&lt;version&gt;/oneapi-vars.sh initializing oneAPI environment ...</p><p class="s19" style="text-indent: 0pt;text-align: left;">(SNIP: lot of output)</p><p class="s19" style="text-indent: 0pt;text-align: left;">oneAPI environment initialized ::</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ source &lt;install-dir&gt;/&lt;toolkit-version&gt;/oneapi-vars.sh</p><p class="s19" style="text-indent: 0pt;text-align: left;">WARNING: setvars.sh has already been run. Skipping re-execution. To force a re-execution of setvars.sh, use the &#39;--force&#39; option.</p><p class="s19" style="text-indent: 0pt;text-align: left;">Using &#39;--force&#39; can result in excessive use of your environment variables</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">In the third instance, the user runs <span class="s18">oneapi-vars.sh --force </span>and the initialization is successful.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">$ source &lt;install-dir&gt;/ ``oneapi-vars.sh`` --force initializing oneAPI environment ...</p><p class="s19" style="text-indent: 0pt;text-align: left;">(SNIP: lot of output)</p><p class="s19" style="text-indent: 0pt;text-align: left;">oneAPI environment initialized ::</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Sourcing <span class="s18">oneapi-vars.sh </span>with the <span class="s18">--force </span>argument may lead to argument pollution with bash version</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">3.x and 4.x, as shown below:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:89.7pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">$ source &lt;install-dir&gt;/&lt;toolkit-version&gt;/oneapi-vars.sh --force initializing oneAPI environment ...</p><p class="s19" style="text-indent: 0pt;text-align: left;">(SNIP: lot of output)</p><p class="s19" style="text-indent: 0pt;text-align: left;">oneAPI environment initialized ::</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ echo ${@}</p><p class="s19" style="text-indent: 0pt;text-align: left;">advisor=latest ccl=latest compiler=latest dal=latest debugger=latest dev-utilities=latest dnnl=latest dpcpp-ct=latest dpl=latest ipp=latest ippcp=latest mkl=latest mpi=latest tbb=latest vtune=latest</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><b>Note</b>: This is not an issue when <span class="s18">oneapi-vars.sh </span>is sourced with bash version 5.x, zsh, ksh or dash.</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To work around this issue pass the shell command-line options via the <span class="s18">SETVARS_ARGS </span>environment variable.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark104">&zwnj;</a>For example:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:67.3pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ SETVARS_ARGS=&quot;--force&quot; source &lt;install-path&gt;/&lt;toolkit-version&gt;/oneapi-vars.sh</p><p class="s19" style="text-indent: 4pt;text-align: left;">.. code-block:: initializing oneAPI environment ... (SNIP: lot of output)</p><p class="s19" style="padding-left: 4pt;text-indent: 0pt;text-align: left;">.. code-block:: oneAPI environment initialized ::</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ echo ${@}</p><p class="s19" style="text-indent: 0pt;text-align: left;">$</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Environment Initialization in the Unified Directory Layout</p><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="#bookmark102" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">The Unified Directory Layout was implemented with the 2024.0 release. If you are unfamiliar with the change, please see </a>Use the setvars and oneapi-vars Scripts with Linux <span style=" color: #000;">at the top of this page.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Initializing the environment for a “unified” directory is done by the <span class="s18">oneapi-vars.sh </span>script, not the</p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">setvars.sh <span class="p">script. The usage of oneapi-vars is similar to setvars, but there are some subtle differences.</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The key difference between the setvars script and the oneapi-vars script is that the setvars script does not define any environment variables (other than ONEAPI_ROOT) and the oneapi-vars script defines the common environment variables.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">In the Component Directory Layout, each component is responsible for defining the environment variables needed in order to function. For example, in the Component Directory Layout each component adds its linkable library folders to <span class="s18">LD_LIBRARY_PATH </span>and include headers to <span class="s18">CPATH</span>, etc. The components do this via their individual vars scripts, which are always located in:</p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 5pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">$ONEAPI_ROOT/&lt;component-name&gt;/&lt;component-version&gt;/env/vars.sh          </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The Unified Directory Layout combines the externally facing include, lib, and bin folders into a set of common folders. In this scenario, the top-level oneapi-vars script defines the environment variables that are needed to locate these common folders. For example, setvars will define LD_LIBRARY_PATH as $ONEAPI_ROOT/lib and CPATH as $ONEAPI_ROOT/include and so on.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Modulefiles continue to be supported in the 2024.0 release, and can be used as an alternative to using setvars.sh to initialize an environment setup. Modulefiles scripts are only supported on Linux.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">ONEAPI_ROOT Environment Variable</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The <span class="s18">ONEAPI_ROOT </span>variable is set by the top-level <span class="s18">setvars.sh </span>and <span class="s18">oneapi-vars.sh </span>script when either script is sourced. If there is already a <span class="s18">ONEAPI_ROOT </span>environment variable defined, <span class="s18">setvars.sh </span>overwrites it in the terminal session in which you sourced the <span class="s18">setvars.sh </span>or <span class="s18">oneapi-vars.sh </span>script. This variable is primarily used by the <span class="s18">oneapi-cli </span>sample browser and the Eclipse* and Visual Studio Code* sample browsers to help them locate oneAPI tools and components, especially for locating the <span class="s18">setvars.sh </span>script if the <span class="s18">SETVARS_CONFIG </span>feature has been enabled. For more information about the <span class="s18">SETVARS_CONFIG </span><a href="#bookmark105" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">feature, see </a><a href="#bookmark105" class="a">Automate the setvars.sh Script with </a><span style=" color: #075FA7;">Eclipse*</span>.</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">With the 2024.0 release, the installer does not add the <span class="s18">ONEAPI_ROOT </span>variable to the environment. To add it to your default environment, define the variable in your local shell initialization file(s) or in the</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">system’s <span class="s18">/etc/environment </span>file.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark16">&zwnj;</a>Use a Config File for setvars sh on Linux<a name="bookmark103">&zwnj;</a></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;"><b>NOTE </b>Starting with the 2024.0 release, macOS is no longer supported in Intel<span class="s12">® </span>oneAPI Toolkits and components. Several Intel-led open source developer tool projects will continue supporting macOS on Apple Silicon including oneAPI Threading Building Blocks (oneTBB) and Intel<span class="s12">® </span>Implicit SPMD Program Compiler. We welcome the opportunity to work with contributors to expand support to additional tools in the future.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">There are two methods for customizing your environment in Linux*:</p><ul id="l28"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Use a setvars.sh configuration file, as described on this page</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="#bookmark106" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Use </a><a href="#bookmark106">modulefiles</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;"><b>NOTE </b>Configuration files can only be used with <span class="s18">setvars.sh </span>in the Component Directory Layout. The Unified Directory Layout utilizes <span class="s18">oneapi-vars.sh</span><a href="#bookmark102" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">, which does not support configuration files. To learn more about the layouts, see </a><a href="#bookmark102">Use the setvars and oneapi-vars Scripts with Linux*</a></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">The <span class="s18">setvars.sh </span>script sets environment variables for use with the oneAPI toolkits by sourcing each of the</p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">&lt;install-dir&gt;/latest/env/vars.sh <span class="p">scripts found in the respective oneAPI folders. Unless you configure your Linux system to source the </span>setvars.sh <a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-base-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">script automatically, it must be sourced every time a new terminal window is opened for command line development, or prior to launching Eclipse* or any other C/C++ IDE or editor you use for C/C++ development. For more information, see </a><span class="s13">Configure Your System</span><span class="p">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The procedure below describes how to use a configuration file to manage environment variables.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Versions and Configurations</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Some oneAPI tools support installation of multiple versions. For those tools that do support multiple versions, the directory is organized like this:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">intel/oneapi/compiler/</p><p class="s19" style="text-indent: 0pt;text-align: left;">|-- 2021.1.1</p><p class="s19" style="text-indent: 0pt;text-align: left;">|-- 2021.2.0</p><p class="s19" style="text-indent: 0pt;text-align: left;">`-- latest -&gt; 2021.2.0</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For example:</p><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Multiple versions and environmental variables</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">For all tools, there is a symlink named <span class="s18">latest </span>that points to the latest installed version of that component; and the <span class="s18">vars.sh </span>script located in the <span class="s18">latest/env/ </span>folder is what the <span class="s18">setvars.sh </span>sources by default.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">If required, <span class="s18">setvars.sh </span>can be customized to point to a specific directory by using a configuration file.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">–config Parameter</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The top level <span class="s18">setvars.sh </span>script accepts a <span class="s18">--config </span>parameter that identifies your custom <b>config.txt </b>file.</p><ul id="l29"><li data-list-text="&gt;"><p style="padding-top: 8pt;padding-left: 21pt;text-indent: -9pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">source    &lt;install-dir&gt;/setvars.sh    --config=&quot;full/path/to/your/config.txt&quot;       </span></p></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The name of your configuration file can have any name you choose. You can create many config files to setup a variety of development or test environments. For example, you might want to test the latest version of a library with an older version of a compiler; use a setvars config file to manage such a setup.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Config File Sample</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The examples below show a simple example of the config file:</p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Load Latest of Everything but…</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">mkl=1.1 dldt=exclude</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Exclude Everything but…</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">default=exclude mkl=1.0 ipp=latest</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The configuration text file must follow these requirements:</p><ul id="l30"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">a newline delimited text file</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">each line consists of a single <span class="s18">&quot;key=value&quot; </span>pair</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">&quot;key&quot; <span class="p">names a component folder in the top-level set of oneAPI directories (the folders found in the</span></p><p class="s18" style="padding-left: 19pt;text-indent: 0pt;line-height: 108%;text-align: left;">$ONEAPI_ROOT <span class="p">directory). If a </span>&quot;key&quot; <span class="p">appears more than once in a config file, the last </span>&quot;key&quot; <span class="p">wins and any prior keys with the same name are ignored.</span></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;">“<span class="s18">value</span>” names a version directory that is found at the top-level of the component directory. This includes any symlinks (such as <span class="s18">latest</span>) that might be present at that level in the component directory.</p><ul id="l31"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 34pt;text-indent: -14pt;line-height: 108%;text-align: left;">OR <span class="s18">&quot;value&quot; </span>can be <span class="s18">&quot;exclude&quot;</span>, which means the named key will NOT have its <span class="s18">env/vars.sh </span>script sourced by the <span class="s18">setvars.sh </span>script.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The <span class="s18">&quot;key=value&quot; </span>pair <span class="s18">&quot;default=exclude&quot; </span>is a special case. When included, it will exclude sourcing ALL</p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">env/vars.sh <span class="p">scripts, except those that are listed in the config file. See the examples below.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Further Customization of Config Files</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The config file can be used to exclude specific components, include specific component versions or only include specific component versions that are named after a <span class="s18">&quot;default=exclude&quot; </span>statement.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">By default, <span class="s18">setvars.sh </span>will process the <span class="s18">latest </span>version of each <span class="s18">env/vars.sh </span>script.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The sample below shows two versions of Intel<span class="s12">® </span>oneAPI Math Kernel Library (oneMKL) installed: 2021.1.1 and 2021.2.0. The <span class="s18">latest </span>symlink points to the 2021.2.0 folder because it is the latest version. By default <span class="s18">setvars.sh </span>will source the 2021.2.0 <span class="s18">vars.sh </span>script in the <span class="s18">mkl </span>folder because that is the folder that <span class="s18">latest </span>points to.</p><p class="s14" style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Two versions of oneMKL installed</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Specify a Specific Version</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To direct <span class="s18">setvars.sh </span>to source the <span class="s18">&lt;install-dir&gt;/mkl/2021.1.1/env/vars.sh </span>script, add</p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">mkl=2021.1.1 <span class="p">to your config file.</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">This instructs <span class="s18">setvars.sh </span>to source on the <span class="s18">env/vars.sh </span>script located in the <span class="s18">2021.1.1 </span>version folder inside the <span class="s18">mkl </span>directory. For other installed components, <span class="s18">setvars.sh </span>will source the <span class="s18">env/vars.sh </span>script located in the latest version folder.</p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Exclude Specific Components</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To exclude a component, use the following syntax:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">&lt;key&gt;=exclude                       </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;">For example, to exclude Intel<span class="s12">® </span>Integrated Performance Primitives (Intel <span class="s12">® </span>IPP) , but include the 2021.1.1 version of Intel<span class="s12">® </span>oneAPI Math Kernel Library (oneMKL):</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">mkl=2021.1.1</p><p class="s19" style="text-indent: 0pt;text-align: left;">ipp=exclude</p></div></li></ul></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">In this example:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l32"><li data-list-text="•"><p class="s18" style="padding-left: 19pt;text-indent: -14pt;text-align: left;">setvars.sh <span class="p">WILL source the oneMKL 2021.1.1 </span>env/vars.sh <span class="p">script</span></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><span class="s18">setvars.sh </span>WILL NOT source any Intel<span class="s12">® </span>IPP <span class="s18">env/vars.sh </span>script files</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">setvars.sh <span class="p">WILL source the latest version of the remaining </span>env/vars.sh <span class="p">script files</span></p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">Include Specific Components</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: justify;">To source a specific list of component <span class="s18">env/vars.sh </span>scripts, you must first exclude all <span class="s18">env/vars.sh </span>scripts. Then add back the list of components to be sourced by <span class="s18">setvars.sh</span>. Use the following syntax to exclude all component <span class="s18">env/vars.sh </span>scripts from being sourced:</p><p style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">default=exclude                      </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">For example, to have <span class="s18">setvars.sh </span>source only the oneMKL and Intel IPP component <span class="s18">env/vars.sh </span>scripts, use this config file:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">default=exclude mkl=2021.1.1</p><p class="s19" style="text-indent: 0pt;text-align: left;">ipp=latest</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">In this example:</p><ul id="l33"><li data-list-text="•"><p class="s18" style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">setvars.sh <span class="p">WILL source the oneMKL 2021.1.1 </span>env/vars.sh <span class="p">script</span></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><span class="s18">setvars.sh </span>WILL source the latest version of the Intel<span class="s12">® </span>IPP <span class="s18">env/vars.sh </span>script</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">setvars.sh <span class="p">WILL NOT source the </span>env/vars.sh <span class="p">script for any other components</span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark17">&zwnj;</a>Automate the setvars sh Script with Eclipse*<a name="bookmark105">&zwnj;</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The <span class="s18">setvars.sh </span>script sets up the environment variables needed to use the Intel<span class="s12">® </span>oneAPI toolkits. This script must be run every time a new terminal window is opened for command-line development. The <span class="s18">setvars.sh </span>script can also be run automatically when Eclipse* is started. You can configure this feature to instruct the <span class="s18">setvars.sh </span>script to set up a specific set of oneAPI tools by using the <span class="s18">SETVARS_CONFIG </span>environment variable.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To learn more about how <span class="s18">setvars.sh </span><a href="#bookmark102" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">set environment variables, see </a><a href="#bookmark102" class="a">Use the setvars and oneapi-vars </a><a href="#bookmark102">Scripts with Linux*</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">SETVARS_CONFIG Environment Variable States</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The <span class="s18">SETVARS_CONFIG </span>environment variable enables automatic configuration of the oneAPI development environment when you start your instance of Eclipse IDE for C/C++ Developers. The variable has three conditions or states:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Undefined (the <span class="s18">SETVARS_CONFIG </span>environment variable does not exist)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Defined but empty (the value contains nothing or only whitespace)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Defined and points to a <span class="s18">setvars.sh </span>configuration file</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">If <span class="s18">SETVARS_CONFIG </span>is undefined or if it exists but has no value (or contains only whitespace), the <span class="s18">setvars.sh </span>script will be automatically run when Eclipse is started. In this case, the <span class="s18">setvars.sh </span>script initializes the environment for <i>all </i>oneAPI tools that are installed on your system. For more information about running the <span class="s18">setvars.sh </span><a href="https://www.intel.com/content/www/us/en/docs/oneapi-base-toolkit/get-started-guide-linux/2024-0/run-a-sample-project-using-an-ide.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">script, see </a><span style=" color: #075FA7;">Build and Run a Sample Project Using Eclipse</span>.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">When <span class="s18">SETVARS_CONFIG </span>is defined with the absolute pathname to a <span class="s18">setvars </span>configuration file, the <span class="s18">setvars.sh </span>script will be automatically run when Eclipse is started. In this case, the <span class="s18">setvars.sh </span>script initializes the environment for only those oneAPI tools that are defined in the <span class="s18">setvars </span><a href="#bookmark104" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">configuration file. For more information about how to create a setvars config file, see </a><a href="#bookmark104" class="a">Use a Config File for setvars.sh or oneapi- </a><span style=" color: #075FA7;">vars.sh on Linux</span>.</p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 108%;text-align: justify;"><b>NOTE </b>The default <span class="s18">SETVARS_CONFIG </span>behavior in Eclipse is different than the behavior described for Visual Studio on Windows. When starting Eclipse, automatic execution of the <span class="s18">setvars.sh </span>script is always attempted. When starting Visual Studio automatic execution of the <span class="s18">setvars.bat </span>script it is only attempted if the <span class="s18">SETVARS_CONFIG </span>environment variable has been defined.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">A <span class="s18">setvars </span>configuration file can have any name and can be saved to any location on your hard disk, as long as that location and the file are accessible and readable by Eclipse. (A plug-in that was added to Eclipse when you installed the oneAPI tools on your LInux system performs the <span class="s18">SETVARS_CONFIG </span>actions; that is why Eclipse must have access to the location and contents of the <span class="s18">setvars </span>configuration file.)</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">If you leave the <span class="s18">setvars </span>config file empty, the <span class="s18">setvars.sh </span>script will initialize your environment for <i>all </i>oneAPI tools that are installed on your system. This is equivalent to defining the <span class="s18">SETVARS_CONFIG </span><a href="#bookmark104" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">variable with an empty string. See </a><span style=" color: #075FA7;">Use a Config File for setvars.sh or oneapi-vars.sh on Linux </span>for details regarding what to put inside of your setvars config file.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Define the SETVARS_CONFIG Environment Variable</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Since the <span class="s18">SETVARS_CONFIG </span>environment variable is not automatically defined during installation, you must add it to your environment before starting Eclipse (per the rules above). There are a variety of places to define the <span class="s18">SETVARS_CONFIG </span>environment variable:</p></li><li data-list-text="•"><p class="s18" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">/etc/environment</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">/etc/profile</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">~/.bashrc</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">and so on…</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The list above shows common places to define environment variables on a Linux system. Ultimately, where you choose to define the SETVARS_CONFIG environment variable depends on your system and your needs.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark18">&zwnj;</a>Use Environment Modulefiles with Linux*<a name="bookmark106">&zwnj;</a></h4><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Modulefiles can be used to setup your environment, allowing you to specify the precise versions of components you wish to use.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">There are two methods for customizing your environment variables in Linux*:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Use modulefiles, as described on this page</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="#bookmark104" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Use a </a><a href="#bookmark104">setvars.sh configuration file</a></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Most of the component tool folders contain one or more modulefile scripts that configure the environment variables needed by that component to support development work. Modulefiles are an alternative to using the <span class="s18">setvars.sh </span>script to set up the development environment. Because modulefiles do not support arguments, multiple modulefiles are available for oneAPI tools and libraries that support multiple configurations (such as a 32-bit configuration and a 64-bit configuration).</p><p style="padding-top: 11pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-left: 35pt;text-indent: 0pt;text-align: left;"><b>NOTE </b>The modulefiles provided with the Intel<span class="s12">® </span>oneAPI toolkits are compatible with the Tcl Environment Modules (Tmod) and Lua Environment Modules (Lmod). The following minimum versions are supported:</p><ul id="l34"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">Tmod version 4.2</p></li><li data-list-text="•"><p style="padding-left: 49pt;text-indent: -14pt;text-align: left;">Tcl version 8.4</p></li><li data-list-text="•"><p style="padding-left: 49pt;text-indent: -14pt;text-align: left;">Lmod version 8.7.44</p><p style="padding-top: 5pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">Test which version of Tmod is installed on your system using the following command:</p><p style="padding-top: 8pt;padding-left: 41pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">module                    --version                    </span></p><p style="padding-top: 5pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">Test which version of Tcl is installed on your system with the following commands:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:456.7pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ tclsh</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ puts $tcl_version 8.6</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ exit</p></div></li></ul></li></ul><p style="padding-left: 41pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">Each modulefile automatically verifies the Tcl version on your system when it runs, but it does not test the version of Tmod on your system.</p><p class="s13" style="padding-top: 5pt;padding-left: 35pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/using-environment-modules-with-the-intel-development-tools.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">If your modulefile version is not supported (older than 4.2), a workaround may be possible. See </a><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/using-environment-modules-with-the-intel-development-tools.html" class="a" target="_blank">Using </a>Environment Modules with Intel Development Tools <span style=" color: #000;">for more details.</span></p><p style="padding-top: 5pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">As of the oneAPI 2024.0 release, the <span class="s18">icc </span>modulefile has been removed because the Intel<span class="s12">® </span>Classic Compiler has been discontinued. Please use the Intel<span class="s12">® </span>oneAPI C/C++ Complier (<span class="s18">icx </span>and <span class="s18">icpx</span>) instead. The <span class="s18">ifort </span>compiler is still available, but you are encouraged to use the equivalent Intel<span class="s12">® </span>oneAPI Fortran Compiler (<span class="s18">ifx</span>).</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Modulefile Auto-load</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The “auto-load” feature in Environment Modules (Tmod) was introduced in version 4.2 of Modulefiles as an experimental feature. The auto-load feature was elevated to a standard feature in the 5.0 release. With the 2024.0 release of Intel oneAPI toolkits, automatic loading of dependent modulefiles now relies on the auto- load feature. If you are using version 4.x of Environment Modules, the auto-load feature of dependent modulefiles (those referenced by the prereq command) is disabled by default. Version 5.x enables auto-load of dependent modules by default.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">To control the auto-load function, the <span class="s18">MODULES_AUTO_HANDLING </span>environment variable can be used to direct modulefiles to auto-load all referenced prereq modulefiles. This behavior can be temporarily overridden by using the <span class="s18">--auto </span>command-line option.</p><ul id="l35"><li data-list-text="•"><p class="s18" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">MODULES_AUTO_HANDLING=1 <span class="p">enables auto-loading via the prereq command.</span></p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">MODULES_AUTO_HANDLING=0 <span class="p">disables auto-loading via the prereq command.</span></p></li></ul><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">If you experience an error message with the text <span class="s18">HINT: the following module must be loaded first</span>, you may need to either add the <span class="s18">MODULES_AUTO_HANDLING=1 </span>environment variable or configure your Modules Environment to set the auto_handling configuration to “1” in order to enable automatic loading of prereq commands.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:89.7pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ module -V</p><p class="s19" style="text-indent: 0pt;text-align: left;">Modules Release 4.4.1 (2020-01-03)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">$ module use /opt/intel/oneapi/2024.1/etc/modulefiles/</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ module load compiler Loading compiler/2024.1.0</p><p class="s19" style="padding-left: 19pt;text-indent: -10pt;text-align: left;">ERROR: compiler/2024.1.0 cannot be loaded due to missing prereq. HINT: the following module must be loaded first: tbb</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">This issue can be resolved using one of the methods below.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Run command to configure auto_handling to be 1:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ module config auto_handling 1</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ module load compiler Loading compiler/2024.1.0</p><p class="s19" style="text-indent: 0pt;text-align: left;">Loading requirement: tbb/2021.12 compiler-rt/2024.1.0 oclfpga/2024.1.0</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Set MODULES_AUTO_HANDLING=1:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">$ export MODULES_AUTO_HANDLING=1 module load compiler</p><p class="s19" style="text-indent: 0pt;text-align: left;">Loading compiler/2024.1.0</p><p class="s19" style="text-indent: 0pt;text-align: left;">Loading requirement: tbb/2021.12 compiler-rt/2024.1.0 oclfpga/2024.1.0</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Load dependencies manually:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:56.0pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">$ module load tbb compiler-rt oclfpga compiler --verbose Loading tbb/2021.12</p><p class="s19" style="text-indent: 0pt;text-align: left;">Loading compiler-rt/2024.1.0 Loading oclfpga/2024.1.0 Loading compiler/2024.1.0</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://modules.readthedocs.io/en/latest/module.html#envvar-MODULES_AUTO_HANDLING" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For more details, see </a>MODULES_AUTO_HANDLING<span style=" color: #000;">.</span></p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Load Everything Modulefile</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">As of the 2024.0 release, there is a “load everything” modulefile named <span class="s18">oneapi </span>located in <span class="s18">intel/oneapi/ 2024.0</span>. The <span class="s18">oneapi </span>modulefile loads all available modulefiles and ensures that all of the prereq modules are also loaded in the right order without relying on the <span class="s18">MODULES_AUTO_HANDLING=1 </span>environment variable described above. It should be usable with the Lmod modulefiles system. If your installation does not include the <span class="s18">intel/oneapi/2024.0 </span>directory install the product with a toolkit installer, such as the Intel oneAPI Base Toolkit and/or the Intel<span class="s12">® </span>HPC Toolkit (use the customize option if you do not wish to install the entire toolkit). The key feature of the <span class="s18">oneapi </span>modulefile is that it only loads those modulefiles that are specific to the toolkit version (e.g., intel/oneapi/2024.0 or intel/oneapi/2024.1, etc.).</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Create a Custom Modulefile To Load Specific Modulefiles</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">To further control which modulefiles are loaded, you can create a “meta” modulefile that loads a specific set of modulefiles (and their prerequisites). For example, if you have a need for an environment that only sets up the Intel compiler, you might create something similar to this:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">module load tbb</p><p class="s19" style="text-indent: 0pt;text-align: left;">module load compiler-rt module load oclfpga module load compiler</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s17" style="padding-top: 12pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Location of Modulefile Scripts</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The oneAPI modulefile scripts are located in a modulefiles directory inside each component folder (similar to where the individual vars scripts are located). For example, in a default installation for 2024.0 and later oneAPI Toolkit releases, the <span class="s18">compiler </span>modulefiles script(s) are in the <span class="s18">/opt/intel/compiler/&lt;component- version&gt;/etc/modulefiles/ </span>directory. In 2023 or earlier oneAPI Toolkit releases, the <span class="s18">compiler </span>modulefiles script(s) are in the <span class="s18">/opt/intel/compiler/&lt;component-version&gt;/modulefiles/ </span>directory.</p><p style="padding-top: 11pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s18" style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 108%;text-align: left;"><span class="s14">NOTE</span>&lt;component-version&gt; <span class="p">is the version number of a component (a library or tool). You may have multiple components installed side-by-side on your development system (e.g., </span>compiler/2023.1<span class="p">, </span>compiler/2023.2<span class="p">, </span>compiler/2024.0<span class="p">, etc.). The Toolkit version, which is the version of a collection of components, may be different than the component version that was delivered with that Toolkit.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Due to how oneAPI component folders are organized on the disk, it can be difficult to use the oneAPI modulefiles directly where they are installed. Therefore, a special <span class="s18">modulefiles-setup.sh </span>script is provided in the oneAPI installation folder to make it easier to work with the oneAPI modulefiles. In a default installation, that setup script is located here: <span class="s18">/opt/intel/oneapi/modulefiles-setup.sh</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The <span class="s18">modulefiles-setup.sh </span>script locates all modulefile scripts that are part of your oneAPI installation and organizes them into a single directory of versioned modulefiles scripts.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Each of these versioned modulefiles scripts is a symlink that points to the modulefiles located by the <span class="s18">modulefiles-setup.sh </span>script. Each component folder includes (at minimum) a “latest” version modulefile that will be selected, by default, when loading a modulefile without specifying a version label. If you use the</p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">--ignore-latest <span class="p">option when running the </span>modulefiles-setup.sh <span class="p">script, the modulefile with the highest version (per semver rules) will be loaded if no version is specified by the </span>module_load <span class="p">command.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Alternatively, on a 2024.0 or later toolkit installation, within the Unified Directory Layout, you will find a modulefiles folder that contains all the component modulefiles associated with that toolkit version. For example, if you install the 2024.0 Intel<span class="s12">® </span>oneAPI Base Toolkit into the default location, you will find a preconfigured and ready to use collection of the 2024.0 Base Toolkit modulefiles located in the <span class="s18">/opt/intel/ oneapi/2024.0/etc/modulefiles </span>folder, which you can add to your modulefile setup by adding that folder to your MODULEPATH environment variable, or by running the <span class="s18">module use </span>command and specify that pre- configured modulefile folder. Installing the 2024.0 Intel<span class="s12">® </span>HPC Toolkit will add additional modulefiles to that same location, because the two toolkits are of the same version (in this case, 2024.0).</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Within the pre-configured toolkit modulefiles folder there is a modulefile named <span class="s18">oneapi </span>that will load the 64- bit component modulefiles that belong to that toolkit version. The <span class="s18">oneapi </span>modulefile is a convenience modulefile, it is not required to use the individual modulefiles. Also, the <span class="s18">oneapi </span>modulefile will not work as expected within a folder created by the <span class="s18">modulefiles-setup.sh </span>script.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Creating the <span class="s23">modulefiles </span>Directory</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Run the <span class="s18">modulefiles-setup.sh </span>script.</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">By default, the <span class="s18">modulefiles-setup.sh </span>script creates a folder named modulefiles in the oneAPI toolkit installation folder. If your oneAPI installation folder is not writeable, use the <span class="s18">--output-dir=&lt;path-to- folder&gt; </span>option to create the modulefiles folder in a writeable location. Run <span class="s18">modulefiles-setup.sh -- help </span>for more information about this and other modulefiles-setup.sh script options.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Running the <span class="s18">modulefiles-setup.sh </span>script creates the <span class="s18">modulefiles </span>output folder, which is organized like the following example (the precise list of modulefiles depends on your installation). In this example, there is one modulefile for configuring the Intel<span class="s12">® </span>Advisor environment and two modulefiles for configuring the compiler environment (the compiler modulefile configures the environment for all Intel compilers). If you follow the latest symlinks, they point to the highest version modulefile, per semver rules.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Update your MODULEPATH environment variable to include to the <span class="s18">modulefiles </span>output folder that was created by the <span class="s18">modulefiles-setup.sh </span>script or run the <span class="s18">module use &lt;folder_name&gt; </span>command.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Installing the Tcl Modulefiles Environment onto Your System</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The instructions below will help you quickly get started with the Environment Modules utility on Ubuntu*. For full details regarding installation and configuration of the <span class="s18">module </span><a href="http://modules.sourceforge.net/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">utility, see </a><span style=" color: #075FA7;">http://modules.sourceforge.net/</span>.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Set your environment:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ sudo apt update</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ sudo apt install tcl</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ sudo apt install environment-modules</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Confirm that the local copy of <span class="s18">tclsh </span>is new enough (see the beginning of this page for a list of supported versions):</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">$ echo &#39;puts [info patchlevel] ; exit 0&#39; | tclsh 8.6.8</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Test the <span class="s18">module </span>installation by initializing the <span class="s18">module </span>alias.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ source /usr/share/modules/init/sh</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ module</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 11pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 109%;text-align: left;"><b>NOTE </b>Initialization of the Modulefiles environment in POSIX-compatible shells should work with the source command shown above. However, the precise location and name of the modulefiles init folder does vary with the Linux distribution. Most installations of Environment Modules will automatically source the modulefiles initialization script: <span class="s18">/etc/profile.d/modules.sh</span>. You can test for proper initialization of the module command by typing the <span class="s18">module --version </span>command which should result in a response similar to: <span class="s18">Modules Release 4.4.1 (2020-01-03)</span>. At this point, the system should be ready to use the module command as shown in the following section.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Getting Started with the <span class="s23">modulefiles-setup.sh </span>Script</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following example assumes you have:</p><ul id="l36"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">installed <span class="s18">tclsh </span>on to the Linux development system</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">installed the Environment Modules utility (i.e., <span class="s18">module</span>) onto the system</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">sourced the <span class="s18">.../modules/init/sh </span>(or equivalent) module init command</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s18" style="text-indent: 0pt;text-align: left;">$ cd &lt;oneapi-root-folder&gt;</p><p class="s18" style="text-indent: 0pt;text-align: left;">$ ./modulefiles-setup.sh</p><p class="s18" style="text-indent: 0pt;text-align: left;">$ module use modulefiles</p><p class="s18" style="text-indent: 0pt;text-align: left;">$ module avail</p><p class="s18" style="text-indent: 0pt;text-align: left;">$ module load tbb</p><p class="s18" style="text-indent: 0pt;text-align: left;">$ module list</p><p style="text-indent: 0pt;text-align: left;"/><p class="s18" style="text-indent: 0pt;text-align: left;"># cd to the oneapi_root installation directory # run the modulefiles setup script</p><p class="s18" style="text-indent: 0pt;text-align: left;"># use the modulefiles folder created above # will show tbb/X.Y, etc.</p><p class="s18" style="text-indent: 0pt;text-align: left;"># loads tbb/X.Y module</p><p class="s18" style="text-indent: 0pt;text-align: left;"># should list the tbb/X.Y module you just loaded</p><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="•"><p style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 159%;text-align: left;">installed the oneAPI toolkits required for your oneAPI development Navigate to the installation directory, and load <span class="s18">tbb</span>:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;">Use the <span class="s18">env </span>command to inspect the environment and look for the changes that were made by the modulefile you loaded.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:11.2pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ env | grep -i &quot;intel&quot;</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;"/><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">For example, if you loaded the <span class="s18">tbb modulefile</span>, the command will show you some of the env changes made by that <span class="s18">modulefile</span>.</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s18" style="text-indent: 0pt;text-align: left;">$ module unload tbb</p><p class="s18" style="text-indent: 0pt;text-align: left;">$ module list</p><p style="text-indent: 0pt;text-align: left;"/><p class="s18" style="text-indent: 0pt;text-align: left;"># removes tbb/X.Y changes from the environment</p><p class="s18" style="text-indent: 0pt;text-align: left;"># should no longer list the tbb/X.Y env var module</p><p style="text-indent: 0pt;text-align: left;"/><ul id="l37"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Unload <span class="s18">tbb</span>:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 1pt;padding-bottom: 3pt;padding-left: 35pt;text-indent: 0pt;line-height: 108%;text-align: left;"><b>NOTE </b>A <span class="s18">modulefile </span>is a script, but it does not need to have the ‘x’ (executable) permission set, because it is loaded and interpreted by the “module” interpreter that is installed and maintained by the end-user. Installation of the oneAPI toolkits do not include the <span class="s18">modulefile </span>interpreter. It must be installed separately. Likewise, <span class="s18">modulefiles </span>do not require that the ‘w’ permission be set, but they must be readable (ideally, the ‘r’ permission is set for all users).</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Versioning</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s18" style="text-indent: 0pt;text-align: center;">$ module avail</p><p class="s18" style="text-indent: 0pt;text-align: center;">modulefiles</p><p class="s18" style="text-indent: 0pt;text-align: center;">ipp/1.1 ipp/1.2 compiler/1.0 compiler32/1.0</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The oneAPI toolkit installer uses version folders to allow oneAPI tools and libraries to exist in a side-by-side layout. These versioned component folders are used by the <span class="s18">modulefiles-setup.sh </span>script to create the versioned <span class="s18">modulefiles</span>. The script organizes the symbolic links it creates in the <span class="s18">modulefiles </span>output folder as <span class="s18">&lt;modulefile-name&gt;/version</span>, so that each respective <span class="s18">modulefile </span>can be referenced by version when using the module command.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Multiple modulefiles</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">A tool or library may provide multiple <span class="s18">modulefiles </span>within its <span class="s18">modulefiles </span>folder. Each becomes a loadable module. They will be assigned a version per the component folder from which they were extracted.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">How <span class="s23">modulefiles </span>Are Set Up in oneAPI</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Symbolic links are used by the <span class="s18">modulefiles-setup.sh </span>script to gather all the available <span class="s18">modulefiles </span>into a single <span class="s18">modulefiles </span>folder. The actual <span class="s18">modulefile </span>scripts are not moved or modified. The <span class="s18">$</span></p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">{ModulesCurrentModulefile} <span class="p">variable points to the symlink to each </span>modulefile<span class="p">, not to the actual </span>modulefile <span class="p">located in the respective installation folders. To determine the full path to the real modulefiles, each modulefile includes a statement simliar to this:</span></p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 5pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">[     file     normalize     ${scriptpath}     ]                  </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">to get a direct reference to the original <span class="s18">modulefile </span>in the product installation directory. This is done because the install location might be customized and is therefore unknown at runtime. The actual modulefile cannot be moved outside of the installed location, otherwise it will not be able to locate the absolute path to the library or application that it must configure.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">For a better understanding, review the <span class="s18">modulefiles </span>included with the installation. Most include comments explaining how they resolve <span class="s18">symlink </span>references to a real file, as well as parsing the version number (and version directory). They also include checks to insure that the installed Tcl is an appropriate version level.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Additional Resources</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For more information about <span class="s18">modulefiles</span>, see:</p></li><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="http://www.admin-magazine.com/HPC/Articles/Environment-Modules">http://www.admin-magazine.com/HPC/Articles/Environment-Modules</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.chpc.utah.edu/documentation/software/modules-advanced.php">https://www.chpc.utah.edu/documentation/software/modules-advanced.php</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://modules.readthedocs.io/en/latest/">https://modules.readthedocs.io/en/latest/</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://lmod.readthedocs.io/en/latest/">https://lmod.readthedocs.io/en/latest/</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark19">&zwnj;</a>Use CMake with oneAPI Applications<a name="bookmark107">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The CMake packages provided with Intel oneAPI products allow a CMake project to make easy use of oneAPI libraries on Windows* or Linux*. Using the provided packages, the experience should be similar to how other system libraries integrate with a CMake project. There are dependency and other build variables provided to CMake project targets as desired.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following components support CMake:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>oneAPI DPC++ Compiler - Linux, Windows</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>Integrated Performance Primitives (Intel<span class="s12">® </span>IPP) and Intel<span class="s12">® </span>Integrated Performance Primitives Cryptography (Intel<span class="s12">® </span>IPP Cryptography) - Linux, Windows</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>MPI Library - Linux, Windows</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>oneAPI Collective Communications Library (oneCCL) - Linux, Windows</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>oneAPI Data Analytics Library (oneDAL) - Linux, Windows</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>oneAPI Deep Neural Network Library (oneDNN) - Linux, Windows</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>oneAPI DPC++ Library (oneDPL) - Linux, Windows</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>oneAPI Math Kernel Library (oneMKL) - Linux, Windows</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>oneAPI Threading Building Blocks (oneTBB) - Linux, Windows</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>Video Processing Library (oneVPL) - Linux, Windows</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;"><b>NOTE </b>Starting with the 2024.0 release, macOS is no longer supported in Intel<span class="s12">® </span>oneAPI Toolkits and components. Several Intel-led open source developer tool projects will continue supporting macOS on Apple Silicon including oneAPI Threading Building Blocks (oneTBB) and Intel<span class="s12">® </span>Implicit SPMD Program Compiler and we welcome the opportunity to work with contributors to expand support to additional tools in the future.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Libraries that provide a CMake configuration can be identified by looking in the following locations:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">On Linux or macOS:</p><ul id="l38"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 34pt;text-indent: -14pt;line-height: 12pt;text-align: left;">System: <span class="s18">/usr/local/lib/cmake`</span></p></li><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;line-height: 12pt;text-align: left;">User: <span class="s18">~/lib/cmake`</span></p></li></ul></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 12pt;text-align: left;">On Windows: <span class="s18">HKEY_LOCAL_MACHINESoftwareKitwareCMakePackages\`</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">To use the CMake packages, use the oneAPI libraries as you would other system libraries. For example, using</p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">find_package(tbb) <span class="p">ensures that your application’s CMake package is using the oneTBB package.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark20">&zwnj;</a>Compile &nbsp;&nbsp; and &nbsp;&nbsp; Run &nbsp;&nbsp; oneAPI &nbsp;&nbsp; Programs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a name="bookmark108">&zwnj;</a></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark109">&zwnj;</a>This chapter details the oneAPI compilation process across direct programming and API-based programming covering CPU, GPUs, and FPGAs. Some details about the tools employed at each stage of compilation are explained.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark21">&zwnj;</a>Single-Source Compilation<a name="bookmark110">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The oneAPI programming model supports single-source compilation. Single source compilation has several benefits compared to separate host and device code compilation. It should be noted that the oneAPI programming model also supports separate host and device code compilation as some users may prefer it. Advantages of the single-source compilation model include:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Usability – developers need to create fewer files and can define device code right next to the call site in the host code.</p><p style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Extra safety – single source means one compiler can see the boundary code between host and device and the actual parameters generated by host compiler will match formal parameters of the kernel generated by the device compiler.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Optimization - the device compiler can perform additional optimizations by knowing the context from which a kernel is invoked. For instance, the compiler may propagate some constants or infer pointer aliasing information across the function call.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark22">&zwnj;</a>Invoke the Compiler<a name="bookmark111">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compiler-setup/use-the-command-line/invoke-the-compiler.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI DPC++/C++ Compiler provides multiple drivers to invoke the complier from the command line. The examples below show options for C++ and SYCL*. For a full list of driver options, see the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compiler-setup/use-the-command-line/invoke-the-compiler.html" class="a" target="_blank">Different </a><span style=" color: #075FA7;">Compilers and Drivers </span>table.</p><p class="s20" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compiler-setup/use-the-command-line/invoke-the-compiler.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For more information on the compiler, see </a><span class="s13">Invoking the Compiler </span><span class="p">in the </span>Intel<span class="s24">® </span>oneAPI DPC++/C++ Compiler Developer Guide and Reference<span class="p">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To enable OpenMP* offloading for C++ applications, invoke the compiler with:</p></li><li data-list-text="•"><p class="s18" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;line-height: 12pt;text-align: left;">icpx -fiopenmp -fopenmp-targets=&lt;arch&gt; <span class="p">(Linux)</span></p></li><li data-list-text="•"><p class="s18" style="padding-left: 19pt;text-indent: -14pt;line-height: 12pt;text-align: left;">icx /Qiopenmp /Qopenmp-targets:&lt;arch&gt; <span class="p">(Windows).</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To enable OpenMP offloading for SYCL applications, invoke the compiler with:</p></li><li data-list-text="•"><p class="s18" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;line-height: 12pt;text-align: left;">icpx -fsycl -fiopenmp -fopenmp-targets=&lt;arch&gt; <span class="p">(Linux)</span></p></li><li data-list-text="•"><p class="s18" style="padding-left: 19pt;text-indent: -14pt;line-height: 12pt;text-align: left;">icx-cl -fsycl /Qiopenmp /Qopenmp-targets:&lt;arch&gt; <span class="p">(Windows)</span></p><p class="s20" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compiler-reference/compiler-options.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For more information about options, you can go to the option descriptions found in the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compiler-reference/compiler-options.html" class="a" target="_blank">Compiler </a><span class="s13">Options </span><span class="p">section of the </span>Intel<span class="s24">® </span>oneAPI DPC++/C++ Compiler Developer Guide and Reference<span class="p">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The compiler driver has different compatibilities on different OS hosts. On Linux, <span class="s18">icpx -fsycl </span>provides GCC*-style command line options. On Windows, <span class="s18">icx-cl </span>provides Microsoft Visual C++* compatibility with Microsoft Visual Studio*.</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">It recognizes GCC-style command line options (starting with “-“) and can be useful for projects that share a build system across multiple operating systems.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">It recognizes Windows command line options (starting with “/”) and can be useful for Microsoft Visual Studio-based projects.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark23">&zwnj;</a>Standard Intel® oneAPI DPC++/C++ Compiler Options<a name="bookmark112">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">A full list of Intel oneAPI DPC++/C++ Compiler options are available from the <i>Intel oneAPI DPC++/C++ Compiler Developer Guide and Reference</i>.</p></li><li data-list-text="•"><p class="s13" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compiler-reference/compiler-options/offload-openmp-and-parallel-processing-options.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The </a>Offload Compilation Options, OpenMP* Options, and Parallel Processing Options <span style=" color: #000;">section includes options specific to SYCL* and OpenMP* offload.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compiler-reference/compiler-options/alphabetical-list-of-compiler-options.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">A full list of available options and a brief description of each is available in the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compiler-reference/compiler-options/alphabetical-list-of-compiler-options.html" class="a" target="_blank">Alphabetical List of </a>Compiler Options<span style=" color: #000;">.</span></p></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark24">&zwnj;</a>Example Compilation<a name="bookmark113">&zwnj;</a></h4><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">oneAPI applications can be directly programmed, API-based, which makes use of available oneAPI libraries, or a combination of directly programmed and API-based. API-based programming takes advantage of device offload using library functionality, which can save developers time when writing an application. In general it is easiest to start with API-based programming and use SYCL* or OpenMP* offload features where API-based programming is insufficient for your needs.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following sections give examples of API-based code and direct programming using SYCL.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">API-Based Code</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The following code shows usage of an API call (<span class="s18">a * x + y</span>) employing the Intel oneAPI Math Kernel Library function <span class="s18">oneapi::mkl::blas::axpy </span>to multiply <span class="s18">a </span>times <span class="s18">x </span>and add <span class="s18">y </span>across vectors of floating point numbers. It takes advantage of the oneAPI programming model to perform the addition on an accelerator.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:459.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#include &lt;vector&gt; // std::vector() #include &lt;cstdlib&gt; // std::rand() #include &lt;CL/sycl.hpp&gt;</p><p class="s19" style="text-indent: 0pt;text-align: left;">#include &quot;oneapi/mkl/blas.hpp&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">int main(int argc, char* argv[]) {</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">double alpha = 2.0; int n_elements = 1024;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">int incx = 1; std::vector&lt;double&gt; x; x.resize(incx * n_elements);</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">for (int i=0; i&lt;n_elements; i++)</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">x[i*incx] = 4.0 * double(std::rand()) / RAND_MAX - 2.0;</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">// rand value between -2.0 and 2.0</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">int incy = 3; std::vector&lt;double&gt; y; y.resize(incy * n_elements);</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">for (int i=0; i&lt;n_elements; i++)</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">y[i*incy] = 4.0 * double(std::rand()) / RAND_MAX - 2.0;</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">// rand value between -2.0 and 2.0</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">cl::sycl::device my_dev; try {</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">my_dev = cl::sycl::device(cl::sycl::gpu_selector());</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">} catch (...) {</p><p class="s19" style="text-indent: 39pt;text-align: left;">std::cout &lt;&lt; &quot;Warning, failed at selecting gpu device. Continuing on default(host) device.\n&quot;;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">// Catch asynchronous exceptions</p><p class="s19" style="padding-left: 39pt;text-indent: -19pt;text-align: left;">auto exception_handler = [] (cl::sycl::exception_list exceptions) {</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:515.7pt;width:486.6pt;"><p class="s19" style="padding-left: 59pt;text-indent: -19pt;text-align: left;">for (std::exception_ptr const&amp; e : exceptions) { try {</p><p class="s19" style="padding-left: 79pt;text-indent: 0pt;text-align: left;">std::rethrow_exception(e);</p><p class="s19" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">} catch(cl::sycl::exception const&amp; e) {</p><p class="s19" style="padding-left: 79pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Caught asynchronous SYCL exception:\n&quot;; std::cout &lt;&lt; e.what() &lt;&lt; std::endl;</p><p class="s19" style="padding-left: 59pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">};</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">cl::sycl::queue my_queue(my_dev, exception_handler);</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">cl::sycl::buffer&lt;double, 1&gt; x_buffer(x.data(), x.size()); cl::sycl::buffer&lt;double, 1&gt; y_buffer(y.data(), y.size());</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">// perform y = alpha*x + y try {</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">oneapi::mkl::blas::axpy(my_queue, n_elements, alpha, x_buffer, incx, y_buffer, incy);</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">catch(cl::sycl::exception const&amp; e) {</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;\t\tCaught synchronous SYCL exception:\n&quot;</p><p class="s19" style="padding-left: 89pt;text-indent: 0pt;text-align: left;">&lt;&lt; e.what() &lt;&lt; std::endl;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;The axpy (y = alpha * x + y) computation is complete!&quot; &lt;&lt; std::endl;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">// print y_buffer</p><p class="s19" style="padding-left: 29pt;text-indent: -10pt;text-align: left;">auto y_accessor = y_buffer.template get_access&lt;cl::sycl::access::mode::read&gt;();</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; std::endl;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;y&quot; &lt;&lt; &quot; = [ &quot; &lt;&lt; y_accessor[0] &lt;&lt; &quot; ]\n&quot;; std::cout &lt;&lt; &quot; [ &quot; &lt;&lt; y_accessor[1*incy] &lt;&lt; &quot; ]\n&quot;; std::cout &lt;&lt; &quot;  [ &quot; &lt;&lt; &quot;... ]\n&quot;;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; std::endl;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">return 0;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To compile and build the application (saved as <span class="s18">axpy.cpp</span>):</p><ol id="l39"><li data-list-text="1."><p style="padding-top: 6pt;padding-left: 30pt;text-indent: -25pt;line-height: 108%;text-align: left;">Ensure that the MKLROOT environment variable is set appropriately (<span class="s18">echo ${MKLROOT}</span>). If it is not set appropriately, source the <span class="s18">setvars.sh </span>| <span class="s18">oneapi-vars.sh </span>script or run the <span class="s18">setvars.bat </span>| <span class="s18">oneapi- vars.bat </span>script or set the variable to the folder that contains the <span class="s18">lib </span>and <span class="s18">include </span>folders.</p><p style="padding-top: 5pt;padding-left: 30pt;text-indent: 0pt;line-height: 108%;text-align: left;">For more information about the <span class="s18">setvars </span>and <span class="s18">oneapi-vars </span><a href="#bookmark96" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">scripts, see </a><a href="#bookmark96" class="a">oneAPI Development </a><span style=" color: #075FA7;">Environment Setup</span>.</p></li><li data-list-text="2."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Build the application using the following command:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 30pt;text-indent: 0pt;text-align: left;">On Linux:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icpx   -fsycl   -I${MKLROOT}/include   -c   axpy.cpp   -o   axpy.o            </span></p><p style="padding-top: 6pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">On Windows:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icpx  -fsycl  -I${MKLROOT}/include  /EHsc  -c  axpy.cpp  /Foaxpy.obj          </span></p></li><li data-list-text="3."><p style="padding-bottom: 2pt;padding-left: 30pt;text-indent: -25pt;line-height: 159%;text-align: left;">Link the application using the following command: On Linux:</p><div class="textbox" style="background:#F0F0F0;display:block;min-height:67.3pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">icpx -fsycl axpy.o -fsycl-device-code-split=per_kernel \ &quot;${MKLROOT}/lib/intel64&quot;/libmkl_sycl.a -Wl,-export-dynamic -Wl,--start-group \ &quot;${MKLROOT}/lib/intel64&quot;/libmkl_intel_ilp64.a \ &quot;${MKLROOT}/lib/intel64&quot;/libmkl_sequential.a \ &quot;${MKLROOT}/lib/intel64&quot;/libmkl_core.a -Wl,--end-group -lsycl -lOpenCL \</p><p class="s19" style="text-indent: 0pt;text-align: left;">-lpthread -lm -ldl -o axpy.out</p></div></li></ol><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">On Windows:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:67.3pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">icpx -fsycl axpy.obj -fsycl-device-code-split=per_kernel ^ &quot;${MKLROOT}\lib\intel64&quot;\mkl_sycl.lib ^ &quot;${MKLROOT}\lib\intel64&quot;\mkl_intel_ilp64.lib ^ &quot;${MKLROOT}\lib\intel64&quot;\mkl_sequential.lib ^ &quot;${MKLROOT}\lib\intel64&quot;\mkl_core.lib ^</p><p class="s19" style="text-indent: 0pt;text-align: left;">sycl.lib OpenCL.lib -o axpy.exe</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><ol id="l40"><li data-list-text="4."><p style="padding-left: 30pt;text-indent: -25pt;line-height: 159%;text-align: left;">Run the application using the following command: On Linux:</p></li></ol><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">./axpy.out                       </span></p><p style="padding-top: 6pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">On Windows:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">axpy.exe                        </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Direct Programming</p><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming/C%2B%2BSYCL/DenseLinearAlgebra/vector-add" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The </a>vector addition sample code <span style=" color: #000;">is employed in this example. It takes advantage of the oneAPI programming model to perform the addition on an accelerator.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following command compiles and links the executable.</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icpx          -fsycl          vector_add.cpp                   </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The components and function of the command and options are similar to those discussed in the API-Based Code section above.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Execution of this command results in the creation of an executable file, which performs the vector addition when run.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark25">&zwnj;</a>Compilation Flow Overview<a name="bookmark114">&zwnj;</a></h4><p style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">When you create a program with offload, the compiler must generate code for both the host and the device. oneAPI tries to hide this complexity from the developer. The developer simply compiles a SYCL* application using the Intel<span class="s12">® </span>oneAPI DPC++ Compiler with <span class="s18">icpx -fsycl</span>, and the same compile command generates both host and device code.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-left: 35pt;text-indent: 0pt;text-align: left;"><b>NOTE </b>In addition to Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/developer/articles/system-requirements/intel-oneapi-dpcpp-system-requirements.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">processors listed in the </a><span style=" color: #075FA7;">System Requirements</span>, AMD* (Linux* only) and NVIDIA* (Linux and Windows*) GPUs may also be targeted:</p><ul id="l41"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">To use an AMD* GPU with the Intel<span class="s12">® </span><a href="https://developer.codeplay.com/products/oneapi/amd/guides/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI DPC++ Compiler, install the </a><a href="https://developer.codeplay.com/products/oneapi/amd/guides/" class="a" target="_blank">oneAPI for AMD GPUs </a><span style=" color: #075FA7;">plugin </span>from Codeplay.</p></li><li data-list-text="•"><p style="padding-bottom: 2pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">To use an NVIDIA* GPU with the Intel<span class="s12">® </span><a href="https://developer.codeplay.com/products/oneapi/nvidia/guides/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI DPC++ Compiler, install the </a><a href="https://developer.codeplay.com/products/oneapi/nvidia/guides/" class="a" target="_blank">oneAPI for NVIDIA </a><span style=" color: #075FA7;">GPUs plugin </span>from Codeplay.</p></li></ul><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://link.springer.com/book/10.1007%2F978-1-4842-5574-2" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For device code, two options are available: Just-in-Time (JIT) compilation and Ahead-of-Time (AOT) compilation, with JIT being the default. This section describes how host code is compiled, and the two options for generating device code. Additional details are available in Chapter 13 of the </a>Data Parallel C++ book<span style=" color: #000;">.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Traditional Compilation Flow (Host-only Application)</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The traditional compilation flow is a standard compilation like the one used for C, C++, or other languages, used when there is no offload to a device.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The traditional compilation phases are shown in the following diagram:</p><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Traditional compilation phases</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l42"><li data-list-text="1."><p style="padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;">The front end translates the source into an intermediate representation and then passes that representation to the back end.</p></li><li data-list-text="2."><p style="padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;">The back end translates the intermediate representation to object code and emits an object file (<span class="s18">host.obj </span>on Windows*, <span class="s18">host.o </span>on Linux*).</p></li><li data-list-text="3."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">One or more object files are passed to the linker.</p></li><li data-list-text="4."><p style="padding-top: 1pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">The linker creates an executable.</p></li><li data-list-text="5."><p style="padding-top: 1pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">The application runs.</p></li></ol><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Compilation Flow for SYCL Offload Code</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">The compilation flow for SYCL offload code adds steps for device code to the traditional compilation flow, with JIT and AOT options for device code. In this flow, the developer compiles a SYCL application with <span class="s18">icpx - fsycl</span>, and the output is an executable containing both host and device code.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The basic compilation phases for SYCL offload code are shown in the following diagram:</p><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Basic compilation phases for SYCL offload code</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span/></p><ol id="l43"><li data-list-text="1."><p style="padding-top: 4pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">The host code is translated to object code by the back end.</p></li><li data-list-text="2."><p style="padding-top: 1pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">The device code is translated to either a SPIR-V* or device binary.</p></li><li data-list-text="3."><p style="padding-top: 1pt;padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;">The linker combines the host object code and the device code (SPIR-V or device binary) into an executable containing the host binary with the device code embedded in it. This process is known as a fat binary.</p></li><li data-list-text="4."><p style="padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;">At runtime, the operating system starts the host application. If it has offload, the runtime loads the device code (converting the SPIR-V to device binary if needed).</p></li><li data-list-text="5."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">The application runs on the host and a specified device.</p></li></ol><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">JIT Compilation Flow</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">In the JIT compilation flow, the code for the device is translated to SPIR-V intermediate code by the back- end, embedded in the fat binary as SPRI-V, and translated from SPIR-V to device code by the runtime. When the application is run, the runtime determines the available devices and generates the code specific to that device. This allows for more flexibility in where the application runs and how it performs than the AOT flow, which must specify a device at compile time. However, performance may be worse because compilation occurs when the application runs. Larger applications with significant amounts of device code may notice performance impacts.</p><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 1pt;padding-bottom: 3pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">Tip <span class="p">The JIT compilation flow is useful when you do not know what the target device will be.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 1pt;padding-bottom: 3pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">JIT compilation is not supported for FPGA devices.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The compilation phases are shown in the following diagram:</p><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">JIT compilation phases</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l44"><li data-list-text="1."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">The host code is translated to object code by the back end.</p></li><li data-list-text="2."><p style="padding-top: 1pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">The device code is translated to SPIR-V.</p></li><li data-list-text="3."><p style="padding-top: 1pt;padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;">The linker combines the host object code and the device SPIR-V into a fat binary containing host executable code with SPIR-V device code embedded in it.</p></li><li data-list-text="4."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">At runtime:</p><ol id="l45"><li data-list-text="a."><p style="padding-top: 6pt;padding-left: 55pt;text-indent: -24pt;text-align: left;">The device runtime on the host translates the SPIR-V for the device into device binary code.</p></li><li data-list-text="b."><p style="padding-top: 1pt;padding-left: 55pt;text-indent: -24pt;text-align: left;">The device code is loaded onto the device.</p></li></ol></li><li data-list-text="5."><p style="padding-top: 1pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">The application runs on the host and device available at runtime.</p></li></ol><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">AOT Compilation Flow</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">In the AOT compilation flow, the code for the device is translated to SPIR-V and then device code in the host back-end and the resulting device code is embedded in the generated fat binary. The AOT flow provides less flexibility than the JIT flow because the target device must be specified at compilation time. However, executable start-up time is faster than the JIT flow.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 1pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">Tip</p><ul id="l46"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">The AOT compilation flow is good when you know exactly which device you are targeting.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 49pt;text-indent: -14pt;line-height: 110%;text-align: left;">The AOT flow is recommended when debugging your application as it speeds up the debugging cycle.</p></li></ul><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The compilation phases are shown in the following diagram:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">AOT compilation phases</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l47"><li data-list-text="1."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">The host code is translated to object code by the back end.</p></li><li data-list-text="2."><p style="padding-top: 1pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">The device code is translated to SPIR-V.</p></li><li data-list-text="3."><p style="padding-top: 1pt;padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;">The SPIR-V for the device is translated to a device code object using the device specified by the user on the command line.</p></li><li data-list-text="4."><p style="padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;">The linker combines the host object code and the device object code into a fat binary containing host executable code with device executable code embedded in it.</p></li><li data-list-text="5."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">At runtime, the device executable code is loaded onto the device.</p></li><li data-list-text="6."><p style="padding-top: 1pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">The application runs on a host and specified device.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Fat Binary</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">A fat binary is generated from the JIT and AOT compilation flows. It is a host binary that includes embedded device code. The contents of the device code vary based on the compilation flow.</p><p class="s14" style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">FAT binary</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span/></p><ul id="l48"><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">The host code is an executable in either the ELF (Linux) or PE (Windows) format.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">The device code is a SPIR-V for the JIT flow or an executable for the AOT flow. Executables are in one of the following formats:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l49"><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;text-align: left;">CPU: ELF (Linux), PE (Windows)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">GPU: ELF (Windows, Linux)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">FPGA: ELF (Linux), PE (Windows)</p></li></ul></li></ul></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark26">&zwnj;</a>CPU Flow<a name="bookmark115">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">The CPU is typically called the brain of the computer. The CPU consists of complex circuitry/algorithms that include branch predictors, memory virtualization and instruction scheduling, etc. Given this complexity, it is designed to handle a wide-range of tasks.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The SYCL* and OpenMP* offload programming model enables implementation of an application on heterogenous CPU and GPU systems. The term “devices” in SYCL and OpenMP offload can refer to both CPUs and GPUs.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Modern CPUs have many cores with hyper-threads and high SIMD width, which can be used for parallel computation. If your workloads have regions that are compute intensive and can be run in parallel, it is a good idea to offload those regions to a CPU than to a coprocessor, such as a GPU or FPGA. Also, because data does not need to be offloaded through PCIe (unlike for coprocessors or GPU), latency is reduced with minimal data transfer overhead.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">There are two options for running an application on a CPU: the traditional CPU flow that runs directly on the CPU or a CPU offload flow that runs on a CPU device. You can use CPU offload with either SYCL or OpenMP offload applications. Both OpenMP offload and SYCL offload applications use the OpenCL<span class="s12">™ </span>runtime and Intel<span class="s12">® </span>oneAPI Threading Building Blocks (Intel<span class="s12">® </span>oneTBB) to run on a CPU as a device.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">Tip <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/comparing-cpus-gpus-and-fpgas-for-oneapi.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Unsure whether your workload fits best on CPU, GPU, or FPGA? </a><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/comparing-cpus-gpus-and-fpgas-for-oneapi.html" class="a" target="_blank">Compare the benefits of CPUs, </a><span class="s13">GPUs, and FPGAs for different oneAPI compute workloads</span><span class="p">.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark27">&zwnj;</a>Traditional CPU Flow<a name="bookmark116">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The traditional CPU workflow runs on the CPU without a runtime. The compilation flow is a standard compilation used when there is no offload to a device, like the one used for C, C++, or other languages.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="#bookmark114" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Traditional workloads are compiled and run on host using the Traditional Compilation Flow (Host-only Application) process described in </a>Compilation Flow Overview<span style=" color: #000;">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Example compilation command:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icpx      -g   -o   matrix_mul_omp   src/matrix_mul_omp.cpp             </span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark28">&zwnj;</a>CPU Offload Flow<a name="bookmark117">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">By default, if you are offloading to a CPU device, it goes through an OpenCL<span class="s12">™ </span>runtime, which also uses Intel oneAPI Threading Building Blocks for parallelism.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">When offloading to a CPU, workgroups map to different logical cores and these workgroups can execute in parallel. Each work-item in the workgroup can map to a CPU SIMD lane. Work-items (sub-groups) execute together in a SIMD fashion.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">CPU workgroups</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/comparing-cpus-gpus-and-fpgas-for-oneapi.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To learn more about CPU execution, see </a><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/comparing-cpus-gpus-and-fpgas-for-oneapi.html" class="a" target="_blank">Compare Benefits of CPUs, GPUs, and FPGAs for Different oneAPI </a>Compute Workloads<span style=" color: #000;">.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">Set Up for CPU Offload</p><ol id="l50"><li data-list-text="1."><p style="padding-top: 4pt;padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;"><a href="#bookmark96" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Make sure you have followed all steps in the </a><span style=" color: #075FA7;">oneAPI Development Environment Setup </span>section, including running the <span class="s18">setvars </span>or <span class="s18">oneapi-vars </span>script.</p></li><li data-list-text="2."><p style="padding-left: 30pt;text-indent: -25pt;line-height: 108%;text-align: left;">Check if you have the required OpenCL runtime associated with the CPU using the <span class="s18">sycl-ls </span>command. For example:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$sycl-ls</p><p class="s19" style="text-indent: 0pt;text-align: left;">CPU : OpenCL 2.1 (Build 0)[ 2020.11.12.0.14_160000 ] GPU : OpenCL 3.0 NEO [ 21.33.20678 ]</p><p class="s19" style="text-indent: 0pt;text-align: left;">GPU : 1.1[ 1.2.20939 ]</p></div></li></ol><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><ol id="l51"><li data-list-text="3."><p style="padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;">Use one of the following code samples to verify that your code is running on the CPU. The code sample adds scalar to large vectors of integers and verifies the results.</p></li></ol><p class="s14" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL*</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">To run on a CPU, SYCL provides built-in device selectors for convenience. They use <span class="s18">device_selector </span>as a base class. <span class="s18">cpu_selector </span>selects a CPU device.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Alternatively, you could also use the following environment variable when using <span class="s18">default_selector </span>to select a device according to implementation-defined heuristics.</p><p style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">export                 ONEAPI_DEVICE_SELECTOR=cpu                 </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL code sample:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:426.0pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#include &lt;CL/sycl.hpp&gt; #include &lt;array&gt; #include &lt;iostream&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">using namespace sycl; using namespace std;</p><p class="s19" style="text-indent: 0pt;text-align: left;">constexpr size_t array_size = 10000; int main(){</p><p class="s19" style="text-indent: 0pt;text-align: left;">constexpr int value = 100000; try{</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">cpu_selector d_selector; queue q(d_selector);</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">int *sequential = malloc_shared&lt;int&gt;(array_size, q); int *parallel = malloc_shared&lt;int&gt;(array_size, q);</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">//Sequential iota</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">for (size_t i = 0; i &lt; array_size; i++) sequential[i] = value + i;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">//Parallel iota in SYCL</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">auto e = q.parallel_for(range{array_size}, [=](auto i) { parallel[i] = value + i; }); e.wait();</p><p class="s19" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">// Verify two results are equal.</p><p class="s19" style="padding-left: 29pt;text-indent: -10pt;text-align: left;">for (size_t i = 0; i &lt; array_size; i++) { if (parallel[i] != sequential[i]) {</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">cout &lt;&lt; &quot;Failed on device.\n&quot;; return -1;</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">free(sequential, q); free(parallel, q);</p><p class="s19" style="text-indent: 0pt;text-align: left;">}catch (std::exception const &amp;e) {</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">cout &lt;&lt; &quot;An exception is caught while computing on device.\n&quot;; terminate();</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 9pt;text-indent: -5pt;text-align: left;">cout &lt;&lt; &quot;Successfully completed on device.\n&quot;; return 0;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To compile the code sample, use:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">dpcpp      simple-iota-dp.cpp      -o      simple-iota.                </span></p><p class="s13" style="padding-top: 6pt;padding-bottom: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 159%;text-align: left;"><a href="#bookmark118" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Additional commands are available from </a>Example CPU Commands<span style=" color: #000;">. Results after compilation:</span></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">./simple-iota</p><p class="s19" style="text-indent: 0pt;text-align: left;">Running on device: Intel<span class="s22">® </span>Core<span class="s22">™ </span>i7-8700 CPU @ 3.20GHz Successfully completed on device.</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">OpenMP*</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">OpenMP code sample:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:56.0pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#include&lt;iostream&gt; #include&lt;omp.h&gt; #define N 1024</p><p class="s19" style="text-indent: 0pt;text-align: left;">int main(){</p><p class="s19" style="text-indent: 0pt;text-align: left;">float *a = (float *)malloc(sizeof(float)*N);</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:89.7pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">for(int i = 0; i &lt; N; i++) a[i] = i;</p><p class="s19" style="text-indent: 0pt;text-align: left;">#pragma omp target teams distribute parallel for simd map(tofrom: a[:N]) for(int i = 0; i &lt; 1024; i++)</p><p class="s19" style="text-indent: 0pt;text-align: left;">a[i]++;</p><p class="s19" style="text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Successfully completed on device.\n&quot;; return 0;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To compile the code sample, use:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icpx  simple-ompoffload.cpp  -fiopenmp  -fopenmp-targets=spir64  -o  simple-ompoffload     </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Setup the following environment variables before executing the binary to run the offload regions on the CPU:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">export LIBOMPTARGET_DEVICETYPE=cpu export LIBOMPTARGET_PLUGIN=opencl</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Results after execution:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">./simple-ompoffload</p><p class="s19" style="text-indent: 0pt;text-align: left;">Successfully completed on device</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s17" style="padding-top: 12pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">Offload Code to CPU</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">When offloading your application, it is important to identify the bottlenecks and which code will benefit from offloading. If you have a code that is compute intensive or a highly data parallel kernel, offloading your code would be something to look into.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/advisor-user-guide/top/model-offloading-to-a-gpu.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To find opportunities to offload your code, use the </a>Intel Advisor for Offload Modeling<span style=" color: #000;">.</span></p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">Debug Offloaded Code</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">The following list has some basic debugging tips for offloaded code.</p><ul id="l52"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Check host target to verify the correctness of your code.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Use <span class="s18">printf </span>to debug your application. Both SYCL and OpenMP offload support <span class="s18">printf </span>in kernel code.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Use environment variables to control verbose log information.</p><ul id="l53"><li data-list-text="•"><p class="s13" style="padding-top: 6pt;padding-left: 34pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For SYCL, the following debug environment variables are recommended. A full list of environment variables is available from </a>GitHub<span style=" color: #000;">.</span></p><p class="s25" style="padding-top: 4pt;padding-bottom: 1pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">SYCL Recommended Debug Environment Variables</p><table style="border-collapse:collapse;margin-left:34.0394pt" cellspacing="0"><tr style="height:21pt"><td style="width:147pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">Name</p></td><td style="width:165pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Value</p></td><td style="width:158pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">Description</p></td></tr><tr style="height:18pt"><td style="width:147pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 6pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">ONEAPI_DEVICE_SELECTOR</p></td><td style="width:165pt;border-top-style:solid;border-top-width:1pt"><p class="s19" style="padding-top: 6pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">backend:device_type:devic</p></td><td style="width:158pt;border-top-style:solid;border-top-width:1pt;border-right-style:solid;border-right-width:1pt"><p style="padding-top: 4pt;padding-left: 7pt;text-indent: 0pt;text-align: left;"><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md#ONEAPI_DEVICE_SELECTOR" class="s27">GitHub description</a></p></td></tr><tr style="height:17pt"><td style="width:147pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:165pt"><p class="s19" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">e_num</p></td><td style="width:158pt;border-right-style:solid;border-right-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td></tr><tr style="height:17pt"><td style="width:147pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;line-height: 10pt;text-align: left;">SYCL_UR_TRACE</p></td><td style="width:165pt"><p class="s28" style="padding-top: 4pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">1|2|-1</p></td><td style="width:158pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">1: print out the basic trace log</p></td></tr><tr style="height:12pt"><td style="width:147pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:165pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:158pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 7pt;text-indent: 0pt;line-height: 10pt;text-align: left;">of the SYCL/DPC++ runtime</p></td></tr><tr style="height:15pt"><td style="width:147pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:165pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:158pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">plugin</p></td></tr><tr style="height:15pt"><td style="width:147pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:165pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:158pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 10pt;text-align: left;">2: print out all API traces of</p></td></tr><tr style="height:15pt"><td style="width:147pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:165pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:158pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">SYCL/DPC++ runtime plugin</p></td></tr><tr style="height:15pt"><td style="width:147pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:165pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:158pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 10pt;text-align: left;">-1: all of “2” including more</p></td></tr><tr style="height:16pt"><td style="width:147pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:165pt;border-bottom-style:solid;border-bottom-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:158pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">debug messages</p></td></tr></table></li><li data-list-text="•"><p class="s13" style="padding-left: 34pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://openmp.llvm.org//design/Runtimes.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For OpenMP, the following debug environment variables are recommended. A full list is available from the </a>LLVM/OpenMP documentation<span style=" color: #000;">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s25" style="padding-bottom: 1pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">OpenMP Recommended Debug Environment Variables</p><table style="border-collapse:collapse;margin-left:34.0394pt" cellspacing="0"><tr style="height:21pt"><td style="width:150pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">Name</p></td><td style="width:148pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">Value</p></td><td style="width:172pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 23pt;text-indent: 0pt;text-align: left;">Description</p></td></tr><tr style="height:22pt"><td style="width:150pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 6pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_DEVICETYPE</p></td><td style="width:148pt;border-top-style:solid;border-top-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">cpu|gpu|host</p></td><td style="width:172pt;border-top-style:solid;border-top-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 21pt;text-indent: 0pt;text-align: left;">Select</p></td></tr><tr style="height:33pt"><td style="width:150pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_DEBUG</p></td><td style="width:148pt"><p class="s28" style="padding-top: 4pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">1</p></td><td style="width:172pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 21pt;text-indent: 0pt;line-height: 110%;text-align: left;">Print out verbose debug information</p></td></tr><tr style="height:41pt"><td style="width:150pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_INFO</p></td><td style="width:148pt"><p style="padding-top: 4pt;padding-left: 13pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://openmp.llvm.org//design/Runtimes.html" class="s27" target="_blank">Values available in LLVM/ OpenMP documentation</a></p></td><td style="width:172pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 3pt;padding-left: 21pt;padding-right: 31pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">Allows the user to request different types of runtime information from</p></td></tr><tr style="height:17pt"><td style="width:150pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:148pt;border-bottom-style:solid;border-bottom-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:172pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s19" style="padding-top: 1pt;padding-left: 21pt;text-indent: 0pt;text-align: left;">libomptarget</p></td></tr></table></li></ul></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="#bookmark119" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Use Ahead of Time (AOT) to move Just-in-Time (JIT) compilations to AOT compilation issues. For more information, see </a>Ahead-of-Time Compilation for CPU Architectures<span style=" color: #000;">.</span></p><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="#bookmark162" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">See </a>Debugging the SYCL and OpenMP Offload Process <span style=" color: #000;">for more information on debug techniques and debugging tools available with oneAPI.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Optimize CPU Code</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">There are many factors that can affect the performance of CPU offload code. The number of work-items, workgroups, and amount of work done depends on the number of cores in your CPU.</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">If the amount of work being done by the core is not compute-intensive, then this could hurt performance. This is because of the scheduling overhead and thread context switching.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">On a CPU, there is no need for data transfer through PCIe, resulting in lower latency because the offload region does not have to wait long for the data.</p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="#bookmark120" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Based on the nature of your application, thread affinity could affect the performance on CPU. For details, see </a>Control Binary Execution on Multiple Cores<span style=" color: #000;">.</span></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="#bookmark119" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Offloaded code uses JIT compilation by default. Use AOT compilation (offline compilation) instead. With offline compilation, you could target your code to specific CPU architecture. Refer to </a><a href="#bookmark119" class="a">Optimization Flags for </a>CPU Architectures <span style=" color: #000;">for details.</span></p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="#bookmark163" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Additional recommendations are available from </a>Optimize Offload Performance<span style=" color: #000;">.</span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark29">&zwnj;</a>Example CPU Commands<a name="bookmark118">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The commands below implement the scenario when part of the device code resides in a static library.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">Linking with a dynamic library is not supported.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Produce a fat object with device code:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:11.2pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">icpx -fsycl -c static_lib.cpp</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Create a fat static library out of it using the <span class="s18">ar </span>tool:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:11.2pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">ar cr libstlib.a static_lib.o</p></div><p style="padding-left: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Compile application sources:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:11.2pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">icpx -fsycl -c a.cpp</p></div><p style="padding-left: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Link the application with the static library:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:11.2pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">icpx -fsycl -foffload-static-lib=libstlib.a a.o -o a.exe</p></div><p style="padding-left: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;"/><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark30">&zwnj;</a>Ahead-of-Time Compilation for CPU Architectures<a name="bookmark119">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="#bookmark114" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">In </a>ahead-of-time (AOT) compilation mode<span style=" color: #000;">, optimization flags can be used to produce code aimed to run better on a specific CPU architecture.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">icpx -fsycl -fsycl-targets=spir64_x86_64 -Xs &quot;-device &lt;CPU optimization flags&gt;&quot;&quot; a.cpp b.cpp -o app.out</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Supported CPU optimization flags are:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">-march=&lt;instruction_set_arch&gt; Set target instruction set architecture: &#39;sse42&#39; for Intel<span class="s22">® </span>Streaming SIMD Extensions 4.2</p><p class="s19" style="text-indent: 0pt;text-align: left;">&#39;avx2&#39; for Intel<span class="s22">® </span>Advanced Vector Extensions 2 &#39;avx512&#39; for Intel<span class="s22">® </span>Advanced Vector Extensions 512</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">The set of supported optimization flags may be changed in future releases.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark31">&zwnj;</a>Control Binary Execution on Multiple CPU Cores<a name="bookmark120">&zwnj;</a></p><p style="padding-top: 12pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Environment Variables</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">The following environment variables control the placement of SYCL* or OpenMP* threads on multiple CPU cores during program execution. Use these variables if you are using the OpenCL<span class="s12">™ </span>runtime CPU device to offload to a CPU.</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;">DPCPP_CPU_CU_AFFINITY</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 110%;text-align: left;">Set thread affinity to CPU. The value and meaning is the following:</p><ul id="l54"><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 14pt;text-indent: -14pt;line-height: 110%;text-align: left;">close - threads are pinned to CPU cores successively through available cores.</p></li><li data-list-text="•"><p style="padding-left: 14pt;text-indent: -14pt;text-align: left;">spread - threads are sread to available cores.</p></li></ul><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Description</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Environment Variable</p><p style="text-indent: 0pt;text-align: left;"/><p class="s25" style="padding-top: 4pt;padding-bottom: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL* or OpenMP* environmental variables</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">Environment Variable               Description</p><ul id="l55"><ul id="l56"><li data-list-text="•"><p style="padding-top: 9pt;padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">master - threads are put in the same cores as master. If DPCPP_CPU_CU_AFFINITY is set, master thread is pinned as well, otherwise master thread is not pinned.</p><p style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;line-height: 110%;text-align: left;">This environment variable is similar to the OMP_PROC_BIND variable used by OpenMP.</p><p class="s14" style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;text-align: left;">Default: <span class="p">Not set</span></p><p style="padding-top: 9pt;padding-left: 261pt;text-indent: -248pt;line-height: 110%;text-align: left;">DPCPP_CPU_SCHEDULE               Specify the algorithm for scheduling work-groups by the scheduler. Currently, the SYCL runtime uses Intel<span class="s12">® </span>oneAPI Threading Building Blocks (Intel<span class="s12">® </span>oneTBB) for scheduling. The value selects the petitioner used by the Intel oneTBB scheduler. The value and meaning is the following:</p></li><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">dynamic - Intel oneTBB auto_partitioner. It performs sufficient splitting to balance load.</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">affinity - Intel oneTBB affinity_partitioner. It improves auto_partitioner’s cache affinity by its choice of mapping subranges to worker threads compared to</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">static - Intel oneTBB static_partitioner. It distributes range iterations among worker threads as uniformly as possible. Intel oneTBB partitioner relies grain-size to control chunking. Grain-size is 1 by default, indicating every work- group can be executed independently.</p></li></ul></ul><p class="s14" style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;text-align: left;">Default: <span class="p">Dynamic</span></p><p style="padding-top: 9pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">DPCPP_CPU_NUM_CUS                Set the numbers threads used for kernel execution.</p><p style="padding-top: 6pt;padding-left: 261pt;text-indent: 0pt;line-height: 110%;text-align: left;">To avoid over subscription, maximum value of DPCPP_CPU_NUM_CUS should be the number of hardware threads. If DPCPP_CPU_NUM_CUS is 1, all the workgroups are executed sequentially by a single thread and this is useful for debugging.</p><p style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;line-height: 110%;text-align: left;">This environment variable is similar to OMP_NUM_THREADS variable used by OpenMP.</p><p class="s14" style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;text-align: left;">Default: <span class="p">Not set. Determined by Intel oneTBB.</span></p><p style="padding-top: 9pt;padding-left: 261pt;text-indent: -248pt;line-height: 110%;text-align: left;">DPCPP_CPU_PLACES                 Specify the places that affinities are set. The value is { sockets | numa_domains | cores | threads }.</p><p style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;line-height: 110%;text-align: left;">This environment variable is similar to the OMP_PLACES variable used by OpenMP.</p><p style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;line-height: 110%;text-align: left;">If value is numa_domains, Intel oneTBB NUMA API will be used. This is analogous to OMP_PLACES=numa_domains in the OpenMP 5.1 Specification. Intel oneTBB task arena is bound to numa node and SYCL nd range is uniformly distributed to task arenas.</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><div class="textbox" style="border:1.0pt solid #000000;display:block;min-height:50.8pt;width:498.6pt;"><p class="s28" style="padding-top: 4pt;padding-left: 254pt;text-indent: 0pt;line-height: 110%;text-align: left;">DPCPP_CPU_PLACES is suggested to be used together with DPCPP_CPU_CU_AFFINITY.</p><p class="s26" style="padding-top: 5pt;padding-left: 254pt;text-indent: 0pt;text-align: left;">Default: <span class="s28">cores</span></p></div><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Description</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Environment Variable</p><p style="text-indent: 0pt;text-align: left;"/><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compilation/supported-environment-variables.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">See the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compilation/supported-environment-variables.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compilation/supported-environment-variables.html" class="s16" target="_blank">® </a>oneAPI DPC++/C++ Compiler Developer Guide and Reference <span style=" color: #000;">for more information about all supported environment variables.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Allocating Host Memory</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">When using OpenMP, you can allocate host memory so it can be shared with the device by using this API:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">EXTERN  void  *llvm_omp_target_alloc_host(size_t  Size,  int  DeviceNum)         </span></p><p class="s13" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://oneapi-src.github.io/level-zero-spec/level-zero/latest/core/PROG.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For more information on memory allocation, see the </a>Level Zero Core Programming Guide<span style=" color: #000;">.</span></p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Example 1: Hyper-threading Enabled</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Assume a machine with two sockets and four physical cores per socket, where each physical core has two hyper-threads.</p><ul id="l57"><li data-list-text="•"><p class="s18" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">S&lt;num&gt; <span class="p">denotes the socket number that has eight cores specified in a list</span></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><span class="s18">T&lt;num&gt; </span>denotes the Intel<span class="s12">® </span>oneAPI Threading Building Blocks (Intel<span class="s12">® </span>oneTBB) thread number</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">“-” means unused core</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s18" style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">DPCPP_CPU_NUM_CUS=16</p><p class="s18" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">export DPCPP_CPU_PLACES=sockets</p><p class="s18" style="padding-left: 11pt;text-indent: 14pt;text-align: left;">DPCPP_CPU_CU_AFFINITY=close:  S0:[T0 T1 T2 T3 T4 T5 T6 T7]   S1:[T8 T9 T10 T11 T12 T13 T14 T15]</p><p class="s18" style="padding-left: 11pt;text-indent: 14pt;text-align: left;">DPCPP_CPU_CU_AFFINITY=spread: S0:[T0 T2 T4 T6 T8 T10 T12 T14]  S1:[T1 T3 T5 T7 T9 T11 T13 T15]</p><p class="s18" style="padding-left: 11pt;text-indent: 14pt;text-align: left;">DPCPP_CPU_CU_AFFINITY=master: S0:[T0 T1 T2 T3 T4 T5 T6 T7]   S1:[T8 T9 T10 T11 T12 T13 T14 T15]</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s18" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">export DPCPP_CPU_PLACES=cores</p><p class="s18" style="padding-left: 11pt;text-indent: 14pt;text-align: left;">DPCPP_CPU_CU_AFFINITY=close : S0:[T0 T8 T1 T9 T2 T10 T3 T11]  S1:[T4 T12 T5 T13 T6 T14 T7 T15]</p><p class="s18" style="padding-left: 11pt;text-indent: 14pt;text-align: left;">DPCPP_CPU_CU_AFFINITY=spread: S0:[T0 T8 T2 T10 T4 T12 T6 T14]  S1:[T1 T9 T3 T11 T5 T13 T7 T15]</p><p class="s18" style="padding-left: 11pt;text-indent: 14pt;text-align: left;">DPCPP_CPU_CU_AFFINITY=master: S0:[T0 T1 T2 T3 T4 T5 T6 T7]  S1:[T8 T9 T10 T11 T12 T13 T14 T15]</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s18" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">export DPCPP_CPU_PLACES=threads</p><p class="s18" style="padding-left: 11pt;text-indent: 14pt;text-align: left;">DPCPP_CPU_CU_AFFINITY=close:  S0:[T0 T1 T2 T3 T4 T5 T6 T7]  S1:[T8 T9 T10 T11 T12 T13 T14 T15]</p><p class="s18" style="padding-left: 11pt;text-indent: 14pt;text-align: left;">DPCPP_CPU_CU_AFFINITY=spread: S0:[T0 T2 T4 T6 T8 T10 T12 T14]  S1:[T1 T3 T5 T7 T9 T11 T13 T15]</p><p class="s18" style="padding-left: 11pt;text-indent: 14pt;text-align: left;">DPCPP_CPU_CU_AFFINITY=master: S0:[T0 T1 T2 T3 T4 T5 T6 T7]  S1:[T8 T9 T10 T11 T12 T13 T14 T15]</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">export DPCPP_CPU_NUM_CUS=8</p><p class="s18" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">DPCPP_CPU_PLACES=sockets, cores and threads have the same bindings: DPCPP_CPU_CU_AFFINITY=close close:  S0:[T0 - T1 - T2 - T3 -]  S1:[T4 - T5 - T6 - T7 -] DPCPP_CPU_CU_AFFINITY=close spread: S0:[T0 - T2 - T4 - T6 -]  S1:[T1 - T3 - T5 - T7 -] DPCPP_CPU_CU_AFFINITY=close master: S0:[T0 T1 T2 T3 T4 T5 T6 T7] S1:[]</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Example 2: Hyper-threading Disabled</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Assume a machine with two sockets and four physical cores per socket, where each physical core has two hyper-threads.</p></li><li data-list-text="•"><p class="s18" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">S&lt;num&gt; <span class="p">denotes the socket number that has eight cores specified in a list</span></p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">T&lt;num&gt; <span class="p">denotes the Intel oneTBB thread number</span></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s18" style="text-indent: 0pt;text-align: left;">export DPCPP_CPU_NUM_CUS=8</p><p class="s18" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">DPCPP_CPU_PLACES=sockets, cores and threads have the same bindings: DPCPP_CPU_CU_AFFINITY=close: S0:[T0 T1 T2 T3] S1:[T4 T5 T6 T7] DPCPP_CPU_CU_AFFINITY=spread: S0:[T0 T2 T4 T6] S1:[T1 T3 T5 T7] DPCPP_CPU_CU_AFFINITY=master: S0:[T0 T1 T2 T3]  S1:[T4 T5 T6 T7]</p><p style="text-indent: 0pt;text-align: left;"/><p class="s18" style="text-indent: 0pt;text-align: left;">export DPCPP_CPU_NUM_CUS=4</p><p class="s18" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">DPCPP_CPU_PLACES=sockets, cores and threads have the same bindings: DPCPP_CPU_CU_AFFINITY=close: S0:[T0 - T1 - ] S1:[T2 - T3 - ] DPCPP_CPU_CU_AFFINITY=spread: S0:[T0 - T2 - ] S1:[T1 - T3 - ] DPCPP_CPU_CU_AFFINITY=master: S0:[T0 T1 T2 T3]   S1:[<span class="s31">       </span>]</p><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">“-” means unused core</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 12pt;text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a name="bookmark32">&zwnj;</a>GPU Flow<a name="bookmark121">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">GPUs are special-purpose compute devices that can be used to offload a compute intensive portion of your application. GPUs usually consists of many smaller cores and are therefore known for massive throughput. There are some tasks better suited to a CPU and others that may be better suited to a GPU.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-left: 35pt;text-indent: 0pt;text-align: left;"><b>NOTE </b>In addition to Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/developer/articles/system-requirements/intel-oneapi-dpcpp-system-requirements.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">processors listed in the </a><span style=" color: #075FA7;">System Requirements</span>, AMD* and NVIDIA* GPUs may also be targeted (Linux only):</p><ul id="l58"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">To use an AMD* GPU with the Intel<span class="s12">® </span><a href="https://developer.codeplay.com/products/oneapi/amd/guides/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI DPC++ Compiler, install the </a><a href="https://developer.codeplay.com/products/oneapi/amd/guides/" class="a" target="_blank">oneAPI for AMD GPUs </a><span style=" color: #075FA7;">plugin </span>from Codeplay.</p></li><li data-list-text="•"><p style="padding-bottom: 2pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">To use an NVIDIA* GPU with the Intel<span class="s12">® </span><a href="https://developer.codeplay.com/products/oneapi/nvidia/guides/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI DPC++ Compiler, install the </a><a href="https://developer.codeplay.com/products/oneapi/nvidia/guides/" class="a" target="_blank">oneAPI for NVIDIA </a><span style=" color: #075FA7;">GPUs plugin </span>from Codeplay.</p></li></ul></li></ul><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">Tip <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/comparing-cpus-gpus-and-fpgas-for-oneapi.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Unsure whether your workload fits best on CPU, GPU, or FPGA? </a><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/comparing-cpus-gpus-and-fpgas-for-oneapi.html" class="a" target="_blank">Compare the benefits of CPUs, </a><span class="s13">GPUs, and FPGAs for different oneAPI compute workloads</span><span class="p">.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark33">&zwnj;</a>GPU Offload Flow<a name="bookmark122">&zwnj;</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Offloading a program to a GPU defaults to the level zero runtime. There is also an option to switch to the OpenCL<span class="s12">™ </span>runtime. In SYCL* and OpenMP* offload, each work item is mapped to a SIMD lane. A subgroup maps to SIMD width formed from work items that execute in parallel and subgroups are mapped to GPU EU thread. Work-groups, which include work-items that can synchronize and share local data, are assigned for execution on compute units (that is, streaming multiprocessors or Xe core, also known as sub-slices). Finally, the entire global NDRange of work-items maps to the entire GPU.</p><p style="padding-top: 4pt;text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">PRG Interface GPU workgroups</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/comparing-cpus-gpus-and-fpgas-for-oneapi.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To learn more about GPU execution, see </a><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/comparing-cpus-gpus-and-fpgas-for-oneapi.html" class="a" target="_blank">Compare Benefits of CPUs, GPUs, and FPGAs for Different oneAPI </a>Compute Workloads<span style=" color: #000;">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To learn more about Intel<span class="s12">® </span>Iris<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/docs/oneapi/optimization-guide-gpu/2024-0/intel-xe-gpu-architecture.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Xe GPU Architecture, see the </a><span style=" color: #075FA7;">GPU Optimization Guide</span>.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Set Up for GPU Offload</p><ol id="l59"><li data-list-text="1."><p style="padding-top: 4pt;padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;"><a href="#bookmark96" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Make sure you have followed all steps in the </a><span style=" color: #075FA7;">oneAPI Development Environment Setup </span>section, including running the <span class="s18">setvars </span>or <span class="s18">oneapi-vars </span>script.</p></li><li data-list-text="2."><p style="padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;">Configure your GPU system by installing drivers and add the user to the video group. See the Get Started Guide for instructions:</p><ul id="l60"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 44pt;text-indent: -14pt;text-align: left;">Get Started with Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-base-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI Base Toolkit for </a><span style=" color: #075FA7;">Linux* </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-base-windows/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">| </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-base-windows/top.html" target="_blank">Windows*</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 44pt;text-indent: -14pt;text-align: left;">Get Started with Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-hpc-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">HPC Toolkit for </a><span style=" color: #075FA7;">Linux* </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-hpc-windows/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">| </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-intel-oneapi-hpc-windows/top.html" target="_blank">Windows*</a></p></li></ul></li><li data-list-text="3."><p style="padding-top: 1pt;padding-left: 30pt;text-indent: -25pt;line-height: 109%;text-align: left;">Check if you have a supported GPU and the necessary drivers installed using the <span class="s18">sycl-ls </span>command. In the following example, if you had the OpenCL and Level Zero driver installed you would see two entries for each runtime associated with the GPU:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">CPU : OpenCL 2.1 (Build 0)[ 2020.11.12.0.14_160000 ] GPU : OpenCL 3.0 NEO [ 21.33.20678 ]</p><p class="s19" style="text-indent: 0pt;text-align: left;">GPU : 1.1[ 1.2.20939 ]</p></div></li></ol><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l61"><li data-list-text="4."><p style="padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;">Use one of the following code samples to verify that your code is running on the GPU. The code sample adds scalar to large vectors of integers and verifies the results.</p></li></ol><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">To run on a GPU, SYCL provides built-in device selectors using <span class="s18">device_selector </span>as a base class. <span class="s18">gpu_selector </span><a href="https://link.springer.com/book/10.1007%2F978-1-4842-5574-2" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">selects a GPU device. You can also create your own custom selector. For more information, see the Choosing Devices section in </a><a href="https://link.springer.com/book/10.1007%2F978-1-4842-5574-2" class="a" target="_blank">Data Parallel C++: Mastering DPC++ for Programming of Heterogeneous </a><span style=" color: #075FA7;">Systems using C++ and SYCL </span>(book).</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL code sample:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:482.1pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#include &lt;CL/sycl.hpp&gt; #include &lt;array&gt; #include &lt;iostream&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">using namespace sycl; using namespace std;</p><p class="s19" style="text-indent: 0pt;text-align: left;">constexpr size_t array_size = 10000; int main(){</p><p class="s19" style="text-indent: 0pt;text-align: left;">constexpr int value = 100000; try{</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">//</p><p class="s19" style="padding-left: 39pt;text-indent: -39pt;text-align: left;">// The default device selector will select the most performant device. default_selector d_selector;</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">queue q(d_selector);</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">//Allocating shared memory using USM.</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">int *sequential = malloc_shared&lt;int&gt;(array_size, q); int *parallel = malloc_shared&lt;int&gt;(array_size, q);</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">//Sequential iota</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">for (size_t i = 0; i &lt; array_size; i++) sequential[i] = value + i;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">//Parallel iota in SYCL</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">auto e = q.parallel_for(range{array_size}, [=](auto i) { parallel[i] = value + i; }); e.wait();</p><p class="s19" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">// Verify two results are equal.</p><p class="s19" style="padding-left: 29pt;text-indent: -10pt;text-align: left;">for (size_t i = 0; i &lt; array_size; i++) { if (parallel[i] != sequential[i]) {</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">cout &lt;&lt; &quot;Failed on device.\n&quot;; return -1;</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">free(sequential, q); free(parallel, q);</p><p class="s19" style="text-indent: 0pt;text-align: left;">}catch (std::exception const &amp;e) {</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">cout &lt;&lt; &quot;An exception is caught while computing on device.\n&quot;; terminate();</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 9pt;text-indent: -5pt;text-align: left;">cout &lt;&lt; &quot;Successfully completed on device.\n&quot;; return 0;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To compile the code sample, use:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icpx    -fsycl    simple-iota-dp.cpp    -o    simple-iota              </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Results after compilation:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">./simple-iota</p><p class="s19" style="text-indent: 0pt;text-align: left;">Running on device: Intel<span class="s22">® </span>UHD Graphics 630 [0x3e92] Successfully completed on device.</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">OpenMP*</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">OpenMP code sample:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:437.2pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#include &lt;stdlib.h&gt; #include &lt;omp.h&gt; #include &lt;iostream&gt;</p><p class="s19" style="text-indent: 0pt;text-align: left;">constexpr size_t array_size = 10000; #pragma omp requires unified_shared_memory int main(){</p><p class="s19" style="text-indent: 0pt;text-align: left;">constexpr int value = 100000;</p><p class="s19" style="text-indent: 0pt;text-align: left;">// Returns the default target device.</p><p class="s19" style="text-indent: 0pt;text-align: left;">int deviceId = (omp_get_num_devices() &gt; 0) ? omp_get_default_device() : omp_get_initial_device(); int *sequential = (int *)omp_target_alloc_host(array_size, deviceId);</p><p class="s19" style="text-indent: 0pt;text-align: left;">int *parallel = (int *)omp_target_alloc(array_size, deviceId);</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 79pt;text-indent: -39pt;text-align: left;">for (size_t i = 0; i &lt; array_size; i++) sequential[i] = value + i;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">#pragma omp target parallel for</p><p class="s19" style="padding-left: 79pt;text-indent: -39pt;text-align: left;">for (size_t i = 0; i &lt; array_size; i++) parallel[i] = value + i;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 44pt;text-indent: -5pt;text-align: left;">for (size_t i = 0; i &lt; array_size; i++) { if (parallel[i] != sequential[i]) {</p><p class="s19" style="padding-left: 54pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Failed on device.\n&quot;; return -1;</p><p class="s19" style="padding-left: 44pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">omp_target_free(sequential, deviceId); omp_target_free(parallel, deviceId);</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 44pt;text-indent: -5pt;text-align: left;">std::cout &lt;&lt; &quot;Successfully completed on device.\n&quot;; return 0;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To compile the code sample, use:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icpx  -fsyclsimple-iota-omp.cpp  -fiopenmp  -fopenmp-targets=spir64  -o  simple-iota     </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Results after compilation:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="padding-left: 4pt;text-indent: 0pt;line-height: 10pt;text-align: left;">./simple-iota</p><p class="s19" style="text-indent: 0pt;text-align: left;">Successfully completed on device.</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 110%;text-align: left;"><b>NOTE </b>If you have an offload region present and no accelerator, the kernel falls back to traditional host compilation (without the OpenCL runtime) unless you are using the environment variable <span class="s18">OMP_TARGET_OFFLOAD=mandatory</span>.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Offload Code to GPU</p><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/gpu-optimization-workflow.html#gs.fuzf1w" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To decide which GPU hardware and what parts of the code to offload, refer to the </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/gpu-optimization-workflow.html#gs.fuzf1w" class="a" target="_blank">GPU optimization workflow </a>guide<span style=" color: #000;">.</span></p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/advisor-user-guide/top/model-offloading-to-a-gpu.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To find opportunities to offload your code to GPU, use the </a>Intel Advisor for Offload Modeling<span style=" color: #000;">.</span></p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Debug GPU Code</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following list has some basic debugging tips for offloaded code.</p><ul id="l62"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Check CPU or host/target or switch runtime to OpenCL to verify the correctness of code.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">You could use printf to debug your application. Both SYCL and OpenMP offload support printf in kernel code.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Use environment variables to control verbose log information.</p><p class="s13" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For SYCL, the following debug environment variables are recommended. A full list is available from </a>GitHub<span style=" color: #000;">.</span></p><p class="s25" style="padding-top: 8pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Debugging Tips, Offloaded Code</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s14" style="text-indent: 0pt;text-align: left;">Description</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Value</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Name</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 12pt;text-indent: 0pt;text-align: left;"><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md#ONEAPI_DEVICE_SELECTOR" style=" color: black; font-family:&quot;Courier New&quot;, monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt;" target="_blank">ONEAPI_DEVICE_SELECTOR   backend:device_type:device_ </a><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md#ONEAPI_DEVICE_SELECTOR" target="_blank">GitHub description</a></p><p class="s18" style="padding-top: 2pt;padding-left: 177pt;text-indent: 0pt;text-align: left;">num</p><p class="s14" style="padding-top: 9pt;padding-left: 344pt;text-indent: -331pt;line-height: 107%;text-align: left;"><span class="s18">SYCL_UR_TRACE        </span>1|2|-1               1<span class="p">: print out the basic trace log of the DPC++ runtime plugin </span>2<span class="p">: print out all API traces of DPC++ runtime plugin </span>-1<span class="p">: all of “2” including more debug messages</span></p><p class="s18" style="padding-top: 8pt;padding-left: 177pt;text-indent: -165pt;text-align: left;">ZE_DEBUG         <span class="p">Variable defined with any value - enabled</span></p><p style="padding-top: 8pt;padding-left: 12pt;text-indent: 0pt;line-height: 110%;text-align: left;">This environment variable enables debug output from the Level Zero backend when used with the DPC++ runtime. It reports: * Level Zero APIs called</p><p style="padding-left: 12pt;text-indent: 0pt;line-height: 11pt;text-align: left;">* Level Zero event information</p><p class="s13" style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://openmp.llvm.org//design/Runtimes.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For OpenMP, the following debug environment variables are recommended. A full list is available from the </a>LLVM/OpenMP documentation<span style=" color: #000;">.</span></p><p class="s25" style="padding-top: 7pt;padding-bottom: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Recommended OpenMP Debug Environment Variables</p><table style="border-collapse:collapse;margin-left:5.69292pt" cellspacing="0"><tr style="height:21pt"><td style="width:155pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">Name</p></td><td style="width:176pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Value</p></td><td style="width:168pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">Description</p></td></tr><tr style="height:22pt"><td style="width:155pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 6pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_DEVICETYPE</p></td><td style="width:176pt;border-top-style:solid;border-top-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">cpu | gpu</p></td><td style="width:168pt;border-top-style:solid;border-top-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">Select</p></td></tr><tr style="height:33pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_DEBUG</p></td><td style="width:176pt"><p class="s26" style="padding-top: 4pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">1</p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 8pt;padding-right: 3pt;text-indent: 0pt;line-height: 110%;text-align: left;">Print out verbose debug information</p></td></tr><tr style="height:45pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_INFO</p></td><td style="width:176pt;border-bottom-style:solid;border-bottom-width:1pt"><p style="padding-top: 4pt;padding-left: 17pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://openmp.llvm.org//design/Runtimes.html" class="s27" target="_blank">Values available in LLVM/OpenMP documentation</a></p></td><td style="width:168pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 8pt;padding-right: 3pt;text-indent: 0pt;line-height: 110%;text-align: left;">Allows the user to request different types of runtime information from <span class="s19">libomptarget</span></p></td></tr></table><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Use Ahead of Time (AOT) to move Just-in-Time (JIT) compilations to AOT compilation issues.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">CL_OUT_OF_RESOURCES <span class="p">Error</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The <b>CL_OUT_OF_RESOURCES </b>error can occur when a kernel uses more <span class="s32">&nbsp;&nbsp;&nbsp; </span><span class="s18">private </span>or <span class="s32">&nbsp;&nbsp;&nbsp; </span><span class="s18">local </span>memory than the emulator supports by default.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">When this occurs, you will see an error message similar to this:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:89.7pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ ./myapp</p><p class="s19" style="text-indent: 0pt;text-align: left;">:</p><p class="s19" style="text-indent: 0pt;text-align: left;">Problem size: c(150,600) = a(150,300) * b(300,600)</p><p class="s19" style="padding-left: 9pt;text-indent: -10pt;text-align: left;">terminate called after throwing an instance of &#39;cl::sycl::runtime_error&#39; what(): Native API failed. Native API returns: -5 (CL_OUT_OF_RESOURCES) -5</p><p class="s19" style="text-indent: 0pt;text-align: left;">(CL_OUT_OF_RESOURCES)</p><p class="s19" style="text-indent: 0pt;text-align: left;">Aborted (core dumped)</p><p class="s19" style="text-indent: 0pt;text-align: left;">$</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Or if using onetrace:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:134.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ onetrace -c ./myapp</p><p class="s19" style="text-indent: 0pt;text-align: left;">:</p><p class="s19" style="text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [6254070891] zeKernelSuggestGroupSize: hKernel = 0x263b7a0 globalSizeX = 163850 globalSizeY</p><p class="s19" style="text-indent: 0pt;text-align: left;">= 1 globalSizeZ = 1 groupSizeX = 0x7fff94e239f0 groupSizeY = 0x7fff94e239f4 groupSizeZ = 0x7fff94e239f8</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [6254082074] zeKernelSuggestGroupSize [922 ns] -&gt; ZE_RESULT_ERROR_OUT_OF_DEVICE_MEMORY(0x1879048195)</p><p class="s19" style="padding-left: 9pt;text-indent: -10pt;text-align: left;">terminate called after throwing an instance of &#39;cl::sycl::runtime_error&#39; what(): Native API failed. Native API returns: -5 (CL_OUT_OF_RESOURCES) -5</p><p class="s19" style="text-indent: 0pt;text-align: left;">(CL_OUT_OF_RESOURCES)</p><p class="s19" style="text-indent: 0pt;text-align: left;">Aborted (core dumped)</p><p class="s19" style="text-indent: 0pt;text-align: left;">$</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">To see how much memory was being copied to shared local memory and the actual hardware limit, set debug keys:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">export PrintDebugMessages=1 export NEOReadDebugKeys=1</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">This will change the output to:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:89.7pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ ./myapp</p><p class="s19" style="text-indent: 0pt;text-align: left;">:</p><p class="s19" style="text-indent: 0pt;text-align: left;">Size of SLM (656384) larger than available (131072)</p><p class="s19" style="padding-left: 9pt;text-indent: -10pt;text-align: left;">terminate called after throwing an instance of &#39;cl::sycl::runtime_error&#39; what(): Native API failed. Native API returns: -5 (CL_OUT_OF_RESOURCES) -5</p><p class="s19" style="text-indent: 0pt;text-align: left;">(CL_OUT_OF_RESOURCES)</p><p class="s19" style="text-indent: 0pt;text-align: left;">Aborted (core dumped)</p><p class="s19" style="text-indent: 0pt;text-align: left;">$</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Or, if using onetrace:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:112.1pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ onetrace -c ./myapp</p><p class="s19" style="text-indent: 0pt;text-align: left;">:</p><p class="s19" style="text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [317651739] zeKernelSuggestGroupSize: hKernel = 0x2175ae0 globalSizeX = 163850 globalSizeY</p><p class="s19" style="text-indent: 0pt;text-align: left;">= 1 globalSizeZ = 1 groupSizeX = 0x7ffd9caf0950 groupSizeY = 0x7ffd9caf0954 groupSizeZ = 0x7ffd9caf0958</p><p class="s19" style="text-indent: 0pt;text-align: left;">Size of SLM (656384) larger than available (131072)</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [317672417] zeKernelSuggestGroupSize [10325 ns] -&gt; ZE_RESULT_ERROR_OUT_OF_DEVICE_MEMORY(0x1879048195)</p><p class="s19" style="padding-left: 9pt;text-indent: -10pt;text-align: left;">terminate called after throwing an instance of &#39;cl::sycl::runtime_error&#39; what(): Native API failed. Native API returns: -5 (CL_OUT_OF_RESOURCES) -5</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">(CL_OUT_OF_RESOURCES)</p><p class="s19" style="text-indent: 0pt;text-align: left;">Aborted (core dumped)</p><p class="s19" style="text-indent: 0pt;text-align: left;">$</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="#bookmark162" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">See </a>Debugging the DPC++ and OpenMP Offload Process <span style=" color: #000;">for more information on debug techniques and debugging tools available with oneAPI.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Optimize GPU Code</p><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-gpu-optimization-guide/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">There are multiple ways to optimize offloaded code. The following list provides some starting points. Review the </a>oneAPI GPU Optimization Guide <span style=" color: #000;">for additional information.</span></p><ul id="l63"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Reduce overhead of memory transfers between host and device.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Have enough work to keep the cores busy and reduce the data transfer overhead cost.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Use GPU memory hierarchy like GPU caches, shared local memory for faster memory accesses.</p></li><li data-list-text="•"><p class="s13" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="#bookmark124" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Use AOT compilation (offline compilation) instead of JIT compilation. With offline compilation, you could target your code to specific GPU architecture. Refer to </a>Offline Compilation for GPU <span style=" color: #000;">for details.</span></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 112%;text-align: left;"><a href="https://oneapi-src.github.io/oneAPI-samples/Tools/GPU-Occupancy-Calculator/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The </a><a href="https://oneapi-src.github.io/oneAPI-samples/Tools/GPU-Occupancy-Calculator/" class="a" target="_blank">Intel</a><a href="https://oneapi-src.github.io/oneAPI-samples/Tools/GPU-Occupancy-Calculator/" class="s16" target="_blank">® </a><span style=" color: #075FA7;">GPU Occupancy Calculator </span>allows you to compute the occupancy of an Intel<span class="s12">® </span>GPU for a given kernel and work group parameters.</p></li></ul><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="#bookmark163" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Additional recommendations are available from </a>Optimize Offload Performance<span style=" color: #000;">.</span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark34">&zwnj;</a>Example GPU Commands<a name="bookmark123">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The examples below illustrate how to create and use static libraries with device code on Linux.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">Linking with a dynamic library is not supported.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Produce a fat object with device code:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icpx       -fsycl       -c       static_lib.cpp                  </span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Create a fat static library out of it using the ar tool:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">ar       cr       libstlib.a       static_lib.o                  </span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Compile application sources:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icpx       -fsycl       -c       a.cpp                     </span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Link the application with the static library:</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icpx   -fsycl   -foffload-static-lib=libstlib.a   a.o   -o   a.exe           </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark35">&zwnj;</a>Ahead-of-Time Compilation for GPU<a name="bookmark124">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 143%;text-align: left;">The following example command produces <span class="s18">app.out </span>for a specific GPU target: For DPC++:</p><p style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">icpx -fsycl -fsycl-targets=spir64_gen -Xs &quot;-device &lt;device name&gt;&quot; a.cpp b.cpp -o app.out   </span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For OpenMP*offload:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">icpx -fiopenmp -fopenmp-targets=spir64_gen -Xopenmp-target-backend &quot;-device &lt;device name&gt;&quot; a.cpp b.cpp -o app.out</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s13" style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compilation/ahead-of-time-compilation.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">A list of allowed values for the device name are available from the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compilation/ahead-of-time-compilation.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compilation/ahead-of-time-compilation.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compilation/ahead-of-time-compilation.html" class="a" target="_blank">oneAPI DPC++/C++ Compiler </a>Developer Guide and Reference<span style=" color: #000;">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark36">&zwnj;</a>FPGA Flow<a name="bookmark125">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Field-programmable gate arrays (FPGAs) are configurable integrated circuits that you can program to implement arbitrary circuit topologies. Classified as spatial compute architectures, FPGAs differ significantly from fixed Instruction Set Architecture (ISA) devices such as CPUs and GPUs. FPGAs offer a different set of optimization trade-offs from these traditional accelerator devices.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">While you can compile SYCL* code for CPU, GPU or FPGA, the compiling process for FPGA development is somewhat different than that for CPU or GPU development.</p><p style="padding-top: 8pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">FPGA support in the Intel<span class="s12">® </span>oneAPI DPC++/C++</p><p style="padding-left: 7pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Compiler requires the</p><p style="padding-top: 6pt;padding-left: 3pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" class="a" target="_blank">FPGA Support Package for the Intel</a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" target="_blank">oneAPI DPC++/C++ Compiler</a></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/current.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For full details about the FPGA flow, refer to the </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/current.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/current.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/current.html" class="a" target="_blank">oneAPI DPC++/C++ Compiler Handbook for Intel</a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/current.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/current.html" target="_blank">FPGAs</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-left: 35pt;text-indent: 0pt;text-align: left;">Tip <a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming/C%2B%2BSYCL_FPGA" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Learn about programming SYCL* programming for FPGA devices by reviewing the </a><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming/C%2B%2BSYCL_FPGA" class="a" target="_blank">oneAPI Samples </a><span class="s13">for FPGAs </span><span class="p">on GitHub.</span></p><p style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">You can also learn about programming for FPGA devices in detail from the <i>Data Parallel C++ </i><a href="https://link.springer.com/chapter/10.1007/978-1-4842-5574-2_17" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">book available at </a><span style=" color: #075FA7;">https://link.springer.com/chapter/10.1007/978-1-4842-5574-2_17</span>.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark37">&zwnj;</a>Why is FPGA Compilation Different?<a name="bookmark126">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">FPGAs differ from CPUs and GPUs in some important ways. A significant difference between compilation for CPU or GPU and compilation for FPGA is that generating a device binary for FPGA hardware is a computationally intensive and time-consuming process. It is normal for an FPGA compile to take several hours to complete. For this reason, only ahead-of-time (or <i>offline</i>) kernel compilation mode is supported for FPGA. The long compile time for FPGA hardware makes just-in-time (or <i>online</i>) compilation impractical, and is therefore not supported.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Longer compile times are detrimental to developer productivity. The Intel<span class="s12">® </span>oneAPI DPC++/C++ Compiler provides several mechanisms that enable you to target FPGA and iterate quickly on your designs. By circumventing the time-consuming process of full FPGA compilation wherever possible, you can benefit from the faster compile times that you are familiar with for CPU and GPU development.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/current.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/current.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/current.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/current.html" class="a" target="_blank">oneAPI DPC++/C++ Compiler Handbook for Intel</a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/current.html" class="s16" target="_blank">® </a>FPGAs <span style=" color: #000;">provides full details about the FPGA flow.</span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark38">&zwnj;</a>Types of SYCL* FPGA Compilation<a name="bookmark127">&zwnj;</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL supports accelerators in general. The FPGA Support Package for the Intel<span class="s12">® </span>oneAPI DPC++/C++ Compiler adds FPGA-specific support to the Intel<span class="s12">® </span>oneAPI DPC++/C++ Compiler to assist FPGA code development. This topic highlights different FPGA compilation flows that the FPGA Support Package supports.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 148%;text-align: left;"><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming/C%2B%2BSYCL_FPGA/Tutorials/GettingStarted/fpga_compile" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For a hands-on lesson in the types of FPGA compilation, review the </a>FPGA Compile Sample <span style=" color: #000;">on GitHub. The following table summarizes the types of FPGA compilation:</span></p><p class="s25" style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Types of FPGA Compilation</p><table style="border-collapse:collapse;margin-left:5.69292pt" cellspacing="0"><tr style="height:30pt"><td style="width:118pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">Device Image Type</p></td><td style="width:71pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 15pt;padding-right: 15pt;text-indent: 0pt;text-align: left;">Time to Compile</p></td><td style="width:310pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Description</p></td></tr><tr style="height:42pt"><td style="width:118pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">FPGA Emulator</p></td><td style="width:71pt;border-top-style:solid;border-top-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Seconds</p></td><td style="width:310pt;border-top-style:solid;border-top-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 16pt;padding-right: 6pt;text-indent: 0pt;text-align: left;">Compiles the FPGA device code to the CPU. Use the Intel<span class="s34">® </span>FPGA Emulation Platform for OpenCL<span class="s34">™ </span>software to verify your SYCL code’s functional correctness.</p></td></tr><tr style="height:96pt"><td style="width:118pt;border-left-style:solid;border-left-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 6pt;padding-right: 16pt;text-indent: 0pt;text-align: left;">FPGA Optimization Report</p></td><td style="width:71pt"><p class="s28" style="padding-top: 4pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Minutes</p></td><td style="width:310pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 16pt;padding-right: 6pt;text-indent: 0pt;text-align: left;">Partially compiles the FPGA device code for hardware to generate an optimization report that describes the structures generated on the FPGA, identifies performance bottlenecks, and estimates resource utilization. When your compilation targets an FPGA device family or part number, this stage also give you RTL files for the IP component in your code. You can then use Quartus<span class="s34">® </span>Prime Software to integrate your IP components into a larger design.</p></td></tr><tr style="height:31pt"><td style="width:118pt;border-left-style:solid;border-left-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">FPGA Simulator</p></td><td style="width:71pt"><p class="s28" style="padding-top: 4pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Minutes</p></td><td style="width:310pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">Compiles the FPGA device code to the CPU. Use the Questa*- Intel<span class="s34">® </span>FPGA Edition simulator to debug your code.</p></td></tr><tr style="height:85pt"><td style="width:118pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 6pt;padding-right: 31pt;text-indent: 0pt;text-align: left;">FPGA Hardware Image</p></td><td style="width:71pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Hours</p></td><td style="width:310pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 16pt;padding-right: 5pt;text-indent: 0pt;text-align: left;">When your compilation targets an FPGA acceleration board, this stage generates the real FPGA bitstream to execute on the target FPGA platform. When your compilation targets an FPGA device family or part number, this stage also gives you RTL files for the IP component in your code. You can then use Quartus<span class="s34">® </span>Prime Software to integrate your IP components into a larger design.</p></td></tr></table><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">A typical FPGA development workflow is to iterate in the emulation, optimization report, and simulation stages, refining your code using the feedback provided by each stage. Intel<span class="s12">® </span>recommends relying on emulation and the FPGA optimization report whenever possible.</p><p style="padding-top: 11pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-left: 35pt;text-indent: 0pt;text-align: left;">Tip <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To compile for FPGA emulation or FPGA simulation, and to generate the FPGA optimization report, the </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" class="a" target="_blank">FPGA Support Package for the Intel</a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" class="s16" target="_blank">® </a><span class="s13">oneAPI DPC++/C++ Compiler </span><span class="p">is required.</span></p><p class="s13" style="padding-left: 35pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/products/details/fpga/development-tools/quartus-prime.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To compile on FPGA hardware, you must also install the </a><a href="https://www.intel.com/content/www/us/en/products/details/fpga/development-tools/quartus-prime.html" class="a" target="_blank">Quartus</a><a href="https://www.intel.com/content/www/us/en/products/details/fpga/development-tools/quartus-prime.html" class="s16" target="_blank">® </a>Prime Software<span style=" color: #000;">. Targeting a board also requires that you install the BSP for the board.</span></p><p class="s13" style="padding-top: 5pt;padding-left: 35pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/articles/guide/installation-guide-for-oneapi-toolkits.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For more information, refer to the </a><a href="https://www.intel.com/content/www/us/en/developer/articles/guide/installation-guide-for-oneapi-toolkits.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/developer/articles/guide/installation-guide-for-oneapi-toolkits.html" class="s16" target="_blank">® </a>oneAPI Toolkits Installation Guide <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">and </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" class="a" target="_blank">FPGA </a>development flow <span style=" color: #000;">webpage.</span></p><p style="padding-top: 5pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: justify;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Generating an RTL IP core requires only the </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" class="a" target="_blank">FPGA Support Package for the Intel</a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/fpga.html" class="a" target="_blank">oneAPI DPC++/C++ </a><span style=" color: #075FA7;">Compiler </span>Simulating or integrating that IP core into your hardware design requires the Quartus<span class="s12">® </span>Prime Pro Edition Software.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">FPGA Emulator</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The FPGA emulator (Intel<span class="s12">® </span>FPGA Emulation Platform for OpenCL<span class="s12">™ </span>software) is the fastest method to verify the correctness of your code. It executes the SYCL device code on the CPU. The emulator is similar to the SYCL host device, but unlike the host device, the FPGA emulator device supports FPGA extensions such as FPGA pipes and <span class="s18">fpga_reg</span><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/pipes-extension.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">. For more information, refer to </a><span style=" color: #075FA7;">Pipes Extension </span><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/kernel-variables.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">and </a><span style=" color: #075FA7;">Kernel Variables </span>topics in the <i>Intel oneAPI FPGA Handbook</i>.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following are some important caveats to remember when using the FPGA emulator:</p><ul id="l64"><li data-list-text="•"><p class="s14" style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Performance is not representative<span class="p">.</span></p><p style="padding-top: 6pt;padding-left: 19pt;text-indent: 0pt;line-height: 110%;text-align: left;">Never draw inferences about FPGA performance from the FPGA emulator. The FPGA emulator’s timing behavior is not correlated to that of the physical FPGA hardware. For example, an optimization that yields a 100x performance improvement on the FPGA may not impact the emulator performance. The emulator might show an unrelated increase or decrease.</p></li><li data-list-text="•"><p class="s14" style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Undefined behavior may differ<span class="p">.</span></p><p style="padding-top: 6pt;padding-left: 19pt;text-indent: 0pt;line-height: 110%;text-align: left;">If your code produces different results when compiled for the FPGA emulator versus FPGA hardware, your code most likely exercises undefined behavior. By definition, undefined behavior is not specified by the language specification and might manifest differently on different targets.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/emulate-and-debug-your-design.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For detailed information about emulation your kernels, refer to </a><span style=" color: #075FA7;">Emulate Your Kernel </span>in the <i>Intel oneAPI FPGA Handbook</i>.</p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">FPGA Optimization Report</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The FPGA Optimization Report is generated in the following compilation stages:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.69292pt" cellspacing="0"><tr style="height:33pt"><td style="width:155pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">Stages</p></td><td style="width:176pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Description</p></td><td style="width:168pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 9pt;padding-right: 55pt;text-indent: 0pt;line-height: 110%;text-align: left;">Optimization Report Information</p></td></tr><tr style="height:17pt"><td style="width:155pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;line-height: 10pt;text-align: left;">FPGA Optimization Report</p></td><td style="width:176pt;border-top-style:solid;border-top-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 17pt;text-indent: 0pt;line-height: 10pt;text-align: left;">The SYCL device code is</p></td><td style="width:168pt;border-top-style:solid;border-top-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 7pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Contains important information</p></td></tr><tr style="height:12pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p class="s26" style="padding-left: 6pt;text-indent: 0pt;line-height: 10pt;text-align: left;">image <span class="s28">(Compilation takes</span></p></td><td style="width:176pt"><p class="s28" style="padding-left: 17pt;text-indent: 0pt;line-height: 10pt;text-align: left;">optimized and converted into an</p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 7pt;text-indent: 0pt;line-height: 10pt;text-align: left;">about how the compiler has</p></td></tr><tr style="height:12pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p class="s28" style="padding-left: 6pt;text-indent: 0pt;line-height: 10pt;text-align: left;">minutes to complete)</p></td><td style="width:176pt"><p class="s28" style="padding-left: 17pt;text-indent: 0pt;line-height: 10pt;text-align: left;">FPGA design specified in the</p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 7pt;text-indent: 0pt;line-height: 10pt;text-align: left;">transformed your SYCL device</p></td></tr><tr style="height:12pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:176pt"><p style="padding-left: 17pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><a href="https://www.youtube.com/watch?v=zm-RA6BsYmc" class="s27">Verilog Register-Transfer Level</a></p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 7pt;text-indent: 0pt;line-height: 10pt;text-align: left;">code into an FPGA design. The</p></td></tr><tr style="height:12pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:176pt"><p class="s29" style="padding-left: 17pt;text-indent: 0pt;line-height: 10pt;text-align: left;">(RTL) <span style=" color: #000;">(a low-level, native entry</span></p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 7pt;text-indent: 0pt;line-height: 10pt;text-align: left;">report includes the following</p></td></tr><tr style="height:12pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:176pt"><p class="s28" style="padding-left: 17pt;text-indent: 0pt;line-height: 10pt;text-align: left;">language for FPGAs). The</p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 7pt;text-indent: 0pt;line-height: 10pt;text-align: left;">information:</p></td></tr><tr style="height:12pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:176pt"><p class="s28" style="padding-left: 17pt;text-indent: 0pt;line-height: 10pt;text-align: left;">intermediate compilation result is</p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"/></tr><tr style="height:15pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:176pt"><p class="s28" style="padding-left: 17pt;text-indent: 0pt;text-align: left;">the FPGA early device image that</p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 5pt;padding-left: 21pt;text-indent: 0pt;line-height: 8pt;text-align: left;">generated on the FPGA.</p></td></tr><tr style="height:15pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:176pt"><p class="s28" style="padding-left: 17pt;text-indent: 0pt;line-height: 9pt;text-align: left;">is not an executable.</p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"/></tr><tr style="height:13pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:176pt"><p class="s28" style="padding-left: 17pt;text-indent: 0pt;line-height: 10pt;text-align: left;">The optimization report</p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 21pt;text-indent: 0pt;line-height: 11pt;text-align: left;">performance bottleneck.</p></td></tr><tr style="height:13pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:176pt"><p class="s28" style="padding-left: 17pt;text-indent: 0pt;line-height: 10pt;text-align: left;">generated at this stage is static</p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"/></tr><tr style="height:16pt"><td style="width:155pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:176pt"><p class="s28" style="padding-left: 17pt;text-indent: 0pt;text-align: left;">in nature.</p></td><td style="width:168pt;border-right-style:solid;border-right-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td></tr></table><ul id="l65"><li data-list-text="•"><p class="s28" style="padding-top: 5pt;padding-left: 21pt;text-indent: -14pt;line-height: 6pt;text-align: left;">Visualizations of structures</p></li></ul><ul id="l66"><li data-list-text="•"><p class="s28" style="padding-top: 3pt;padding-left: 21pt;text-indent: -14pt;line-height: 10pt;text-align: left;">Performance and expected</p></li></ul><ul id="l67"><li data-list-text="•"><p class="s28" style="padding-left: 21pt;text-indent: -14pt;line-height: 11pt;text-align: left;">Estimated resource utilization.</p></li></ul><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.69292pt" cellspacing="0"><tr style="height:33pt"><td style="width:152pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">Stages</p></td><td style="width:180pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 22pt;text-indent: 0pt;text-align: left;">Description</p></td><td style="width:167pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 8pt;padding-right: 54pt;text-indent: 0pt;line-height: 110%;text-align: left;">Optimization Report Information</p></td></tr><tr style="height:215pt"><td style="width:152pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s26" style="padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: left;">FPGA hardware image <span class="s28">(Compilation takes hours to complete)</span></p></td><td style="width:180pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s29" style="padding-left: 20pt;padding-right: 4pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/programmable/products/design-software/fpga-design/quartus-prime/user-guides.html" class="s47" target="_blank">The Verilog RTL specifying the design’s circuit topology is mapped onto the FPGA’s primitive hardware resources by the </a><a href="https://www.intel.com/content/www/us/en/programmable/products/design-software/fpga-design/quartus-prime/user-guides.html" class="s27" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/programmable/products/design-software/fpga-design/quartus-prime/user-guides.html" class="s35" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/programmable/products/design-software/fpga-design/quartus-prime/user-guides.html" class="s27" target="_blank">Quartus</a><a href="https://www.intel.com/content/www/us/en/programmable/products/design-software/fpga-design/quartus-prime/user-guides.html" class="s35" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/programmable/products/design-software/fpga-design/quartus-prime/user-guides.html" class="s27" target="_blank">Prime pro Edition </a>Software<span style=" color: #000;">. The result is an FPGA hardware binary (also referred to as a bitstream).</span></p></td><td style="width:167pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s37" style="padding-top: 4pt;padding-left: 6pt;padding-right: 8pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/fpga-report.html" class="s47" target="_blank">For information about the FPGA optimization report, refer to the </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/fpga-report.html" class="s27" target="_blank">Review the FPGA Optimization </a><span class="s29">Report </span><span class="s28">in the </span>Intel<span class="s38">® </span>oneAPI FPGA Handbook<span class="s28">.</span></p><p class="s28" style="padding-top: 8pt;padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 110%;text-align: left;">Contains precise information about resource utilization and f<span class="s39">MAX</span><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/analyzing-your-design.html" class="s47" target="_blank"> numbers. For detailed information about how to analyze reports, refer to </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/analyzing-your-design.html" class="s27" target="_blank">Analyze your </a><span style=" color: #075FA7;">Design </span>in the <i>Intel</i><span class="s38">® </span><i>oneAPI FPGA Handbook</i>.</p><p class="s29" style="padding-top: 5pt;padding-left: 6pt;padding-right: 8pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-0/analyze-the-fpga-image.html" class="s47" target="_blank">For information about the FPGA hardware image, refer to the </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-0/analyze-the-fpga-image.html" class="s27" target="_blank">Intel oneAPI DPC++/C++ </a>Compiler Handbook for FPGAs<span style=" color: #000;">.</span></p></td></tr></table><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">When your compilation targets an FPGA device or part number, this stage gives you RTL files for the IP component in your code. You can then use Quartus<span class="s12">® </span>Prime Software to integrate your IP components into a larger design.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">FPGA Simulator</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The simulation flow allows you to use the Questa*-Intel<span class="s12">® </span>FPGA Edition simulator software to simulate the exact behavior of the synthesized kernel. Like emulation, you can run simulation on a system that does not have a target FPGA board installed. The simulator models a kernel much more accurately than the emulator, but it is much slower than the emulator.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The simulation flow is cycle-accurate and bit-accurate. It exactly models the behavior of a kernel datapath and the results of operations on floating-point data types. However, simulation cannot accurately model variable-latency memories or other external interfaces. Intel recommends that you simulate your design with a small input dataset because simulation is much slower than running on FPGA hardware or emulator.</p><p class="s20" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/intel-fpga-dynamic-profiler-for-dpc.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">You can use the simulation flow in conjunction with profiling to collect additional information about your design. For more information about profiling, refer to </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/intel-fpga-dynamic-profiler-for-dpc.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/intel-fpga-dynamic-profiler-for-dpc.html" class="s16" target="_blank">® </a><span class="s13">FPGA Dynamic Profiler for DPC++ </span><span class="p">in the </span>Intel<span class="s24">® </span>oneAPI FPGA Handbook<span class="p">.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 110%;text-align: left;">NOTE <span class="p">You cannot debug kernel code compiled for simulation using the GNU Project Debugger (GDB)*, Microsoft* Visual Studio*, or any standard software debugger.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/evaluate-your-kernel-through-simulation.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For more information about the simulation flow, refer to </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/evaluate-your-kernel-through-simulation.html" class="a" target="_blank">Evaluate Your Kernel Through </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/evaluate-your-kernel-through-simulation.html" target="_blank">Simulation</a></p><p class="s20" style="padding-top: 5pt;padding-left: 1pt;text-indent: 0pt;text-align: left;"><span class="p">in the </span>Intel<span class="s24">® </span>oneAPI FPGA Handbook<span class="p">.</span></p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">FPGA Hardware</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;">An FPGA hardware compilation requires the Quartus<span class="s12">® </span>Prime Software (installed separately). This is a full compilation stage through to the FPGA hardware image where you can target one of the following:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Altera<span class="s12">® </span>FPGA device family</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Specific Altera<span class="s12">® </span>FPGA device part number</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Custom board with a supported BSP</p><p class="s13" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/articles/system-requirements/intel-oneapi-dpcpp-system-requirements.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For more information about the targets, refer to the </a><a href="https://www.intel.com/content/www/us/en/developer/articles/system-requirements/intel-oneapi-dpcpp-system-requirements.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/developer/articles/system-requirements/intel-oneapi-dpcpp-system-requirements.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/developer/articles/system-requirements/intel-oneapi-dpcpp-system-requirements.html" class="a" target="_blank">oneAPI DPC++/C++ Compiler System </a>Requirements<span style=" color: #000;">. For more information about using Intel</span><span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/fpga-boards-and-board-support-packages-bsps.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">PAC or custom boards, refer to </a><a href="https://www.intel.com/content/www/us/en/docs/oneapi-fpga-add-on/developer-guide/2024-2/fpga-boards-and-board-support-packages-bsps.html" class="a" target="_blank">FPGA Boards and </a>Board Support Packages (BSPs) <span style=" color: #000;">in the </span><span class="s20">Intel</span><span class="s24">® </span><span class="s20">oneAPI FPGA Handbook </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/installation-guide-for-intel-oneapi-toolkits-linux/top/installation/set-up-a-system-for-fpga-with-the-intel-pac.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">and the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/installation-guide-for-intel-oneapi-toolkits-linux/top/installation/set-up-a-system-for-fpga-with-the-intel-pac.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/installation-guide-for-intel-oneapi-toolkits-linux/top/installation/set-up-a-system-for-fpga-with-the-intel-pac.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/installation-guide-for-intel-oneapi-toolkits-linux/top/installation/set-up-a-system-for-fpga-with-the-intel-pac.html" class="a" target="_blank">oneAPI Toolkits </a>Installation Guide for Linux* OS Installation Guide<span style=" color: #000;">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark39">&zwnj;</a>API-Based &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Programming &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a name="bookmark128">&zwnj;</a></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Several libraries are available with Intel<span class="s12">® </span>oneAPI toolkits that can simplify the programming process by providing specialized APIs for use in optimized applications. This chapter provides basic details about the libraries, including code samples, to help guide the decision on which library is most useful in certain use cases. Detailed information about each library, including more about the available APIs, is available in the main documentation for that library.</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;">Use this library for high performance parallel applications.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;">Use this library to include highly optimized and extensively parallelized math routines in an application.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;">Use this library to combine TBB-based parallelism on multicore CPUs and SYCL* device-accelerated parallelism in an application.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;">Use this library to speed up big data analysis applications and distributed computation.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;">Use this library for applications that focus on Deep Learning and Machine Learning workloads.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;">Use this library for deep learning applications that use neural networks optimized for Intel Architecture Processors and Intel Processor Graphics.</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 269%;text-align: left;"><a href="#bookmark130" class="a">Intel</a><a href="#bookmark130" class="s16">® </a><a href="#bookmark133" class="a">oneAPI DPC++ Library Intel</a><a href="#bookmark133" class="s16">® </a><a href="#bookmark133" class="a">oneAPI Math Kernel </a><a href="#bookmark133">Library</a></p><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><a href="#bookmark136" class="a">Intel</a><a href="#bookmark136" class="s16">® </a><a href="#bookmark136">oneAPI Threading Building Blocks</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><a href="#bookmark139" class="a">Intel</a><a href="#bookmark139" class="s16">® </a><a href="#bookmark139">oneAPI Data Analytics Library</a></p><p style="text-indent: 0pt;line-height: 30pt;text-align: left;"><a href="#bookmark143" class="a">Intel</a><a href="#bookmark143" class="s16">® </a><a href="#bookmark143" class="a">oneAPI Collective Communications </a><a href="#bookmark146" class="a">Library Intel</a><a href="#bookmark146" class="s16">® </a><a href="#bookmark146">oneAPI Deep Neural Network Library</a></p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Usage</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Library</p><p style="text-indent: 0pt;text-align: left;"/><p class="s25" style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">oneAPI Toolkit Libraries</p><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">Explore the complete list of oneAPI code samples in the </span>oneAPI Samples Catalog &lt;https:// oneapi-src.github.io/oneAPI-samples/&gt; <span class="p">(GitHub*). These samples were designed to help you develop, offload, and optimize multiarchitecture applications targeting CPUs, GPUs, and FPGAs.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark40">&zwnj;</a>Intel® oneAPI DPC++ Library (oneDPL)<a name="bookmark129">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark130">&zwnj;</a>The Intel<span class="s12">® </span>oneAPI DPC++ Library (oneDPL) aims to work with the Intel<span class="s12">® </span>oneAPI DPC++/C++ Compiler to provide high-productivity APIs to developers, which can minimize SYCL* programming efforts across devices for high performance parallel applications.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">oneDPL consists of the following components:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Parallel STL:</p><ul id="l68"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">Parallel STL Usage Instructions</p></li><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;text-align: left;">Macros</p></li></ul></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">An additional set of library classes and functions (referred to throughout this document as <b>Extension API</b>):</p><ul id="l69"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">Parallel Algorithms</p></li><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;text-align: left;">Iterators</p></li><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;text-align: left;">Function Object Classes</p></li><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;text-align: left;">Range-Based API</p></li></ul></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Tested Standard C++ APIs</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Random Number Generator</p><p style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark41">&zwnj;</a>oneDPL Library Usage<a name="bookmark131">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Install the </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html" class="s16" target="_blank">® </a>oneAPI Base Toolkit <span style=" color: #000;">to use oneDPL.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To use Parallel STL or the Extension API, include the corresponding header files in your source code. All oneDPL header files are in the <span class="s18">oneapi/dpl </span>directory. Use <span class="s18">#include &lt;oneapi/dpl/...&gt; </span>to include them. oneDPL uses the namespace <span class="s18">oneapi::dpl </span>for the most of its classes and functions.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">To use tested C++ standard APIs, you need to include the corresponding C++ standard header files and use the <span class="s18">std </span>namespace.</p><p style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark42">&zwnj;</a>oneDPL Code Samples<a name="bookmark132">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/Libraries/oneDPL" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneDPL sample code is available from the oneAPI GitHub repository </a><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/Libraries/oneDPL" class="a" target="_blank">https://github.com/oneapi-src/oneAPI- </a>samples/tree/master/Libraries/oneDPL<span style=" color: #000;">. Each sample includes a readme with build instructions.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark43">&zwnj;</a>Intel® oneAPI Math Kernel Library (oneMKL)<a name="bookmark133">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The Intel<span class="s12">® </span>oneAPI Math Kernel Library (oneMKL) is a computing math library of highly optimized and extensively parallelized routines for applications that require maximum performance. oneMKL contains the high-performance optimizations from the full Intel<span class="s12">® </span>Math Kernel Library for CPU architectures (with C/Fortran programming language interfaces) and adds to them a set of SYCL* interfaces for achieving performance on various CPU architectures and Intel Graphics Technology for certain key functionalities. oneMKL provides BLAS and LAPACK linear algebra routines, fast Fourier transforms, vectorized math functions, random number generation functions, and other functionality.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/onemkl-developer-reference-c/top/openmp-offload/openmp-offload-for-onemkl.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">You can use OpenMP* offload to run standard oneMKL computations on Intel GPUs. Refer to </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/onemkl-developer-reference-c/top/openmp-offload/openmp-offload-for-onemkl.html" class="a" target="_blank">OpenMP* offload </a>for C interfaces <a href="https://www.intel.com/content/www/us/en/develop/documentation/onemkl-developer-reference-fortran/top/openmp-offload/openmp-offload-for-onemkl.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">and </a>OpenMP* offload for Fortran interfaces <span style=" color: #000;">for more information.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The new SYCL interfaces with optimizations for CPU and GPU architectures have been added for key functionality in the following major areas of computation:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">BLAS and LAPACK dense linear algebra routines</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Sparse BLAS sparse linear algebra routines</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Random number generators (RNG)</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Vector Mathematics (VM) routines for optimized mathematical operations on vectors</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Fast Fourier Transforms (FFTs)</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For the complete list of features, documentation, code samples, and downloads, visit the official Intel oneAPI Math Kernel Library </a>website<a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">. If you plan to use oneMKL as part of the </a>oneAPI Base Toolkit<a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/commercial-base.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">, consider that </a>priority support <a href="https://community.intel.com/t5/Intel-oneAPI-Math-Kernel-Library/bd-p/oneapi-math-kernel-library" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">is available as a paid option. For Intel community-support, visit the </a>oneMKL forum<a href="https://github.com/uxlfoundation/oneMath" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">. For the open-source oneMath project, visit the </a>oneMath GitHub* page<span style=" color: #000;">.</span></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The table below describes the difference in these sites:</p><p class="s13" style="padding-top: 8pt;padding-left: 261pt;text-indent: -248pt;text-align: left;">oneAPI Specification for oneMath           <span style=" color: #000;">Defines the SYCL interfaces for performance math library functions. The oneMath specification can evolve faster and more frequently than implementations of the specification.</span></p><p class="s13" style="padding-top: 8pt;padding-left: 12pt;text-indent: 0pt;line-height: 11pt;text-align: left;">oneAPI Math Library (oneMath)            <span style=" color: #000;">An open source implementation of the specification.</span></p><p style="padding-left: 261pt;text-indent: 0pt;text-align: left;">The project goal is to demonstrate how the SYCL interfaces documented in the oneMath specification can be implemented for any math library and work for any target hardware. While the implementation provided here may not yet be the full implementation of the specification, the goal is to build it out over time. We encourage the community to contribute to this project and help to extend support to multiple hardware targets and other math libraries.</p><p style="padding-top: 8pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/tools/oneapi/components/onemkl.html" class="a" target="_blank">Intel(R) oneAPI Math Kernel Library (oneMKL) </a><a href="https://www.intel.com/content/www/us/en/develop/tools/oneapi/components/onemkl.html" target="_blank">Product</a></p><p style="padding-top: 8pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">The Intel product has SYCL interfaces that are very similar to the oneMath specification as well as similar functionality with C and Fortran interfaces, and is provided as part of Intel<span class="s12">® </span>oneAPI Base Toolkit. It is highly optimized for Intel CPU and Intel GPU hardware and is used for the Intel backends of the oneMath open-source project.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark44">&zwnj;</a>oneMKL Usage<a name="bookmark134">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">When using the SYCL* interfaces, there are a few changes to consider:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">oneMKL has a dependency on the Intel<span class="s12">® </span>oneAPI DPC++/C++ Compiler and Intel oneAPI DPC++ Library. Applications must be built with the Intel oneAPI DPC++/C++ Compiler, the SYCL headers made available, and the application linked with oneMKL using the DPC++ linker.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">SYCL interfaces in oneMKL use device-accessible Unified Shared Memory (USM) pointers for input data (vectors, matrices, etc.).</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Many SYCL interfaces in oneMKL also support the use of <span class="s18">sycl::buffer </span>objects in place of the device- accessible USM pointers for input data.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">SYCL interfaces in oneMKL are overloaded based on the floating point types. For example, there are several general matrix multiply APIs, accepting single precision real arguments (float), double precision real arguments (double), half precision real arguments (half), and complex arguments of different precision using the standard library types <span class="s18">std::complex&lt;float&gt;</span>, <span class="s18">std::complex&lt;double&gt;</span>.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 11pt;text-align: left;">A two-level namespace structure for oneMKL is added for SYCL interfaces:</p></li></ul><p class="s25" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">oneMKL Two-Level Namespaces</p><table style="border-collapse:collapse;margin-left:5.69292pt" cellspacing="0"><tr style="height:20pt"><td style="width:185pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">Namespace</p></td><td style="width:314pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 72pt;text-indent: 0pt;text-align: left;">Description</p></td></tr><tr style="height:16pt"><td style="width:185pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">oneapi::mkl</p></td><td style="width:314pt;border-top-style:solid;border-top-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Contains common elements between various</p></td></tr><tr style="height:15pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 70pt;text-indent: 0pt;line-height: 10pt;text-align: left;">domains in oneMKL</p></td></tr><tr style="height:16pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">oneapi::mkl::blas</p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Contains dense vector-vector, matrix-vector, and</p></td></tr><tr style="height:15pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 70pt;text-indent: 0pt;line-height: 10pt;text-align: left;">matrix-matrix low level operations</p></td></tr><tr style="height:16pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">oneapi::mkl::lapack</p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Contains higher-level dense matrix operations like</p></td></tr><tr style="height:15pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 70pt;text-indent: 0pt;line-height: 10pt;text-align: left;">matrix factorizations and eigensolvers</p></td></tr><tr style="height:16pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">oneapi::mkl::rng</p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Contains random number generators for various</p></td></tr><tr style="height:15pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 70pt;text-indent: 0pt;line-height: 10pt;text-align: left;">probability density functions</p></td></tr><tr style="height:16pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">oneapi::mkl::stats</p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Contains basic statistical estimates for single and</p></td></tr><tr style="height:15pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 70pt;text-indent: 0pt;line-height: 10pt;text-align: left;">double precision multi-dimensional datasets</p></td></tr><tr style="height:21pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">oneapi::mkl::vm</p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;text-align: left;">Contains vector math routines</p></td></tr><tr style="height:20pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">oneapi::mkl::dft</p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;text-align: left;">Contains fast fourier transform operations</p></td></tr><tr style="height:16pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">oneapi::mkl::sparse</p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Contains sparse matrix operations like sparse</p></td></tr><tr style="height:11pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 70pt;text-indent: 0pt;line-height: 9pt;text-align: left;">matrix-vector multiplication and sparse triangular</p></td></tr><tr style="height:15pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:314pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 70pt;text-indent: 0pt;line-height: 11pt;text-align: left;">solver</p></td></tr></table><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark45">&zwnj;</a>oneMKL Code Sample<a name="bookmark135">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">To demonstrate a typical workflow for the oneMKL with SYCL* interfaces, the following example source code snippets perform a double precision matrix-matrix multiplication on a GPU device.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">The following code example requires additional code to compile and run, as indicated by the inline comments.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">// Standard SYCL header #include &lt;CL/sycl.hpp&gt;</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">// STL classes #include &lt;exception&gt; #include &lt;iostream&gt;</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">// Declarations for Intel oneAPI Math Kernel Library SYCL/DPC++ APIs #include &quot;oneapi/mkl.hpp&quot;</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">int main(int argc, char *argv[]) {</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">//</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">// User obtains data here for A, B, C matrices, along with setting m, n, k, ldA, ldB, ldC.</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">//</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">// For this example, A, B and C should be initially stored in a std::vector,</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">// or a similar container having data() and size() member functions.</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">//</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">// Create GPU device sycl::device my_device; try {</p><p class="s18" style="padding-left: 51pt;text-indent: 0pt;text-align: left;">my_device = sycl::device(sycl::gpu_selector());</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">}</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">catch (...) {</p><p class="s18" style="padding-left: 51pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Warning: GPU device not found! Using default device instead.&quot; &lt;&lt; std::endl;</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">}</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">// Create asynchronous exceptions handler to be attached to queue.</p><p class="s18" style="padding-left: 11pt;text-indent: 19pt;text-align: left;">// Not required; can provide helpful information in case the system isn’t correctly configured.</p><p class="s18" style="padding-left: 51pt;text-indent: -19pt;text-align: left;">auto my_exception_handler = [](sycl::exception_list exceptions) { for (std::exception_ptr const&amp; e : exceptions) {</p><p class="s18" style="padding-left: 71pt;text-indent: 0pt;text-align: left;">try {</p><p class="s18" style="padding-left: 91pt;text-indent: 0pt;text-align: left;">std::rethrow_exception(e);</p><p class="s18" style="padding-left: 71pt;text-indent: 0pt;text-align: left;">}</p><p class="s18" style="padding-left: 71pt;text-indent: 0pt;text-align: left;">catch (sycl::exception const&amp; e) {</p><p class="s18" style="padding-left: 91pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Caught asynchronous SYCL exception:\n&quot;</p><p class="s18" style="padding-left: 111pt;text-indent: 0pt;text-align: left;">&lt;&lt; e.what() &lt;&lt; std::endl;</p><p class="s18" style="padding-left: 71pt;text-indent: 0pt;text-align: left;">}</p><p class="s18" style="padding-left: 71pt;text-indent: 0pt;text-align: left;">catch (std::exception const&amp; e) {</p><p class="s18" style="padding-left: 91pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Caught asynchronous STL exception:\n&quot;</p><p class="s18" style="padding-left: 111pt;text-indent: 0pt;text-align: left;">&lt;&lt; e.what() &lt;&lt; std::endl;</p><p class="s18" style="padding-left: 71pt;text-indent: 0pt;text-align: left;">}</p><p class="s18" style="padding-left: 51pt;text-indent: 0pt;text-align: left;">}</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">};</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">// create execution queue on my gpu device with exception handler attached sycl::queue my_queue(my_device, my_exception_handler);</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">// create sycl buffers of matrix data for offloading between device and host sycl::buffer&lt;double, 1&gt; A_buffer(A.data(), A.size());</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">sycl::buffer&lt;double, 1&gt; B_buffer(B.data(), B.size()); sycl::buffer&lt;double, 1&gt; C_buffer(C.data(), C.size());</p><p class="s18" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">// add oneapi::mkl::blas::gemm to execution queue and catch any synchronous exceptions try {</p><p class="s18" style="padding-left: 51pt;text-indent: 0pt;text-align: left;">using oneapi::mkl::blas::gemm;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:336.3pt;width:486.6pt;"><p class="s19" style="padding-left: 39pt;text-indent: 0pt;line-height: 10pt;text-align: left;">using oneapi::mkl::transpose;</p><p class="s19" style="text-indent: 39pt;text-align: left;">gemm(my_queue, transpose::nontrans, transpose::nontrans, m, n, k, alpha, A_buffer, ldA, B_buffer,</p><p class="s19" style="padding-left: 54pt;text-indent: 0pt;text-align: left;">ldB, beta, C_buffer, ldC);</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">catch (sycl::exception const&amp; e) {</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;\t\tCaught synchronous SYCL exception during GEMM:\n&quot;</p><p class="s19" style="padding-left: 59pt;text-indent: 0pt;text-align: left;">&lt;&lt; e.what() &lt;&lt; std::endl;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">catch (std::exception const&amp; e) {</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;\t\tCaught synchronous STL exception during GEMM:\n&quot;</p><p class="s19" style="padding-left: 59pt;text-indent: 0pt;text-align: left;">&lt;&lt; e.what() &lt;&lt; std::endl;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">// ensure any asynchronous exceptions caught are handled before proceeding my_queue.wait_and_throw();</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">//</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">// post process results</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">//</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">// Access data from C buffer and print out part of C matrix</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">auto C_accessor = C_buffer.template get_access&lt;sycl::access::mode::read&gt;(); std::cout &lt;&lt; &quot;\t&quot; &lt;&lt; C &lt;&lt; &quot; = [ &quot; &lt;&lt; C_accessor[0] &lt;&lt; &quot;, &quot;</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">&lt;&lt; C_accessor[1] &lt;&lt; &quot;, ... ]\n&quot;;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;\t  [ &quot; &lt;&lt; C_accessor[1 * ldC + 0] &lt;&lt; &quot;, &quot;</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">&lt;&lt; C_accessor[1 * ldC + 1] &lt;&lt; &quot;, ... ]\n&quot;;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;\t [ &quot; &lt;&lt; &quot;... ]\n&quot;; std::cout &lt;&lt; std::endl;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">return 0;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Consider that (double precision valued) matrices A(of size m-by-k), B( of size k-by-n) and C(of size m-by-n) are stored in some arrays on the host machine with leading dimensions ldA, ldB, and ldC, respectively. Given scalars (double precision) alpha and beta, compute the matrix-matrix multiplication (<span class="s18">mkl::blas::gemm</span>):</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">C = alpha * A * B + beta * C</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Include the standard SYCL headers and the oneMKL SYCL/DPC++ specific header that declares the desired</p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">mkl::blas::gemm <span class="p">API:</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:78.5pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">// Standard SYCL header #include &lt;CL/sycl.hpp&gt;</p><p class="s19" style="text-indent: 0pt;text-align: left;">// STL classes #include &lt;exception&gt; #include &lt;iostream&gt;</p><p class="s19" style="text-indent: 0pt;text-align: left;">// Declarations for Intel oneAPI Math Kernel Library SYCL/DPC++ APIs #include &quot;oneapi/mkl.hpp&quot;</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Next, load or instantiate the matrix data on the host machine as usual and then create the GPU device, create an asynchronous exception handler, and finally create the queue on the device with that exception handler. Exceptions that occur on the host can be caught using standard C++ exception handling mechanisms; however, exceptions that occur on a device are considered asynchronous errors and stored in an exception list to be processed later by this user-provided exception handler.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:78.5pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">// Create GPU device sycl::device my_device; try {</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">my_device = sycl::device(sycl::gpu_selector());</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p><p class="s19" style="text-indent: 0pt;text-align: left;">catch (...) {</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Warning: GPU device not found! Using default device instead.&quot; &lt;&lt; std::endl;</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:201.8pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">}</p><p class="s19" style="text-indent: 0pt;text-align: left;">// Create asynchronous exceptions handler to be attached to queue.</p><p class="s19" style="text-indent: 0pt;text-align: left;">// Not required; can provide helpful information in case the system isn’t correctly configured. auto my_exception_handler = [](sycl::exception_list exceptions) {</p><p class="s19" style="padding-left: 39pt;text-indent: -19pt;text-align: left;">for (std::exception_ptr const&amp; e : exceptions) { try {</p><p class="s19" style="padding-left: 59pt;text-indent: 0pt;text-align: left;">std::rethrow_exception(e);</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">catch (sycl::exception const&amp; e) {</p><p class="s19" style="padding-left: 59pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Caught asynchronous SYCL exception:\n&quot;</p><p class="s19" style="padding-left: 79pt;text-indent: 0pt;text-align: left;">&lt;&lt; e.what() &lt;&lt; std::endl;</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">catch (std::exception const&amp; e) {</p><p class="s19" style="padding-left: 59pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Caught asynchronous STL exception:\n&quot;</p><p class="s19" style="padding-left: 79pt;text-indent: 0pt;text-align: left;">&lt;&lt; e.what() &lt;&lt; std::endl;</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="text-indent: 0pt;text-align: left;">};</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The matrix data is now loaded into the SYCL buffers, which enables offloading to desired devices and then back to host when complete. Finally, the <span class="s18">mkl::blas::gemm </span>API is called with all the buffers, sizes, and transpose operations, which will enqueue the matrix multiply kernel and data onto the desired queue.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:246.7pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">// create execution queue on my gpu device with exception handler attached sycl::queue my_queue(my_device, my_exception_handler);</p><p class="s19" style="text-indent: 0pt;text-align: left;">// create sycl buffers of matrix data for offloading between device and host sycl::buffer&lt;double, 1&gt; A_buffer(A.data(), A.size());</p><p class="s19" style="text-indent: 0pt;text-align: left;">sycl::buffer&lt;double, 1&gt; B_buffer(B.data(), B.size()); sycl::buffer&lt;double, 1&gt; C_buffer(C.data(), C.size());</p><p class="s19" style="text-indent: 0pt;text-align: left;">// add oneapi::mkl::blas::gemm to execution queue and catch any synchronous exceptions try {</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">using oneapi::mkl::blas::gemm; using oneapi::mkl::transpose;</p><p class="s19" style="text-indent: 19pt;text-align: left;">gemm(my_queue, transpose::nontrans, transpose::nontrans, m, n, k, alpha, A_buffer, ldA, B_buffer,</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">ldB, beta, C_buffer, ldC);</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p><p class="s19" style="text-indent: 0pt;text-align: left;">catch (sycl::exception const&amp; e) {</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;\t\tCaught synchronous SYCL exception during GEMM:\n&quot;</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">&lt;&lt; e.what() &lt;&lt; std::endl;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p><p class="s19" style="text-indent: 0pt;text-align: left;">catch (std::exception const&amp; e) {</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;\t\tCaught synchronous STL exception during GEMM:\n&quot;</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">&lt;&lt; e.what() &lt;&lt; std::endl;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">At some time after the <span class="s18">gemm </span>kernel has been enqueued, it will be executed. The queue is asked to wait for all kernels to execute and then pass any caught asynchronous exceptions to the exception handler to be thrown. The runtime will handle transfer of the buffer’s data between host and GPU device and back. By the time an accessor is created for the <span class="s18">C_buffer</span>, the buffer data will have been silently transferred back to the host machine if necessary. In this case, the accessor is used to print out a 2x2 submatrix of <span class="s18">C_buffer</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:78.5pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">// Access data from C buffer and print out part of C matrix</p><p class="s19" style="text-indent: 0pt;text-align: left;">auto C_accessor = C_buffer.template get_access&lt;sycl::access::mode::read&gt;(); std::cout &lt;&lt; &quot;\t&quot; &lt;&lt; C &lt;&lt; &quot; = [ &quot; &lt;&lt; C_accessor[0] &lt;&lt; &quot;, &quot;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">&lt;&lt; C_accessor[1] &lt;&lt; &quot;, ... ]\n&quot;;</p><p class="s19" style="text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;\t  [ &quot; &lt;&lt; C_accessor[1 * ldC + 0] &lt;&lt; &quot;, &quot;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">&lt;&lt; C_accessor[1 * ldC + 1] &lt;&lt; &quot;, ... ]\n&quot;;</p><p class="s19" style="text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;\t  [ &quot; &lt;&lt; &quot;... ]\n&quot;;</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">std::cout &lt;&lt; std::endl;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">return 0;</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Note that the resulting data is still in the <span class="s18">C_buffer </span>object and, unless it is explicitly copied elsewhere (like back to the original C container), it will only remain available through accessors until the <span class="s18">C_buffer </span>is out of scope.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark46">&zwnj;</a>Intel® oneAPI Threading Building Blocks (oneTBB)<a name="bookmark136">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Intel<span class="s12">® </span>oneAPI Threading Building Blocks (oneTBB) is a widely used C++ library for task-based, shared memory parallel programming on the host. The library provides features for parallel programming on CPUs beyond those currently available in SYCL* and ISO C++, including:</p><ul id="l70"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Generic parallel algorithms</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Concurrent containers</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">A scalable memory allocator</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Work-stealing task scheduler</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Low-level synchronization primitives</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">oneTBB is compiler-independent and is available on a variety of processors and operating systems. It is used by other oneAPI libraries (Intel oneAPI Math Kernel Library, Intel<span class="s12">® </span>oneAPI Deep Neural Network Library, etc.) to express multithreading parallelism for CPUs.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/onetbb.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For the complete list of features, documentation, code samples, and downloads, visit the official Intel oneAPI Threading Building Blocks Library </a>website<a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">. If you plan to use oneTBB as part of the </a>oneAPI Base Toolkit<a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/commercial-base.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">, consider that </a>priority support <a href="https://community.intel.com/t5/Intel-oneAPI-Threading-Building/bd-p/oneapi-threading-building-blocks" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">is available as a paid option. For Intel community-support, visit the </a><a href="https://community.intel.com/t5/Intel-oneAPI-Threading-Building/bd-p/oneapi-threading-building-blocks" class="a" target="_blank">oneTBB </a>forum<a href="https://github.com/oneapi-src/oneTBB" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">. For the community-supported open-source version, visit the </a>oneTBB GitHub* page<span style=" color: #000;">.</span></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark47">&zwnj;</a>oneTBB Usage<a name="bookmark137">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">oneTBB can be used with the Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/onetbb-documentation/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI DPC++/C++ Compiler in the same way as with any other C++ compiler. For more details, see the </a><span style=" color: #075FA7;">oneTBB documentation</span>.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Currently, oneTBB does not directly use any accelerators. However, it can be combined with SYCL*, OpenMP* offload, and other oneAPI libraries to build a program that efficiently uses all available hardware resources.</p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark48">&zwnj;</a>oneTBB Code Sample<a name="bookmark138">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/Libraries/oneTBB" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Two basic oneTBB code samples are available within the oneAPI GitHub repository </a><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/Libraries/oneTBB" class="a" target="_blank">https://github.com/ </a>oneapi-src/oneAPI-samples/tree/master/Libraries/oneTBB<span style=" color: #000;">. Both samples are prepared for CPU and GPU.</span></p></li><li data-list-text="•"><p class="s18" style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">tbb-async-sycl<span class="p">: illustrates how computational kernel can be split for execution between CPU and GPU using oneTBB Flow Graph asynchronous node and functional node. The Flow Graph asynchronous node uses SYCL* to implement calculations on GPU while the functional node does CPU part of calculations.</span></p></li><li data-list-text="•"><p class="s18" style="padding-left: 19pt;text-indent: -14pt;text-align: left;">tbb-task-sycl<span class="p">: illustrates how two oneTBB tasks can execute similar computational kernels with one task executing SYCL code and another one the oneTBB code.</span></p></li><li data-list-text="•"><p class="s18" style="padding-left: 19pt;text-indent: -14pt;text-align: left;">tbb-resumable-tasks-sycl<span class="p">: illustrates how a computational kernel can be split for execution between a CPU and GPU using oneTBB resumable task and parallel_for. The resumable task uses SYCL to implement calculations on GPU while parallel_for does the CPU portion of calculations.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark49">&zwnj;</a>Intel® oneAPI Data Analytics Library (oneDAL)<a name="bookmark139">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Intel<span class="s12">® </span>oneAPI Data Analytics Library (oneDAL) is a library that helps speed up big data analysis by providing highly optimized algorithmic building blocks for all stages of data analytics (preprocessing, transformation, analysis, modeling, validation, and decision making) in batch, online, and distributed processing modes of computation.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/distribution-for-python.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The library optimizes data ingestion along with algorithmic computation to increase throughput and scalability. It includes C++ and Java* APIs and connectors to popular data sources such as Spark* and Hadoop*. Python* wrappers for oneDAL are part of </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/distribution-for-python.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/distribution-for-python.html" class="s16" target="_blank">® </a>Distribution for Python* Programming Language<span style=" color: #000;">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">In addition to classic features, oneDAL provides DPC++ SYCL API extensions to the traditional C++ interface and enables GPU usage for some algorithms.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The library is particularly useful for distributed computation. It provides a full set of building blocks for distributed algorithms that are independent from any communication layer. This allows users to construct fast and scalable distributed applications using user-preferable communication means.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/onedal.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For the complete list of features, documentation, code samples, and downloads, visit the official Intel oneAPI Data Analytics Library </a>website<a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">. If you plan to use oneDAL as part of the </a>oneAPI Base Toolkit<a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/commercial-base.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">, consider that </a>priority support <a href="https://community.intel.com/t5/Intel-oneAPI-Data-Analytics/bd-p/oneapi-data-analytics-library" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">is available as a paid option. For Intel community-support, visit the </a>oneDAL forum<a href="https://github.com/oneapi-src/oneDAL" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">. For the community-supported open-source version, visit the </a>oneDAL GitHub* page<span style=" color: #000;">.</span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark50">&zwnj;</a>oneDAL Usage<a name="bookmark140">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/articles/system-requirements/system-requirements-for-oneapi-data-analytics-library.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Information about dependencies needed to build and link your application with oneDAL are available from the </a>oneDAL System Requirements<span style=" color: #000;">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">A oneDAL-based application can seamlessly execute algorithms on CPU or GPU by picking the proper device selector. New capabilities also allow:</p><p style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">extracting SYCL* buffers from numeric tables and pass them to a custom kernel</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">creating numeric tables from SYCL buffers</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Algorithms are optimized to reuse SYCL buffers to keep GPU data and remove overload from repeatedly copying data between GPU and CPU.</p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark51">&zwnj;</a>oneDAL Code Sample<a name="bookmark141">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://github.com/oneapi-src/oneDAL/tree/master/examples/oneapi/dpc/source/svm" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneDAL code samples are available from the oneDAL GitHub. The following code sample is a recommended starting point: </a><a href="https://github.com/oneapi-src/oneDAL/tree/master/examples/oneapi/dpc/source/svm" target="_blank">https://github.com/oneapi-src/oneDAL/tree/master/examples/oneapi/dpc/source/svm</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark52">&zwnj;</a>Intel® oneAPI Collective Communications Library (oneCCL)<a name="bookmark142">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark143">&zwnj;</a>Intel<span class="s12">® </span>oneAPI Collective Communications Library (oneCCL) is a scalable and high-performance communication library for Deep Learning (DL) and Machine Learning (ML) workloads. It develops the ideas that originated in Intel<span class="s12">® </span>Machine Learning Scaling Library and expands the design and API to encompass new features and use cases.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">oneCCL features include:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Built on top of lower-level communication middleware – MPI and libfabrics</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Optimized to drive scalability of communication patterns by enabling the productive trade-off of compute for communication performance</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Enables a set of DL-specific optimizations, such as prioritization, persistent operations, out of order execution, etc.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">DPC++-aware API to run across various hardware targets, such as CPUs and GPUs</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Works across various interconnects: Intel<span class="s12">® </span>Omni-Path Architecture (Intel<span class="s12">® </span>OPA), InfiniBand*, and Ethernet</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span style=" color: #000;">For the complete list of features, documentation, code samples, and downloads, visit the official Intel</span><span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/oneccl.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI Collective Communications Library </a>website<a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">. If you plan to use oneCCL as part of the </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html" class="a" target="_blank">oneAPI Base </a>Toolkit<a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/commercial-base.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">, consider that </a>premium support <a href="https://github.com/oneapi-src/oneCCL" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">is available as a paid option. For the community-supported open- source version, visit the </a>oneCCL GitHub* page<span style=" color: #000;">.</span></p><p style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark53">&zwnj;</a>oneCCL Usage<a name="bookmark144">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/articles/system-requirements/oneapi-collective-communication-library-system-requirements.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Refer to the </a><a href="https://www.intel.com/content/www/us/en/developer/articles/system-requirements/oneapi-collective-communication-library-system-requirements.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/developer/articles/system-requirements/oneapi-collective-communication-library-system-requirements.html" class="s16" target="_blank">® </a><span style=" color: #075FA7;">oneAPI Collective Communications Library System Requirements </span>for a full list of hardware and software dependencies, such as MPI and Intel<span class="s12">® </span>oneAPI DPC++/C++ Compiler.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL*-aware API is an optional feature of oneCCL. There is a choice between CPU and SYCL back ends when creating the oneCCL stream object.</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;line-height: 12pt;text-align: left;">For CPU backend: Specify <span class="s18">ccl_stream_host </span>as the first argument.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 12pt;text-align: left;">For SYCL backend: Specify <span class="s18">ccl_stream_cpu </span>or <span class="s18">ccl_stream_gpu </span>depending on the device type.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 11pt;text-align: left;">For collective operations that operate on the SYCL stream:</p><ul id="l71"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 34pt;text-indent: -14pt;line-height: 12pt;text-align: left;">For C API, oneCCL expects communication buffers to be <span class="s18">sycl::buffer </span>objects casted to <span class="s18">void*</span>.</p></li><li data-list-text="•"><p class="s13" style="padding-left: 5pt;text-indent: 14pt;line-height: 148%;text-align: left;"><a href="https://oneapi-src.github.io/oneCCL/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For C++ API, oneCCL expects communication buffers to be passed by reference. Additional usage details are available from </a>https://oneapi-src.github.io/oneCCL/<span style=" color: #000;">.</span></p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark54">&zwnj;</a>oneCCL Code Sample<a name="bookmark145">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/Libraries/oneCCL" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneCCL code samples are available from the oneAPI GitHub repository </a><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/Libraries/oneCCL" class="a" target="_blank">https://github.com/oneapi-src/ </a>oneAPI-samples/tree/master/Libraries/oneCCL<span style=" color: #000;">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">A Getting Started sample with instructions to build and run the code is available from within the same GitHub repository.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark55">&zwnj;</a>Intel® oneAPI Deep Neural Network Library (oneDNN)<a name="bookmark146">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Intel<span class="s12">® </span>oneAPI Deep Neural Network Library (oneDNN) is an open-source performance library for deep learning applications. The library includes basic building blocks for neural networks optimized for Intel Architecture Processors and Intel Processor Graphics. oneDNN is intended for deep learning applications and framework developers interested in improving application performance on Intel Architecture Processors and Intel Processor Graphics. Deep learning practitioners should use one of the applications enabled with oneDNN.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">oneDNN is distributed as part of Intel<span class="s12">® </span>oneAPI DL Framework Developer Toolkit, the Intel<span class="s12">® </span>oneAPI Base Toolkit, and is available via apt and yum channels.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">oneDNN continues to support features currently available with Intel<span class="s12">® </span>Deep Neural Network Library (Intel<span class="s12">® </span>DNNL), including C and C++ interfaces, OpenMP*, Intel<span class="s12">® </span>oneAPI Threading Building Blocks, and OpenCL<span class="s12">™ </span>runtimes. oneDNN introduces SYCL*/DPC++ API and runtime support for the oneAPI programming model.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/onednn.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For the complete list of features, documentation, code samples, and downloads, visit the official Intel oneAPI Deep Neural Network Library </a>website<a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">. If you plan to use oneDNN as part of the </a>oneAPI Base Toolkit<a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/commercial-base.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">, consider that </a>premium support <a href="https://github.com/oneapi-src/oneDNN" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">is available as a paid option. For the community-supported open-source version, visit the </a>oneDNN GitHub* page<span style=" color: #000;">.</span></p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark56">&zwnj;</a>Intel® oneAPI Deep Neural Network Library (oneDNN) Usage<a name="bookmark147">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">oneDNN supports systems based on Intel<span class="s12">® </span>64 architecture or compatible processors. A full list of supported CPU and graphics hardware is available from the Intel<span class="s12">® </span>oneAPI Deep Neural Network Library System Requirements.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">oneDNN detects the instruction set architecture (ISA) in the runtime and uses online generation to deploy the code optimized for the latest supported ISA.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Several packages are available for each operating system to ensure interoperability with CPU or GPU runtime libraries used by the application.</p><p class="s25" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Package Availability by Operating System</p><table style="border-collapse:collapse;margin-left:5.69292pt" cellspacing="0"><tr style="height:20pt"><td style="width:185pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">Configuration</p></td><td style="width:314pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 72pt;text-indent: 0pt;text-align: left;">Dependency</p></td></tr><tr style="height:21pt"><td style="width:185pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">cpu_dpcpp_gpu_dpcpp</p></td><td style="width:314pt;border-top-style:solid;border-top-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;text-align: left;">DPC++ runtime</p></td></tr><tr style="height:20pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">cpu_iomp</p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;text-align: left;">Intel OpenMP* runtime</p></td></tr><tr style="height:20pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">cpu_gomp</p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;text-align: left;">GNU* OpenMP runtime</p></td></tr><tr style="height:20pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">cpu_vcomp</p></td><td style="width:314pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;text-align: left;">Microsoft* Visual C++ OpenMP runtime</p></td></tr><tr style="height:20pt"><td style="width:185pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">cpu_tbb</p></td><td style="width:314pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 70pt;text-indent: 0pt;text-align: left;">Intel oneAPI Threading Building Blocks</p></td></tr></table><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The packages do not include library dependencies and these need to be resolved in the application at build time with Intel<span class="s12">® </span>oneAPI toolkits or third-party tools.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">When used in the SYCL* environment, oneDNN relies on the DPC++ SYCL runtime to interact with CPU or GPU hardware. oneDNN may be used with other code that uses SYCL. To do this, oneDNN provides API extensions to interoperate with underlying SYCL objects.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">One of the possible scenarios is executing a SYCL kernel for a custom operation not provided by oneDNN. In this case, oneDNN provides all necessary APIs to seamlessly submit a kernel, sharing the execution context with oneDNN: using the same device and queue.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The interoperability API is provided for two scenarios:</p></li></ul></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Construction of oneDNN objects based on existing SYCL objects</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Accessing SYCL objects for existing oneDNN objects</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The mapping between oneDNN and SYCL objects is summarized in the tables below.</p><p class="s25" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">oneDNN and SYCL Object Mapping 1</p><table style="border-collapse:collapse;margin-left:5.69292pt" cellspacing="0"><tr style="height:20pt"><td style="width:173pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">oneDNN Objects</p></td><td style="width:326pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 84pt;text-indent: 0pt;text-align: left;">SYCL Objects</p></td></tr><tr style="height:20pt"><td style="width:173pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Engine</p></td><td style="width:326pt;border-top-style:solid;border-top-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 82pt;text-indent: 0pt;text-align: left;">cl::sycl::device and cl::sycl::context</p></td></tr><tr style="height:20pt"><td style="width:173pt;border-left-style:solid;border-left-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Stream</p></td><td style="width:326pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 82pt;text-indent: 0pt;text-align: left;">cl::sycl::queue</p></td></tr><tr style="height:15pt"><td style="width:173pt;border-left-style:solid;border-left-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Memory</p></td><td style="width:326pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 82pt;text-indent: 0pt;line-height: 10pt;text-align: left;">cl::sycl::buffer&lt;uint8_t, 1&gt; or Unified Shared</p></td></tr><tr style="height:15pt"><td style="width:173pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:326pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-left: 82pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Memory (USM) pointer</p></td></tr></table><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;"><b>NOTE </b>Internally, library memory objects use 1D uint8_t SYCL buffers, however SYCL buffers of a different type can be used to initialize and access memory. In this case, buffers will be reinterpreted to the underlying type <span class="s18">cl::sycl::buffer&lt;uint8_t, 1&gt;</span>.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s25" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">oneDNN and SYCL Object Mapping 2</p><table style="border-collapse:collapse;margin-left:5.69292pt" cellspacing="0"><tr style="height:20pt"><td style="width:171pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">oneDNN Object</p></td><td style="width:328pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s26" style="padding-top: 4pt;padding-left: 87pt;text-indent: 0pt;text-align: left;">Constructing from SYCL Object</p></td></tr><tr style="height:17pt"><td style="width:171pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Engine</p></td><td style="width:328pt;border-top-style:solid;border-top-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 85pt;text-indent: 0pt;line-height: 10pt;text-align: left;">dnnl::sycl_interop::make_engine(sycl_dev,</p></td></tr><tr style="height:16pt"><td style="width:171pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:328pt;border-right-style:solid;border-right-width:1pt"><p class="s19" style="padding-left: 85pt;text-indent: 0pt;text-align: left;">sycl_ctx)</p></td></tr><tr style="height:17pt"><td style="width:171pt;border-left-style:solid;border-left-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Stream</p></td><td style="width:328pt;border-right-style:solid;border-right-width:1pt"><p class="s19" style="padding-top: 5pt;padding-left: 85pt;text-indent: 0pt;line-height: 10pt;text-align: left;">dnnl::sycl_interop::make_stream(engine,</p></td></tr><tr style="height:16pt"><td style="width:171pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:328pt;border-right-style:solid;border-right-width:1pt"><p class="s19" style="padding-left: 85pt;text-indent: 0pt;text-align: left;">sycl_queue)</p></td></tr><tr style="height:17pt"><td style="width:171pt;border-left-style:solid;border-left-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Memory</p></td><td style="width:328pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 4pt;padding-left: 85pt;text-indent: 0pt;line-height: 11pt;text-align: left;">USM based: <span class="s19">dnnl::memory(memory_desc,</span></p></td></tr><tr style="height:14pt"><td style="width:171pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:328pt;border-right-style:solid;border-right-width:1pt"><p class="s19" style="padding-left: 85pt;text-indent: 0pt;text-align: left;">engine, usm_ptr)</p></td></tr><tr style="height:14pt"><td style="width:171pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:328pt;border-right-style:solid;border-right-width:1pt"><p class="s28" style="padding-top: 2pt;padding-left: 85pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Buffer based:</p></td></tr><tr style="height:12pt"><td style="width:171pt;border-left-style:solid;border-left-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:328pt;border-right-style:solid;border-right-width:1pt"><p class="s19" style="padding-left: 85pt;text-indent: 0pt;line-height: 10pt;text-align: left;">dnnl::sycl_interop::make_memory(memory_de</p></td></tr><tr style="height:15pt"><td style="width:171pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:328pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s19" style="padding-left: 85pt;text-indent: 0pt;text-align: left;">sc, engine, sycl_buf)</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s18" style="text-indent: 0pt;line-height: 158%;text-align: left;">dnnl::sycl_interop::get_device(engine) dnnl::sycl_interop::get_context(engine)</p><p class="s18" style="padding-top: 3pt;text-indent: 0pt;text-align: left;">dnnl::sycl_interop::get_queue(stream)</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;">USM pointer:</p><p class="s18" style="padding-top: 1pt;text-indent: 0pt;text-align: left;">dnnl::memory::get_data_handle()</p><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;">Buffer:</p><p class="s18" style="padding-top: 1pt;text-indent: 0pt;text-align: left;">dnnl::sycl_interop::get_buffer(memory)</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;">Engine</p><p style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 20pt;text-align: left;">Stream Memory</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Extracting SYCL Object</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">oneDNN Object</p><p style="text-indent: 0pt;text-align: left;"/><p class="s25" style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">oneDNN and SYCL Object Mapping 3</p><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE</p><ul id="l72"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">Building applications with oneDNN requires a compiler. The Intel<span class="s12">® </span>oneAPI DPC++/C++ Compiler is available as part of the Intel oneAPI Base Toolkit.</p></li><li data-list-text="•"><p style="padding-left: 49pt;text-indent: -14pt;line-height: 11pt;text-align: left;">You must include dnnl_sycl.hpp to enable the SYCL-interop API.</p></li><li data-list-text="•"><p style="padding-bottom: 2pt;padding-left: 49pt;text-indent: -14pt;text-align: left;">Because OpenMP does not rely on the passing of runtime objects, it does not require an interoperability API to work with oneDNN.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark57">&zwnj;</a>Intel® oneAPI Deep Neural Network Library (oneDNN) Code Sample<a name="bookmark148">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">oneDNN sample code is available from the Intel<span class="s12">® </span><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/Libraries/oneDNN" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI Base Toolkit GitHub repository </a><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/Libraries/oneDNN" class="a" target="_blank">https://github.com/ </a><span style=" color: #075FA7;">oneapi-src/oneAPI-samples/tree/master/Libraries/oneDNN</span>. The Getting Started sample is targeted to new users and includes a readme file with example build and run commands.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark58">&zwnj;</a>Other Libraries<a name="bookmark149">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Other libraries are included in various Intel<span class="s12">® </span>oneAPI toolkits. For more information about each of the libraries listed, consult the official documentation for that library.</p></li></ul></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>Integrated Performance Primitives (Intel<span class="s12">® </span>IPP)</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>MPI Library</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Intel<span class="s12">® </span>Open Volume Kernel Library</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark59">&zwnj;</a>Software &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Development &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Process &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a name="bookmark150">&zwnj;</a></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The software development process using the oneAPI programming model is based upon standard development processes. Since the programming model pertains to employing an accelerator to improve performance, this chapter details steps specific to that activity. These include:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">The performance tuning cycle</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Debugging of code</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Migrating code that targets other accelerators</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Composability of code</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark60">&zwnj;</a>Migrating Code to SYCL* and DPC++<a name="bookmark151">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Code written in other programming languages, such as C++ or OpenCL<span class="s12">™</span>, can be migrated to SYCL code for compilation with the Intel<span class="s12">® </span>oneAPI DPC++ compiler for use on multiple devices. The steps used to complete the migration vary based on the original language.</p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark61">&zwnj;</a>Migrating from C++ to SYCL*<a name="bookmark152">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL is a single-source style programming model based on C++. It builds on features of C++17 and C++20 to offer an open, multivendor, multiarchitecture solution for heterogeneous programming.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The Intel<span class="s12">® </span>oneAPI DPC++ Compiler project is bringing SYCL* to an LLVM C++ compiler, with high performance implementations for multiple vendors and architectures.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a href="#bookmark90" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">When accelerating an existing C++ application, SYCL provides seamless integration as most of the C++ code remains intact. Refer to sections within </a>oneAPI Programming Model <span style=" color: #000;">for SYCL constructs to enable device side compilation.</span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a name="bookmark62">&zwnj;</a>Migrating from CUDA* to SYCL* for the oneAPI DPC++ Compiler<a name="bookmark153">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The Intel<span class="s12">® </span>DPC++ Compatibility Tool is part of the Intel<span class="s12">® </span>oneAPI Base Toolkit. The goal of this tool is to assist in the migration of an existing program that is written in NVIDIA* CUDA* to a program written in SYCL* and compiled with the Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/intel-dpcpp-compatibility-tool-user-guide/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI DPC++ Compiler. This tool generates SYCL code as much as it can. However, it will not migrate all code and manual changes may be required. The tool provides help with IDE plugins, a </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/intel-dpcpp-compatibility-tool-user-guide/top.html" class="a" target="_blank">user </a><span style=" color: #075FA7;">guide</span>, and embedded comments in the code to complete the migration to be compiled with DPC++.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">After completing any manual changes, use a oneAPI DPC++ Compiler to create executables.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Migrating CUDA to SYCL Using the Intel<span class="s15">® </span>DPC++ Compatibility Tool</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span/></p></li><li data-list-text="•"><p class="s13" style="padding-top: 4pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compatibility-tool.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Additional details, including examples of migrated code and download instructions for the tool, are available from the </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compatibility-tool.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compatibility-tool.html" class="s16" target="_blank">® </a>DPC++ Compatibility Tool website<span style=" color: #000;">.</span></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/intel-dpcpp-compatibility-tool-user-guide/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Full usage information is available from the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/intel-dpcpp-compatibility-tool-user-guide/top.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/intel-dpcpp-compatibility-tool-user-guide/top.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/intel-dpcpp-compatibility-tool-user-guide/top.html" target="_blank">DPC++ Compatibility Tool User Guide</a></p></li></ul><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark63">&zwnj;</a>Migrating from OpenCL Code to SYCL*<a name="bookmark154">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The SYCL runtime for the DPC++ project uses OpenCL and other means to enact the parallelism. SYCL typically requires fewer lines of code to implement kernels and also fewer calls to essential API functions and methods. It enables creation of OpenCL programs by embedding the device source code in line with the host source code.</p><p style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">OpenCL application developers are keenly aware of the somewhat verbose setup code that goes with offloading kernels on devices. Using SYCL, it is possible to develop a clean, modern C++ based application without most of the setup associated with OpenCL C code. This reduces the learning effort and allows for focus on parallelization techniques.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">However, OpenCL application features can continue to be used via the SYCL API. The updated code can use as much or as little of the SYCL interface as desired.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark64">&zwnj;</a>Migrating Between CPU, GPU, and FPGA<a name="bookmark155">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Programming with SYCL* and using the Intel<span class="s12">® </span>oneAPI DPC++ Compiler, a platform consists of a host device connected to zero or more devices, such as CPU, GPU, FPGA, or other kinds of accelerators and processors.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">When a platform has multiple devices, design the application to offload some or most of the work to the devices. There are different ways to distribute work across devices in the oneAPI programming model:</p><ol id="l73"><li data-list-text="1."><p style="padding-top: 5pt;padding-left: 30pt;text-indent: -25pt;text-align: left;">Initialize device selector – SYCL provides a set of classes called selectors that allow manual selection of devices in the platform or let heuristics of the Intel<span class="s12">® </span>oneAPI Runtime Libraries choose a default device based on the compute power available on the devices.</p></li><li data-list-text="2."><p style="padding-left: 30pt;text-indent: -25pt;text-align: left;">Splitting datasets – With a highly parallel application with no data dependency, explicitly divide the datasets to employ different devices. The following code sample is an example of dispatching workloads across multiple devices. Use <span class="s18">icpx -fsycl snippet.cpp </span>to compile the code.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:347.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">int main() {</p><p class="s19" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">int data[1024];</p><p class="s19" style="padding-left: 34pt;text-indent: -19pt;text-align: left;">for (int i = 0; i &lt; 1024; i++) data[i] = i;</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">try {</p><p class="s19" style="padding-left: 54pt;text-indent: 0pt;text-align: left;">cpu_selector cpuSelector; queue cpuQueue(cpuSelector); gpu_selector gpuSelector; queue gpuQueue(gpuSelector);</p><p class="s19" style="padding-left: 54pt;text-indent: 0pt;text-align: left;">buffer&lt;int, 1&gt; buf(data, range&lt;1&gt;(1024)); cpuQueue.submit([&amp;](handler&amp; cgh) {</p><p class="s19" style="padding-left: 74pt;text-indent: 0pt;text-align: left;">auto ptr = buf.get_access&lt;access::mode::read_write&gt;(cgh); cgh.parallel_for&lt;class divide&gt;(range&lt;1&gt;(512),</p><p class="s19" style="padding-left: 94pt;text-indent: 0pt;text-align: left;">[=](id&lt;1&gt; index) { ptr[index] -= 1;</p><p class="s19" style="padding-left: 74pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="padding-left: 54pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="padding-left: 74pt;text-indent: -19pt;text-align: left;">gpuQueue.submit([&amp;](handler&amp; cgh1) { auto ptr =</p><p class="s19" style="padding-left: 74pt;text-indent: 0pt;text-align: left;">buf.get_access&lt;access::mode::read_write&gt;(cgh1); cgh1.parallel_for&lt;class offset1&gt;(range&lt;1&gt;(1024),</p><p class="s19" style="padding-left: 114pt;text-indent: -19pt;text-align: left;">id&lt;1&gt;(512), [=](id&lt;1&gt; index) { ptr[index] += 1;</p><p class="s19" style="padding-left: 74pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="padding-left: 54pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="padding-left: 54pt;text-indent: 0pt;text-align: left;">cpuQueue.wait(); gpuQueue.wait();</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 49pt;text-indent: -19pt;text-align: left;">catch (exception const&amp; e) { std::cout &lt;&lt;</p></div></li></ol><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 11pt;text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:56.0pt;width:486.6pt;"><p class="s19" style="padding-left: 49pt;text-indent: 0pt;text-align: left;">&quot;SYCL exception caught: &quot; &lt;&lt; e.what() &lt;&lt; &#39;\n&#39;; return 2;</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">return 0;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><ol id="l74"><li data-list-text="3."><p style="padding-left: 30pt;text-indent: -25pt;text-align: left;">Target multiple kernels across devices – If the application has scope for parallelization on multiple independent kernels, employ different queues to target devices. The list of SYCL supported platforms can be obtained with the list of devices for each platform by calling <span class="s18">get_platforms() </span>and <span class="s18">platform.get_devices() </span>respectively. Once all the devices are identified, construct a queue per device and dispatch different kernels to different queues. The following code sample represents dispatching a kernel on multiple SYCL devices.</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:526.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#include &lt;stdio.h&gt; #include &lt;vector&gt; #include &lt;CL/sycl.hpp&gt; using namespace cl::sycl; using namespace std;</p><p class="s19" style="text-indent: 0pt;text-align: left;">int main()</p><p class="s19" style="text-indent: 0pt;text-align: left;">{</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">size_t N = 1024; vector&lt;float&gt; a(N, 10.0);</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">vector&lt;float&gt; b(N, 10.0);</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">vector&lt;float&gt; c_add(N, 0.0);</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">vector&lt;float&gt; c_mul(N, 0.0);</p><p class="s19" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">{</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">buffer&lt;float, 1&gt; abuffer(a.data(), range&lt;1&gt;(N),</p><p class="s19" style="padding-left: 34pt;text-indent: 9pt;text-align: left;">{ property::buffer::use_host_ptr() }); buffer&lt;float, 1&gt; bbuffer(b.data(), range&lt;1&gt;(N),</p><p class="s19" style="padding-left: 44pt;text-indent: 0pt;text-align: left;">{ property::buffer::use_host_ptr() });</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">buffer&lt;float, 1&gt; c_addbuffer(c_add.data(), range&lt;1&gt;(N),</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">{ property::buffer::use_host_ptr() });</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">buffer&lt;float, 1&gt; c_mulbuffer(c_mul.data(), range&lt;1&gt;(N),</p><p class="s19" style="padding-left: 19pt;text-indent: 24pt;text-align: left;">{ property::buffer::use_host_ptr() }); try {</p><p class="s19" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">gpu_selector gpuSelector;</p><p class="s19" style="padding-left: 64pt;text-indent: 0pt;text-align: center;">auto queue = cl::sycl::queue(gpuSelector); queue.submit([&amp;](cl::sycl::handler&amp; cgh) { auto a_acc = abuffer.template</p><p class="s19" style="padding-left: 99pt;text-indent: 9pt;text-align: left;">get_access&lt;access::mode::read&gt;(cgh); auto b_acc = bbuffer.template</p><p class="s19" style="padding-left: 99pt;text-indent: 9pt;text-align: left;">get_access&lt;access::mode::read&gt;(cgh); auto c_acc_add = c_addbuffer.template</p><p class="s19" style="padding-left: 99pt;text-indent: 9pt;text-align: left;">get_access&lt;access::mode::write&gt;(cgh); cgh.parallel_for&lt;class VectorAdd&gt; (range&lt;1&gt;(N), [=](id&lt;1&gt; it) {</p><p class="s19" style="padding-left: 124pt;text-indent: 0pt;text-align: left;">//int i = it.get_global();</p><p class="s19" style="padding-left: 144pt;text-indent: 0pt;text-align: left;">c_acc_add[it] = a_acc[it] + b_acc[it];</p><p class="s19" style="padding-left: 169pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="padding-left: 134pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">cpu_selector cpuSelector;</p><p class="s19" style="padding-left: 64pt;text-indent: 0pt;text-align: center;">auto queue1 = cl::sycl::queue(cpuSelector); queue1.submit([&amp;](cl::sycl::handler&amp; cgh) { auto a_acc = abuffer.template</p><p class="s19" style="padding-left: 99pt;text-indent: 19pt;text-align: left;">get_access&lt;access::mode::read&gt;(cgh); auto b_acc = bbuffer.template</p><p class="s19" style="padding-left: 99pt;text-indent: 19pt;text-align: left;">get_access&lt;access::mode::read&gt;(cgh); auto c_acc_mul = c_mulbuffer.template</p><p class="s19" style="padding-left: 99pt;text-indent: 19pt;text-align: left;">get_access&lt;access::mode::write&gt;(cgh); cgh.parallel_for&lt;class VectorMul&gt;</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:213.0pt;width:486.6pt;"><p class="s19" style="padding-left: 129pt;text-indent: -24pt;text-align: left;">(range&lt;1&gt;(N), [=](id&lt;1&gt; it) { c_acc_mul[it] = a_acc[it] * b_acc[it];</p><p class="s19" style="padding-left: 169pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="padding-left: 134pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="padding-left: 69pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 69pt;text-indent: 0pt;text-align: left;">catch (cl::sycl::exception e) {</p><p class="s19" style="text-indent: 0pt;text-align: left;">/* In the case of an exception being throw, print the error message and</p><p class="s19" style="padding-left: 104pt;text-indent: 0pt;text-align: left;">* return 1. */ std::cout &lt;&lt; e.what(); return 1;</p><p class="s19" style="padding-left: 69pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">for (int i = 0; i &lt; 8; i++) {</p><p class="s19" style="padding-left: 69pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; c_add[i] &lt;&lt; std::endl; std::cout &lt;&lt; c_mul[i] &lt;&lt; std::endl;</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">return 0;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 11pt;text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark65">&zwnj;</a>Composability<a name="bookmark156">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The oneAPI programming model enables an ecosystem with support for the entire development toolchain. It includes compilers and libraries, debuggers, and analysis tools to support multiple accelerators like CPU, GPUs, FPGA, and more.</p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark66">&zwnj;</a>C/C++ OpenMP* and SYCL* Composability<a name="bookmark157">&zwnj;</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The oneAPI programming model provides a unified compiler based on LLVM/Clang with support for OpenMP* offload. This allows seamless integration that allows the use of OpenMP constructs to either parallelize host side applications or offload to a target device. The Intel<span class="s12">® </span>oneAPI DPC++/C++ Compiler, available with the Intel<span class="s12">® </span>oneAPI Base Toolkit, supports OpenMP and SYCL composability with a set of restrictions. A single application can offload execution to available devices using OpenMP target regions or SYCL constructs in different parts of the code, such as different functions or code segments.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">OpenMP and SYCL offloading constructs may be used in separate files, in the same file, or in the same function with some restrictions. OpenMP and SYCL offloading code can be bundled together in executable files, in static libraries, in dynamic libraries, or in various combinations.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">The SYCL runtime for DPC++ uses the TBB runtime when executing device code on the CPU; hence, using both OpenMP and SYCL a CPU can lead to oversubscribing of threads. Performance analysis of workloads executing on the system could help determine if this is occurring.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Restrictions</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">There are some restrictions to be considered when mixing OpenMP and SYCL constructs in the same application.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l75"><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">OpenMP directives cannot be used inside SYCL kernels that run in the device. Similarly, SYCL code cannot be used inside the OpenMP target regions. However, it is possible to use SYCL constructs within the OpenMP code that runs on the host CPU.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">OpenMP and SYCL device parts of the program cannot have cross dependencies. For example, a function defined in the SYCL part of the device code cannot be called from the OpenMP code that runs on the device and vice versa. OpenMP and SYCL device parts are linked independently and they form separate binaries that become a part of the resulting fat binary that is generated by the compiler.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">The direct interaction between OpenMP and SYCL runtime libraries are not supported at this time. For example, a device memory object created by OpenMP API is not accessible by SYCL code. That is, using the device memory object created by OpenMP in SYCL code results unspecified execution behavior.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Example</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following code snippet uses SYCL and OpenMP offloading constructs in the same application.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:403.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#include &lt;CL/sycl.hpp&gt; #include &lt;array&gt; #include &lt;iostream&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 9pt;text-indent: -10pt;text-align: left;">float computePi(unsigned N) { float Pi;</p><p class="s19" style="text-indent: 0pt;text-align: left;">#pragma omp target map(from : Pi)</p><p class="s19" style="padding-left: 9pt;text-indent: -10pt;text-align: left;">#pragma omp parallel for reduction(+ : Pi) for (unsigned I = 0; I &lt; N; ++I) {</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">float T = (I + 0.5f) / N; Pi += 4.0f / (1.0 + T * T);</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">return Pi / N;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 9pt;text-indent: -10pt;text-align: left;">void iota(float *A, unsigned N) { cl::sycl::range&lt;1&gt; R(N); cl::sycl::buffer&lt;float, 1&gt; AB(A, R);</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">cl::sycl::queue().submit([&amp;](cl::sycl::handler &amp;cgh) {</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">auto AA = AB.template get_access&lt;cl::sycl::access::mode::write&gt;(cgh); cgh.parallel_for&lt;class Iota&gt;(R, [=](cl::sycl::id&lt;1&gt; I) {</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">AA[I] = I;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">int main() {</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">std::array&lt;float, 1024u&gt; Vec; float Pi;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">#pragma omp parallel sections</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">{</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:123.3pt;width:486.6pt;"><p class="s19" style="padding-left: 19pt;text-indent: -19pt;text-align: left;">#pragma omp section iota(Vec.data(), Vec.size());</p><p class="s19" style="text-indent: 0pt;text-align: left;">#pragma omp section</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">Pi = computePi(8192u);</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Vec[512] = &quot; &lt;&lt; Vec[512] &lt;&lt; std::endl; std::cout &lt;&lt; &quot;Pi = &quot; &lt;&lt; Pi &lt;&lt; std::endl;</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">return 0;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 118%;text-align: left;">The following command is used to compile the example code: <span class="s18">icpx -fsycl -fiopenmp -fopenmp- targets=spir64 offloadOmp_dpcpp.cpp</span></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">where</p><ul id="l76"><li data-list-text="•"><p class="s18" style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">-fsycl <span class="p">option enables SYCL</span></p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-bottom: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 153%;text-align: left;">-fiopenmp -fopenmp-targets=spir64 <span class="p">option enables OpenMP* offload The following shows the program output from the example code.</span></p></li></ul><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">./a.out Vec[512] = 512</p><p class="s19" style="text-indent: 0pt;text-align: left;">Pi = 3.14159</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 110%;text-align: left;"><b>NOTE </b>If the code does not contain OpenMP offload, but only normal OpenMP code, use the following command, which omits <span class="s18">-fopenmp-targets</span>: <span class="s18">icpx -fsycl -fiopenmp omp_dpcpp.cpp</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark67">&zwnj;</a>OpenCL™ Code Interoperability<a name="bookmark158">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The oneAPI programming model enables developers to continue using all OpenCL code features via different parts of the SYCL* API. The OpenCL code interoperability mode provided by SYCL helps reuse the existing OpenCL code while keeping the advantages of higher programming model interfaces provided by SYCL. There are 2 main parts in the interoperability mode:</p><ol id="l77"><li data-list-text="1."><p style="padding-top: 5pt;padding-left: 30pt;text-indent: -25pt;text-align: left;">To create SYCL objects from OpenCL code objects. For example, a SYCL buffer can be constructed from an OpenCL <span class="s18">cl_mem </span>or SYCL queue from a <span class="s18">cl_command_queue</span>.</p></li><li data-list-text="2."><p style="padding-left: 30pt;text-indent: -25pt;text-align: left;">To get OpenCL code objects from SYCL objects. For example, launching an OpenCL kernel that uses an implicit <span class="s18">cl_mem </span>associated to a SYCL accessor.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark68">&zwnj;</a>Debugging the DPC++ and OpenMP* Offload Process<a name="bookmark159">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">When writing, debugging, and optimizing code for a host platform, the process of improving your code is simple: deal with language errors when you build, catch and root-cause crashes/incorrect results during execution with a debugger, then identify and fix performance issues using a profiling tool.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Improving code can become considerably more complicated in applications where part of the execution is offloaded to another device using either DPC++ or OpenMP* offload.</p><ul id="l78"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Incorrect use of the DPC++ or OpenMP* offload languages may not be exposed until after just-in-time compilation occurs. These issues can be exposed earlier with ahead-of-time (AOT) compilation.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Crashes due to logic errors may arise as unexpected behavior on the host, on the offload device, or in the software stack that ties the various computing devices together. To root cause these issues, you need to:</p><ul id="l79"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">Debug what is happening in your code on the host using a standard debugger, such as Intel<span class="s12">® </span>Distribution for GDB*.</p></li><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;text-align: justify;">Debug problems on the offload device using a device-specific debugger. Note, however, that the device may have a different architecture, conventions for representing compute threads, or assembly than the host.</p></li><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;text-align: justify;">To debug problems that show up in the intermediate software stack only when kernels and data are being exchanged with the device, you need to monitor the communication between device and host and any errors that are reported during the process.</p></li></ul></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Besides the usual performance issues that can occur on the host and offload devices, the patterns by which the host and offload device work together can have a profound impact on application performance. This is another case where you need to monitor the communications between the host and offload device.</p></li></ul></li></ol><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">This section discusses the various debugging and performance analysis tools and techniques available to you for the entire lifecycle of the offload program.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/training/troubleshoot-highly-parallel-applications.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To troubleshoot your applications that use OpenMP* or the SYCL* API with extensions to offload resources, see the </a>Troubleshoot Highly Parallel Applications <span style=" color: #000;">tutorial.</span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark69">&zwnj;</a>oneAPI Debug Tools for SYCL* and OpenMP* Development<a name="bookmark160">&zwnj;</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The following tools are available to help with debugging the SYCL* and OpenMP* offload process.</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;">Environment variables</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;">The onetrace tool from Profiling Tools Interfaces for GPU (PTI for GPU)</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;">Environment variables allow you to gather diagnostic information from the OpenMP and SYCL runtimes at program execution with no modifications to your program.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;">When using the Intel<span class="s12">® </span>oneAPI Level Zero and OpenCL<span class="s12">™ </span>backends for SYCL and OpenMP Offload, this tool can be used to debug backend errors and for performance profiling on both the host and device.</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;">Learn more:</p><p style="text-indent: 0pt;text-align: left;"/><ul id="l80"><li data-list-text="•"><p style="padding-left: 14pt;text-indent: -14pt;text-align: left;"><a href="https://github.com/intel/pti-gpu/tree/master/tools/onetrace">Onetrace tool GitHub</a></p></li><li data-list-text="•"><p style="padding-left: 14pt;text-indent: -14pt;text-align: left;"><a href="https://github.com/intel/pti-gpu">PTI for GPU GitHub</a></p></li><li data-list-text="•"><p style="padding-left: 14pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/docs/vtune-profiler/user-guide/2025-0/gpu-compute-media-hotspots-analysis.html" class="a" target="_blank">GPU Compute/Media Hotspots </a><a href="https://www.intel.com/content/www/us/en/docs/vtune-profiler/user-guide/2025-0/gpu-compute-media-hotspots-analysis.html" target="_blank">Analysis</a></p></li></ul><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;">Intercept Layer for OpenCL<span class="s12">™ </span>Applications</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;">Intel<span class="s12">® </span>Distribution for GDB*</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;">Intel<span class="s12">® </span>Inspector</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;">When using the OpenCL<span class="s12">™ </span>backend for SYCL and OpenMP Offload, this library can be used to debug backend errors and for performance profiling on both the host and device (has wider functionality comparing with onetrace).</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;">Used for source-level debugging of the application, typically to inspect logical bugs, on the host and any devices you are using (CPU, GPU, FPGA emulation).</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;">This tool helps to locate and debug memory and threading problems, including those that can cause offloading to fail.</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">When to Use</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Tool</p><p style="text-indent: 0pt;text-align: left;"/><p class="s25" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Tools to debug SYCL* and OpenMP* offload process</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s14" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">Tool              When to Use</p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-left: 175pt;text-indent: 0pt;text-align: left;"><b>NOTE </b>Intel Inspector is included in the Intel<span class="s42">® </span>HPC Toolkit.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 0pt;line-height: 11pt;text-align: left;">In-application debugging    In addition to these tools and runtime based approaches, the developer</p><p style="padding-left: 161pt;text-indent: 0pt;line-height: 11pt;text-align: left;">can locate problems using other approaches. For example:</p><ul id="l81"><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 175pt;text-indent: -14pt;text-align: left;">Comparing kernel output to expected output</p></li><li data-list-text="•"><p style="padding-left: 175pt;text-indent: -14pt;text-align: left;">Sending intermediate results back by variables they create for debugging purposes</p></li><li data-list-text="•"><p style="padding-left: 175pt;text-indent: -14pt;text-align: left;">Printing results from within kernels</p><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s40" style="padding-left: 175pt;text-indent: 0pt;text-align: left;">NOTE <span class="s41">Both SYCL and OpenMP allow printing to stdout from within an offload region - be sure to note which SIMD lane or thread is providing the output.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 0pt;line-height: 11pt;text-align: left;">SYCL Exception Handler     Some DPC++ programming errors are returned as exceptions by the</p><p style="padding-left: 161pt;text-indent: 0pt;text-align: left;">SYCL runtime during program execution. They can help you diagnose errors in your code that are flagged at runtime. For more details and examples, refer to &lt;link&gt; Using SYCL Exceptions &lt;/link&gt;. For Samples that demonstrate SYCL Exceptions, refer to: * Guided Matrix Multiplication Exception * Guided Matrix Multiplication Invalid Contexts * Guided Matrix Multiplication Race Condition</p><p style="padding-top: 8pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Intel<span class="s12">® </span>Advisor          Use to ensure Fortran, C, C++, OpenCL<span class="s12">™</span>, and SYCL applications realize</p><p style="padding-left: 161pt;text-indent: 0pt;text-align: left;">full performance potential on modern processors.</p><p style="padding-top: 7pt;padding-left: 12pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Intel<span class="s12">® </span>VTune <span class="s43">TM </span>Profiler     Use to gather performance data either on the native system or on a</p><p style="padding-left: 161pt;text-indent: 0pt;line-height: 11pt;text-align: left;">remote system.</p><p class="s13" style="padding-top: 8pt;text-indent: 0pt;line-height: 11pt;text-align: right;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/training/offload-optimize-openmp-applications.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">OpenMP* directives      </a>Offload and Optimize OpenMP* Applications with Intel Tools <span style=" color: #000;">describes</span></p><p style="text-indent: 0pt;line-height: 11pt;text-align: right;">how to use OpenMP* directives to add parallelism to your application.</p><p style="padding-top: 4pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Debug Environment Variables</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Both the OpenMP* and SYCL offload runtimes, as well as Level Zero, OpenCL, and the Shader Compiler, provide environment variables that help you understand the communication between the host and offload device. The variables also allow you to discover or control the runtime chosen for offload computations.</p><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">OpenMP* Offload Environment Variables</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">There are several environment variables that you can use to understand how OpenMP Offload works and control which backend it uses.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 1pt;padding-bottom: 3pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">OpenMP is not supported for FPGA devices.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;">LIBOMPTARGET_DEBUG=&lt;Num&gt;</p><p style="text-indent: 0pt;text-align: left;"/><p class="s13" style="text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://openmp.llvm.org/design/Runtimes.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Controls whether or not debugging information will be displayed. See details in </a>Runtimes <span style=" color: #000;">This environment variable enables debug output from the OpenMP Offload runtime. It reports:</span></p><ul id="l82"><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 14pt;text-indent: -14pt;text-align: left;">The available runtimes detected and used (1,2)</p></li></ul><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Description</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Environment Variable</p><p style="text-indent: 0pt;text-align: left;"/><p class="s25" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">OpenMP* Offload Environment Variables</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">Environment Variable               Description</p><ul id="l83"><li data-list-text="•"><p style="padding-top: 9pt;padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">When the chosen runtime is started and stopped (1,2)</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;text-align: left;">Details on the offload device used (1,2)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 275pt;text-indent: -14pt;text-align: left;">Support libraries loaded (1,2)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: justify;">Size and address of all memory allocations and deallocations (1,2)</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: justify;">Information on every data copy to and from the device, or device mapping in the case of unified shared memory (1,2)</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">When each kernel is launched and details on the launch (arguments, SIMD width, group information, etc.) (1,2)</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">Which Level Zero/OpenCL API functions are invoked (function name, arguments/parameters) (2)</p><p style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;text-align: left;">Values:</p><p class="s18" style="padding-top: 6pt;padding-left: 260pt;text-indent: 0pt;text-align: left;">&lt;Num&gt;=0: <span class="p">Disabled</span></p><p class="s18" style="padding-top: 6pt;padding-left: 260pt;text-indent: 0pt;line-height: 109%;text-align: left;">&lt;Num&gt;=1: <span class="p">Displays basic debug information from the plugin actions such as device detection, kernel compilation, memory copy operations, kernel invocations, and other plugin-dependent actions.</span></p><p class="s18" style="padding-top: 5pt;padding-left: 260pt;text-indent: 0pt;line-height: 109%;text-align: left;">&lt;Num&gt;=2: <span class="p">Additionally displays which GPU runtime API functions are invoked with which arguments/ parameters.</span></p><p style="padding-top: 5pt;padding-left: 260pt;text-indent: 0pt;text-align: left;">Default: 0</p><p style="padding-top: 9pt;padding-left: 260pt;text-indent: -248pt;line-height: 110%;text-align: left;"><a href="https://openmp.llvm.org/design/Runtimes.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">LIBOMPTARGET_INFO=&lt;Num&gt;            This variable controls whether basic offloading information will be displayed from the offload runtime. Allows the user to request different types of runtime information from libomptarget. See details in </a><a href="https://openmp.llvm.org/design/Runtimes.html" target="_blank">Runtimes</a></p></li><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">Prints all data arguments upon entering an OpenMP device kernel (1)</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">Indicates when a mapped address already exists in the device mapping table (2)</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">Dumps the contents of the device pointer map if target offloading fails (4)</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">Indicates when an entry is changed in the device mapping table (8)</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">Indicates when data is copied to and from the device (32)</p></li></ul></li></ul><p style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;text-align: left;">Values: (0, 1, 2, 4, 8, 32)</p><p style="padding-top: 6pt;padding-left: 261pt;text-indent: 0pt;text-align: left;">Default: 0</p><p style="padding-top: 9pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_PLUGIN_PROFILE=&lt;Enable&gt;[,&lt;Un</p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">it&gt;]</p><p style="padding-top: 9pt;padding-left: 12pt;text-indent: 0pt;line-height: 110%;text-align: left;">This variable enables the display of performance data for offloaded OpenMP code. It displays:</p><ul id="l84"><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 26pt;text-indent: -14pt;text-align: left;">Total data transfer times (read and write)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 26pt;text-indent: -14pt;text-align: left;">Data allocation times</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">Environment Variable               Description</p><ul id="l85"><li data-list-text="•"><p style="padding-top: 9pt;padding-left: 275pt;text-indent: -14pt;text-align: left;">Module build times (just-in-time compile)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 261pt;text-indent: 0pt;line-height: 159%;text-align: left;">The execution time of each kernel. Values:</p></li><li data-list-text="•"><p class="s18" style="padding-left: 275pt;text-indent: -14pt;line-height: 11pt;text-align: left;">F <span class="p">- disabled</span></p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 275pt;text-indent: -14pt;text-align: left;">T <span class="p">- enabled with timings in milliseconds</span></p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 260pt;text-indent: 0pt;line-height: 153%;text-align: left;">T,usec <span class="p">- enabled with timings in microseconds Default: </span>F</p><p style="padding-top: 1pt;padding-left: 260pt;text-indent: 0pt;line-height: 118%;text-align: left;">Example: <span class="s18">export LIBOMPTARGET_PLUGIN_PROFILE=T,usec</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:230.8pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">&lt;Enable&gt; := 1 | T</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;Unit&gt; := usec | unit_usec</p></div></li></ul></li></ul><p style="padding-left: 261pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 260pt;text-indent: 0pt;line-height: 110%;text-align: left;">Enables basic plugin profiling and displays the result when program finishes. Microsecond is the default unit if <span class="s18">&lt;Unit&gt; </span>is not specified.</p><p style="padding-top: 8pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_PLUGIN=&lt;Name&gt;          This environment variable allows you to choose the</p><p style="padding-top: 1pt;padding-left: 260pt;text-indent: 0pt;text-align: left;">backend used for OpenMP offload execution.</p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s40" style="padding-left: 269pt;text-indent: 0pt;line-height: 123%;text-align: left;">NOTE <span class="s41">The Level Zero backend is only supported for GPU devices.</span></p><p style="padding-top: 12pt;text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:230.8pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;Name&gt; := LEVEL0 | OPENCL | CUDA | X86_64 | NIOS2 |</p><p class="s19" style="padding-left: 49pt;text-indent: 0pt;text-align: left;">level0 | opencl | cuda | x86_64 |</p><p class="s19" style="text-indent: 0pt;text-align: left;">nios2 |</p></div><p style="padding-left: 261pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 260pt;text-indent: 0pt;line-height: 110%;text-align: left;">Designates offload plugin name to use. Offload runtime does not try to load other RTLs if this option is used.</p><p style="padding-top: 5pt;padding-left: 260pt;text-indent: 0pt;text-align: left;">Values:</p><ul id="l86"><ul id="l87"><li data-list-text="•"><p class="s18" style="padding-top: 5pt;padding-left: 275pt;text-indent: -14pt;line-height: 108%;text-align: left;">LEVEL0 <span class="p">or </span>LEVEL_ZERO <span class="p">- uses the Level Zero backend</span></p></li><li data-list-text="•"><p style="padding-left: 260pt;text-indent: 0pt;line-height: 153%;text-align: left;"><span class="s18">OPENCL </span>- uses the OpenCL<span class="s12">™ </span>backend Default:</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;text-align: left;">For GPU offload devices: <span class="s18">LEVEL0</span></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 275pt;text-indent: -14pt;text-align: left;">For CPU or FPGA offload devices: <span class="s18">OPENCL</span></p></li></ul></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_PROFILE=&lt;FileName&gt;       Allows libomptarget to generate time profile output</p><p style="padding-top: 1pt;padding-left: 260pt;text-indent: 0pt;line-height: 108%;text-align: left;">similar to Clang’s <span class="s18">-ftime-trace </span><a href="https://openmp.llvm.org/design/Runtimes.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">option. See details in </a><a href="https://openmp.llvm.org/design/Runtimes.html" target="_blank">Runtimes</a></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:230.8pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;DeviceKind&gt; := DEVICE | SUBDEVICE | SUBSUBDEVICE | ALL |</p><p class="s19" style="text-indent: 79pt;text-align: left;">device | subdevice | subsubdevice | all</p></div><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 8pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_DEVICES=&lt;DeviceKind&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 261pt;text-indent: 0pt;text-align: left;">Controls how subdevices are exposed to users.</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">Environment Variable               Description</p><p class="s18" style="padding-top: 10pt;padding-left: 260pt;text-indent: 0pt;line-height: 108%;text-align: left;">DEVICE/device<span class="p">: Only top-level devices are reported as OpenMP devices, and </span>subdevice <span class="p">clause is supported.</span></p><p class="s18" style="padding-top: 5pt;padding-left: 260pt;text-indent: 0pt;line-height: 108%;text-align: left;">SUBDEVICE/subdevice<span class="p">: Only 1st-level subdevices are reported as OpenMP devices, and </span>subdevice <span class="p">clause is ignored.</span></p><p class="s18" style="padding-top: 5pt;padding-left: 260pt;text-indent: 0pt;line-height: 109%;text-align: left;">SUBSUBDEVICE/subsubdevice<span class="p">: Only 2nd-level subdevices are reported as OpenMP devices, and </span>subdevice <span class="p">clause is ignored. On Intel GPU using Level Zero backend, limiting the </span>subsubdevice <span class="p">to a single compute slice within a stack also requires setting additional GPU compute runtime environment variable </span>CFESingleSliceDispatchCCSMode=1<span class="p">.</span></p><p class="s18" style="padding-top: 5pt;padding-left: 260pt;text-indent: 0pt;line-height: 109%;text-align: left;">ALL/all<span class="p">: All top-level devices and their subdevices are reported as OpenMP devices, and </span>subdevice <span class="p">clause is ignored. This is not supported on Intel GPU and is being deprecated.</span></p><p class="s14" style="padding-top: 5pt;padding-left: 260pt;text-indent: 0pt;text-align: left;">Default<span class="p">: Equivalent to </span><span class="s18">&lt;DeviceKind&gt;=device</span></p><p style="padding-top: 9pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_LEVEL0_MEMORY_POOL=&lt;Option</p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_LEVEL0_STAGING_BUFFER_SIZE=</p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">&lt;Num&gt;</p><p style="padding-top: 5pt;padding-left: 12pt;text-indent: 0pt;line-height: 109%;text-align: left;">Controls how reusable memory pool is configured. Pool is a list of memory blocks that can serve at least <span class="s18">&lt;Capacity&gt; </span>allocations of up to <span class="s18">&lt;AllocMax&gt; </span>size from a single block, with total size not exceeding <span class="s18">&lt;PoolSize&gt;</span>.</p><p class="s14" style="padding-top: 5pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Default<span class="p">: Equivalent to</span></p><p class="s18" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;line-height: 119%;text-align: left;">&lt;Option&gt;=device,1,4,256,host,1,4,256,shar ed,8,4,256</p><p style="padding-top: 7pt;padding-left: 12pt;text-indent: 0pt;line-height: 109%;text-align: left;">Sets the staging buffer size to <span class="s18">&lt;Num&gt; </span>KB. Staging buffer is used in copy operations between host and device as a temporary storage for two-step copy operation. The buffer is only used for discrete devices.</p><p class="s14" style="padding-top: 5pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Default<span class="p">: 16</span></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s18" style="text-indent: 0pt;text-align: left;">&lt;Option&gt;</p><p style="text-indent: 0pt;text-align: left;"/><p class="s18" style="text-indent: 0pt;text-align: left;">:= 0 | &lt;PoolInfoList&gt;</p><p style="text-indent: 0pt;text-align: left;"/><p class="s18" style="text-indent: 0pt;text-align: left;">&lt;PoolInfoList&gt; := &lt;PoolInfo&gt;[,&lt;PoolInfoList&gt;]</p><p class="s18" style="text-indent: 0pt;text-align: left;">&lt;PoolInfo&gt;  :=</p><p class="s18" style="text-indent: 0pt;text-align: left;">&lt;MemType&gt;[,&lt;AllocMax&gt;[,&lt;Capacity&gt;[,&lt;PoolSize&gt;]</p><p class="s18" style="text-indent: 0pt;text-align: left;">]]</p><p class="s18" style="text-indent: 0pt;text-align: left;">&lt;MemType&gt;  := all | device | host | shared</p><p class="s18" style="text-indent: 0pt;text-align: left;">&lt;AllocMax&gt; := positive integer or empty, max allocation size in MB</p><p class="s18" style="text-indent: 0pt;text-align: left;">&lt;Capacity&gt; := positive integer or empty, number of allocations from a</p><p class="s18" style="padding-left: 89pt;text-indent: 0pt;text-align: left;">single block</p><p class="s18" style="text-indent: 0pt;text-align: left;">&lt;PoolSize&gt; := positive integer or empty, max pool size in MB</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">Environment Variable               Description</p><div class="textbox" style="background:#F0F0F0;display:block;min-height:302.7pt;width:230.8pt;"><p class="s19" style="padding-left: 4pt;text-indent: 0pt;line-height: 10pt;text-align: left;">&lt;Value&gt; := &lt;Type&gt;[,&lt;Count&gt;]</p><p class="s19" style="text-indent: 4pt;text-align: left;">&lt;Type&gt; := none | NONE | copy | COPY | compute | COMPUTE</p><p class="s19" style="text-indent: 4pt;text-align: left;">&lt;Count&gt; := maximum number of commands to batch</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">Enables command batching for a target region.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">``&lt;Type&gt;=none|NONE``: Disables command batching.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: justify;">``&lt;Type&gt;=copy|COPY``: Enables command batching for a target region for data transfer.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">``&lt;Type&gt;=compute|COMPUTE``: Enables command batching for a target region for</p><p class="s19" style="text-indent: 0pt;text-align: left;">data transfer and compute, disabling use of copy engine.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">If ``&lt;Type&gt;`` is either ``copy`` or</p><p class="s19" style="text-indent: 0pt;text-align: left;">``compute`` (enabled) and ``&lt;Count&gt;`` is not specified, batching is performed for all eligible commands for the target</p><p class="s19" style="text-indent: 0pt;text-align: left;">region.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">**Default**: ``&lt;Type&gt;=none`` (Disabled)</p></div><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 10pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">LIBOMPTARGET_LEVEL_ZERO_COMMAND_BATCH=</p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">&lt;Value&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:56.0pt;width:230.8pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">&lt;True&gt; := 1 | T | t</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;False&gt;:= 0 | F | f</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;Bool&gt;:= &lt;True&gt; | &lt;False&gt;</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;Value&gt; := &lt;Bool&gt; | compute | COMPUTE | copy</p><p class="s19" style="text-indent: 0pt;text-align: left;">| COPY | all | ALL</p></div><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 12pt;text-indent: 0pt;line-height: 110%;text-align: left;">LIBOMPTARGET_LEVEL_ZERO_USE_IMMEDIATE_CO MMAND_LIST=&lt;Value&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s18" style="padding-left: 260pt;text-indent: 0pt;line-height: 108%;text-align: left;">compute<span class="p">: Enables immediate command list for kernel submission</span></p><p class="s18" style="padding-left: 261pt;text-indent: 0pt;line-height: 108%;text-align: left;">copy<span class="p">: Enables immediate command list for memory copy operations</span></p><p class="s18" style="padding-left: 260pt;text-indent: 0pt;line-height: 108%;text-align: left;">all<span class="p">: Enables immediate command list for kernel submission and memory copy operations</span></p><p class="s18" style="padding-left: 260pt;text-indent: 0pt;line-height: 108%;text-align: left;">&lt;True&gt;<span class="p">: Equivalent to </span>compute&lt;False&gt;<span class="p">: Immediate command list is disabled.</span></p><p class="s14" style="padding-top: 7pt;padding-left: 260pt;text-indent: 0pt;text-align: left;">Default<span class="p">: “all”</span></p><p style="padding-top: 9pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><a href="https://www.openmp.org/spec-html/5.1/openmpse74.html#x340-5150006.17" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">OMP_TARGET_OFFLOAD=MANDATORY        This is defined by the OpenMP Standard : </a><a href="https://www.openmp.org/spec-html/5.1/openmpse74.html#x340-5150006.17" target="_blank">https://</a></p><p style="padding-top: 1pt;padding-left: 260pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.openmp.org/spec-html/5.1/openmpse74.html#x340-5150006.17" class="a" target="_blank">www.openmp.org/spec-html/5.1/ openmpse74.html#x340-</a><a href="https://www.openmp.org/spec-html/5.1/openmpse74.html#x340-5150006.17" target="_blank">5150006.17</a></p><p style="padding-top: 8pt;padding-left: 261pt;text-indent: -248pt;line-height: 110%;text-align: left;">ONEAPI_DEVICE_SELECTOR              This device selection environment variable can be used to limit the choice of devices available when the OpenMP application is run. Useful for limiting devices to a certain type (like GPUs or accelerators) or backends (like Level Zero or OpenCL). The ONEAPI_DEVICE_SELECTOR syntax is shared with</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><div class="textbox" style="border:1.0pt solid #000000;display:block;min-height:57.4pt;width:498.6pt;"><p class="s29" style="padding-top: 4pt;padding-left: 254pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://intel.github.io/llvm-docs/EnvironmentVariables.html" class="s47" target="_blank">OpenMP and also allows devices to be chosen. See oneAPI DPC++ Compiler documentation for a full description. See </a><a href="https://intel.github.io/llvm-docs/EnvironmentVariables.html" class="s27" target="_blank">oneAPI DPC++ Compiler </a>documentation <span style=" color: #000;">for a full description.</span></p></div><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Description</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="text-indent: 0pt;text-align: left;">Environment Variable</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL* and DPC++ Environment Variables</p><p class="s13" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The oneAPI DPC++ Compiler supports all standard SYCL environment variables. The full list is available from </a>GitHub<span style=" color: #000;">. Of interest for debugging are the following SYCL environment variables, plus an additional Level Zero environment variable.</span></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s25" style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL* and DPC++ Environment Variables</p><p class="s14" style="padding-top: 7pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Environment Variable               Description</p><p style="padding-top: 10pt;padding-left: 261pt;text-indent: -248pt;line-height: 110%;text-align: left;">ONEAPI_DEVICE_SELECTOR             This complex environment variable allows you to limit the runtimes, compute device types, and compute device IDs used by the runtime to a subset of all available combinations.</p><p style="padding-top: 5pt;padding-left: 260pt;text-indent: 0pt;line-height: 109%;text-align: left;">The compute device IDs correspond to those returned by the SYCL API, <span class="s18">clinfo</span>, or <span class="s18">sycl-ls </span>(with the numbering starting at 0) and have no relation to whether the device with that ID is of a certain type or supports a specific runtime. Using a programmatic special selector (like <span class="s18">gpu_selector</span>) to request a device filtered out by <span class="s18">ONEAPI_DEVICE_SELECTOR </span>will cause an exception to be thrown.</p><p style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Refer to the Environment Variables descriptions in GitHub for additional details: </a><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md" class="a" target="_blank">https://github.com/ intel/llvm/blob/sycl/sycl/doc/ </a><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md" target="_blank">EnvironmentVariables.md</a></p><p style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;text-align: left;">Example values include:</p><ul id="l88"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 275pt;text-indent: -14pt;line-height: 108%;text-align: left;"><span class="s18">opencl:cpu </span>- use only the OpenCL<span class="s12">™ </span>runtime on all available CPU devices</p></li><li data-list-text="•"><p class="s18" style="padding-left: 275pt;text-indent: -14pt;line-height: 108%;text-align: left;">opencl:gpu <span class="p">- use only the OpenCL runtime on all available GPU devices</span></p></li><li data-list-text="•"><p class="s18" style="padding-left: 275pt;text-indent: -14pt;line-height: 109%;text-align: left;">opencl:gpu:2 <span class="p">- use only the OpenCL runtime on only the third device, which also has to be a GPU</span></p></li><li data-list-text="•"><p class="s18" style="padding-left: 275pt;text-indent: -14pt;line-height: 109%;text-align: justify;">level_zero:gpu:1 <span class="p">- use only the Level Zero runtime on only the second device, which also has to be a GPU</span></p></li><li data-list-text="•"><p class="s18" style="padding-left: 275pt;text-indent: -14pt;line-height: 109%;text-align: left;">opencl:cpu,level_zero <span class="p">- use only the OpenCL runtime on the CPU device, or the Level Zero runtime on any supported compute device</span></p><p style="padding-top: 5pt;padding-left: 260pt;text-indent: 0pt;text-align: left;">Default: use all available runtimes and devices</p><p style="padding-top: 9pt;padding-left: 260pt;text-indent: -248pt;line-height: 110%;text-align: left;">ONEAPI_DEVICE_SELECTOR             This device selection environment variable can be used to limit the choice of devices available when the SYCL-using application is run. Useful for limiting</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s14" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">Environment Variable               Description</p><p style="padding-top: 10pt;padding-left: 261pt;text-indent: 0pt;line-height: 110%;text-align: left;">devices to a certain type (like GPUs or accelerators) or backends (like Level Zero or OpenCL). This device selection mechanism is replacing ONEAPI_DEVICE_SELECTOR . The</p><p style="padding-left: 261pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://intel.github.io/llvm/EnvironmentVariables.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">ONEAPI_DEVICE_SELECTOR syntax is shared with OpenMP and also allows devices to be chosen. Refer to oneAPI DPC++ Compiler documentation for a full description: </a><a href="https://intel.github.io/llvm/EnvironmentVariables.html" class="a" target="_blank">https://intel.github.io/llvm/ </a><a href="https://intel.github.io/llvm/EnvironmentVariables.html" target="_blank">EnvironmentVariables.html</a></p><p style="padding-top: 8pt;padding-left: 261pt;text-indent: -248pt;line-height: 110%;text-align: left;">SYCL_UR_TRACE                   This environment variable enables debug output from the runtime.</p><p style="padding-top: 5pt;padding-left: 261pt;text-indent: 0pt;text-align: left;">Values:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">1 - report SYCL plugins and devices discovered and used</p></li><li data-list-text="•"><p style="padding-left: 275pt;text-indent: -14pt;line-height: 110%;text-align: left;">2 - report SYCL API calls made, including arguments and result values</p></li><li data-list-text="•"><p style="padding-left: 261pt;text-indent: 0pt;line-height: 159%;text-align: left;">-1 - provides all available tracing Default:disabled</p><p style="padding-top: 3pt;padding-left: 261pt;text-indent: -248pt;line-height: 110%;text-align: left;">ZE_DEBUG                      This environment variable enables debug output from the Level Zero backend when used with the runtime. It reports:</p></li><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 275pt;text-indent: -14pt;text-align: left;">Level Zero APIs called</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 275pt;text-indent: -14pt;text-align: left;">Level Zero event information</p></li></ul><p style="padding-top: 6pt;padding-left: 260pt;text-indent: 0pt;line-height: 159%;text-align: left;">Value: variable defined with any value - enabled Default: disabled</p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Environment Variables that Produce Diagnostic Information for Support</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The Level Zero backend provides a few environment variables that can be used to control behavior and aid in diagnosis.</p><ul id="l89"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://oneapi-src.github.io/level-zero-spec/level-zero/latest/core/PROG.html#environment-variables">Level Zero Specification Core Programming Guide</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://oneapi-src.github.io/level-zero-spec/level-zero/latest/tools/PROG.html">Level Zero Specification Tool Programming Guide</a></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">An additional source of debug information comes from the Intel<span class="s12">® </span>Graphics Compiler, which is called by the Level Zero or OpenCL backends (used by both the OpenMP Offload and SYCL/DPC++ Runtimes) at runtime or during Ahead-of-Time (AOT) compilation. Intel<span class="s12">® </span><a href="https://github.com/intel/intel-graphics-compiler/blob/master/documentation/configuration_flags.md" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Graphics Compiler creates the appropriate executable code for the target offload device. The full list of these environment variables can be found at </a><a href="https://github.com/intel/intel-graphics-compiler/blob/master/documentation/configuration_flags.md" class="a" target="_blank">https:// </a><span style=" color: #075FA7;">github.com/intel/intel-graphics-compiler/blob/master/documentation/configuration_flags.md</span>. The two that are most often needed to debug performance issues are:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;"><span class="s18">IGC_ShaderDumpEnable=1 (default=0) </span>causes all LLVM, assembly, and ISA code generated by the Intel<span class="s12">® </span>Graphics Compiler to be written to <span class="s18">/tmp/IntelIGC/&lt;application_name&gt;</span></p></li><li data-list-text="•"><p class="s18" style="padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: justify;">IGC_DumpToCurrentDir=1 (default=0) <span class="p">writes all the files created by </span>IGC_ShaderDumpEnable <span class="p">to your current directory instead of </span>/tmp/IntelIGC/&lt;application_name&gt;<span class="p">. Since this is potentially a lot of files, it is recommended to create a temporary directory just for the purpose of holding these files.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">If you have a performance issue with your OpenMP offload or SYCL offload application that arises between different versions of Intel<span class="s12">® </span>oneAPI, when using different compiler options, when using the debugger, and so on, then you may be asked to enable <span class="s18">IGC_ShaderDumpEnable </span><a href="#bookmark170" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">and provide the resulting files. For more information on compatibility, see </a><span style=" color: #075FA7;">oneAPI Library Compatibility</span>.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Offload Intercept Tools</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">In addition to debuggers and diagnostics built into the offload software itself, it can be quite useful to monitor offload API calls and the data sent through the offload pipeline. For Level Zero, if your application is run as an argument to the onetrace and ze_tracer tools, they will intercept and report on various aspects of Level Zero made by your application. For OpenCL<span class="s12">™</span>, you can add a library to <span class="s18">LD_LIBRARY_PATH </span>that will intercept and report on all OpenCL calls, and then use environment variables to control what diagnostic information to report to a file. You can also use onetrace or cl_tracer to report on various aspects of OpenCL API calls made by your application. Once again, your application is run as an argument to the onetrace or cl_tracer tool.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Intercept Layer for OpenCL<span class="s12">™ </span>Applications</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">This library collects debugging and performance data when OpenCL is used as the backend to your SYCL or OpenMP offload program. When OpenCL is used as the backend to your SYCL or OpenMP offload program, this tool can help you detect buffer overwrites, memory leaks, mismatched pointers, and can provide more detailed information about runtime error messages (allowing you to diagnose these issues when either CPU, FPGA, or GPU devices are used for computation). Note that you will get nothing useful if you use ze_tracer on a program that uses the OpenCL backend, or the Intercept Layer for OpenCL<span class="s12">™ </span>Applications library and cl_tracer on a program that uses the Level Zero backend.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Additional resources:</p></li><li data-list-text="•"><p class="s13" style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://github.com/intel/opencl-intercept-layer" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Extensive information on building and using the Intercept Layer for OpenCL Applications is available from </a>https://github.com/intel/opencl-intercept-layer<span style=" color: #000;">.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 1pt;padding-bottom: 1pt;padding-left: 35pt;text-indent: 0pt;line-height: 118%;text-align: left;"><b>NOTE </b>For best results, run <span class="s18">cmake </span>with the following flags: <span class="s18">-DENABLE_CLIPROF=TRUE - DENABLE_CLILOADER=TRUE</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://github.com/gmeeker/clintercept" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Information about a similar tool (CLIntercept) is available from </a>https://github.com/gmeeker/clintercept <a href="https://sourceforge.net/p/clintercept/wiki/Home/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">and </a>https://sourceforge.net/p/clintercept/wiki/Home/<span style=" color: #000;">.</span></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 112%;text-align: left;">Information on the controls for the Intercept Layer for OpenCL<span class="s12">™ </span><a href="https://github.com/intel/opencl-intercept-layer/blob/master/docs/controls.md" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Applications can be found at </a><a href="https://github.com/intel/opencl-intercept-layer/blob/master/docs/controls.md" class="a" target="_blank">https:// </a><span style=" color: #075FA7;">github.com/intel/opencl-intercept-layer/blob/master/docs/controls.md</span>.</p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 11pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-gpu-optimization-guide/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Information about optimizing for GPUs is available from the </a>Intel oneAPI GPU Optimization Guide<span style=" color: #000;">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Profiling Tools Interfaces for GPU (onetrace, cl_tracer, and ze_trace)</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Like the Intercept Layer for OpenCL<span class="s12">™ </span><a href="https://github.com/intel/pti-gpu" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Applications, these tools collect debugging and performance data from applications that use the OpenCL and Level Zero offload backends for offload via OpenMP* or SYCL. Note that Level Zero can only be used as the backend for computations that happen on the GPU (there is no Level Zero backend for the CPU or FPGA at this time). The onetrace tool is part of the Profiling Tools Interfaces for GPU (PTI for GPU) project, found at </a><span style=" color: #075FA7;">https://github.com/intel/pti-gpu</span>. This project also contains the ze_tracer and cl_tracer tools, which trace just activity from the Level Zero or OpenCL offload backends respectively. The ze_tracer and cl_tracer tools will produce no output if they are used with the application using the other backend, while onetrace will provide output no matter which offload backend you use.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://github.com/intel/pti-gpu/tree/master/tools/onetrace" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The onetrace tool is distributed as source. Instructions for how to build the tool are available from </a><a href="https://github.com/intel/pti-gpu/tree/master/tools/onetrace" class="a" target="_blank">https:// </a>github.com/intel/pti-gpu/tree/master/tools/onetrace<span style=" color: #000;">. The tool provides the following features:</span></p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Call logging: This mode allows you to trace all standard Level Zero (L0) and OpenCL<span class="s12">™ </span>API calls along with their arguments and return values annotated with time stamps. Among other things, this can give you supplemental information on any failures that occur when a host program tries to make use of an attached compute device.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Host and device timing: These provide the duration of all API calls, the duration of each kernel, and application runtime for the entire application.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Device Timeline mode: Gives time stamps for each device activity. All the time stamps are in the same (CPU) time scale.</p></li><li data-list-text="•"><p class="s13" style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;"><a href="https://www.chromium.org/developers/how-tos/trace-event-profiling-tool/" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Chrome Call Logging mode: Dumps API calls to JSON format that can be opened in </a><a href="https://www.chromium.org/developers/how-tos/trace-event-profiling-tool/" class="a" target="_blank">chrome://tracing </a>browser tool<span style=" color: #000;">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 159%;text-align: left;">These data can help debug offload failures or performance issues. Additional resources:</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://github.com/intel/pti-gpu">Profiling Tools Interfaces for GPU (PTI for GPU) GitHub project</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://github.com/intel/pti-gpu/tree/master/tools/onetrace">Onetrace tool GitHub</a></p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Intel® Distribution for GDB*</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The Intel<span class="s12">® </span>Distribution for GDB* is an application debugger that allows you to inspect and modify the program state. With the debugger, both the host part of your application and kernels that are offloaded to a device can be debugged seamlessly in the same debug session. The debugger supports the CPU, GPU, and FPGA-emulation devices. Major features of the tool include:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Automatically attaching to the GPU device to listen to debug events</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Automatically detecting JIT-compiled, or dynamically loaded, kernel code for debugging</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Defining breakpoints (both inside and outside of a kernel) to halt the execution of the program</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Listing the threads; switching the current thread context</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Listing active SIMD lanes; switching the current SIMD lane context per thread</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Evaluating and printing the values of expressions in multiple thread and SIMD lane contexts</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Inspecting and changing register values</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Disassembling the machine instructions</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Displaying and navigating the function call-stack</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Source- and instruction-level stepping</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Non-stop and all-stop debug mode</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Recording the execution using Intel Processor Trace (CPU only)</p><p class="s13" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><span style=" color: #000;">For more information and links to full documentation for Intel Distribution for GDB, see </span><span class="s20">Get Started with Intel</span><span class="s24">® </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-debugging-dpcpp-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Distribution for GDB on</a>Linux* Host<a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-debugging-dpcpp-windows/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">|</a>Windows* Host<span style=" color: #000;">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Intel® Inspector for Offload</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">Intel<span class="s12">® </span>Inspector is a dynamic memory and threading error checking tool for users developing serial and multithreaded applications. It can be used to verify correctness of the native part of the application as well as dynamically generated offload code.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Unlike the tools and techniques above, Intel Inspector cannot be used to catch errors in offload code that is communicating with a GPU or an FPGA. Instead, Intel Inspector requires that the SYCL or OpenMP runtime needs to be configured to execute kernels on CPU target. In general, it requires definition of the following environment variables prior to an analysis run.</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">To configure a SYCL application to run kernels on a CPU device</p><p style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">export               ONEAPI_DEVICE_SELECTOR=opencl:cpu                </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">To configure an OpenMP application to run kernels on a CPU device</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">export OMP_TARGET_OFFLOAD=MANDATORY</p><p class="s19" style="text-indent: 0pt;text-align: left;">export LIBOMPTARGET_DEVICETYPE=cpu</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><ul id="l90"><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">To enable code analysis and tracing in JIT compilers or runtimes</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">export CL_CONFIG_USE_VTUNE=True export CL_CONFIG_USE_VECTORIZER=false</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Use one of the following commands to start analysis from the command line. You can also start from the Intel Inspector graphical user interface.</p><ul id="l91"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Memory: <span class="s18">inspxe-cl -c mi3 -- &lt;app&gt; [app_args]</span></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Threading: <span class="s18">inspxe-cl -c ti3 -- &lt;app&gt; [app_args]</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">View the analysis result using the following command: <span class="s18">inspxe-cl -report=problems -report-all</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">If your SYCL or OpenMP Offload program passes bad pointers to the OpenCL<span class="s12">™ </span>backend, or passes the wrong pointer to the backend from the wrong thread, Intel Inspector should flag the issue. This may make the problem easier to find than trying to locate it using the intercept layers or the debugger.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span style=" color: #000;">Additional details are available from the </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/inspector-user-guide-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Intel Inspector User Guide for</a>Linux* OS<a href="https://www.intel.com/content/www/us/en/develop/documentation/inspector-user-guide-windows/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">|</a>Windows* OS<span style=" color: #000;">.</span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark70">&zwnj;</a>Trace the Offload Process<a name="bookmark161">&zwnj;</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="#bookmark160" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">When a program that offloads computation to a GPU is started, there are lot of moving parts involved in program execution. Machine-independent code needs to be compiled to machine-dependent code, data and binaries need to be copied to the device, results returned, etc. This section will discuss how to trace all this activity using the tools described in the </a>oneAPI Debug Tools <span style=" color: #000;">section.</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Kernel Setup Time</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Before offload code can run on the device, the machine-independent version of the kernel needs to be compiled for the target device, and the resulting code needs to be copied to the device. This can complicate/ skew benchmarking if this kernel setup time is not considered. Just-in-time compilation can also introduce a noticeable delay when debugging an offload application.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">If you have an OpenMP* offload program, setting <span class="s18">LIBOMPTARGET_PLUGIN_PROFILE=T[,usec] </span>explicitly reports the amount of time required to build the offload code “ModuleBuild”, which you can compare to the overall execution time of your program.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Kernel setup time is more difficult to determine if you have a SYCL* offload program.</p></li><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;line-height: 112%;text-align: left;">If Level Zero or OpenCL<span class="s12">™ </span>is your backend, you can derive kernel setup time from the Device Timing and Device Timeline returned by onetrace or ze_tracer.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;">If OpenCL<span class="s12">™ </span>is your backend, you may also be able to derive the information by setting the <span class="s18">BuildLogging</span>, <span class="s18">KernelInfoLogging</span>, <span class="s18">CallLogging</span>, <span class="s18">CallLoggingElapsedTime</span>, <span class="s18">KernelInfoLogging</span>, <span class="s18">HostPerformanceTiming</span>, <span class="s18">HostPerformanceTimeLogging</span>, <span class="s18">ChromeCallLogging</span>, or <span class="s18">CallLoggingElapsedTime </span>flags when using the Intercept Layer for OpenCL<span class="s12">™ </span>Applications to get similar information. You can also derive kernel setup time from the Device Timing and Device Time- line returned by onetrace or cl_tracer.</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 153%;text-align: left;">You can also use these tools to supplement the information returned by <span class="s18">LIBOMPTARGET_PLUGIN_PROFILE=T</span>. For details on how Intel<span class="s12">® </span>VTune<span class="s12">™ </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/set-up-analysis-target/linux-targets/enabling-linux-kernel-analysis.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Profiler can analyze kernel setup time, see </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/set-up-analysis-target/linux-targets/enabling-linux-kernel-analysis.html" target="_blank">Enable Linux* Kernel Analysis</a></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Monitoring Buffer Creation, Sizes, and Copies</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Understanding when buffers are created, how many buffers are created, and whether they are reused or constantly created and destroyed can be key to optimizing the performance of your offload application. This may not always be obvious when using a high-level programming language like OpenMP or SYCL, which can hide a lot of the buffer management from the user.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">At a high level, you can track buffer-related activities using the <span class="s18">LIBOMPTARGET_DEBUG </span>and <span class="s18">SYCL_UR_TRACE </span>environment variables when running your program. <span class="s18">LIBOMPTARGET_DEBUG </span>gives you more information than <span class="s18">SYCL_UR_TRACE </span>- it reports the addresses and sizes of the buffers created. By contrast, <span class="s18">SYCL_UR_TRACE </span>just reports the API calls, with no information you can easily tie to the location or size of individual buffers.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">At a lower level, if you are using Level Zero or OpenCL<span class="s12">™ </span>as your backend, the Call Logging mode of onetrace or ze_tracer will give you information on all API calls, including their arguments. This can be useful because, for example, a call for buffer creation (such as <span class="s18">zeMemAllocDevice</span>) will give you the size of the resulting buffer being passed to and from the device. onetrace and ze_tracer also allows you to dump all the Level Zero device-side activities (including memory transfers) in Device Timeline mode. For each activity one can get append (to command list), submit (to queue), start and end times.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">If you are using OpenCL as your backend, setting the <span class="s18">CallLogging</span>, <span class="s18">CallLoggingElapsedTime</span>, and <span class="s18">ChromeCallLogging </span>flags when using the Intercept Layer for OpenCL<span class="s12">™ </span>Applications should give you similar information. The Call Logging mode of onetrace or cl_tracer will give you information on all OpenCL API calls, including their arguments. As was the case above, onetrace and cl_tracer also allow you to dump all the OpenCL device-side activities (including memory transfers) in Device Timeline mode.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Total Transfer Time</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Comparing total data transfer time to kernel execution time can be important for determining whether it is profitable to offload a computation to a connected device.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">If you have an OpenMP offload program, setting <span class="s18">LIBOMPTARGET_PLUGIN_PROFILE=T[,usec] </span>explicitly reports the amount of time required to build (“DataAlloc”), read (“DataRead”), and write data (“DataWrite”) to the offload device (although only in aggregate).</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Data transfer times can be more difficult to determine if you have a C++ program using SYCL.</p></li><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;line-height: 112%;text-align: left;">If Level Zero or OpenCL<span class="s12">™ </span>is your backend, you can derive total data transfer time from the Device Timing and Device Timeline returned by onetrace or ze_tracer.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;">If OpenCL is your backend, you can use onetrace or cl_tracer, or alternatively you may also be able to derive the information by setting the <span class="s18">BuildLogging</span>, <span class="s18">KernelInfoLogging</span>, <span class="s18">CallLogging</span>, <span class="s18">CallLoggingElapsedTime</span>, <span class="s18">KernelInfoLogging</span>, <span class="s18">HostPerformanceTiming</span>, <span class="s18">HostPerformanceTimeLogging</span>, <span class="s18">ChromeCallLogging</span>, or <span class="s18">CallLoggingElapsedTime </span>flags when using the Intercept Layer for OpenCL Applications.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;">For details on how Intel<span class="s12">® </span>VTune<span class="s12">™ </span>Profiler can analyze transfer setup time, see these sections of the Intel<span class="s12">® </span>VTune<span class="s12">™ </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/analyze-performance/accelerators-group/gpu-offload-analysis.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Profiler User Guide: </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/analyze-performance/accelerators-group/gpu-compute-media-hotspots-analysis/gpu-compute-media-hotspots-view.html" class="a" target="_blank">GPU Offload Analysis</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/command-line-interface/generating-command-line-reports/hotspots-report.html" class="a" target="_blank">GPU Compute/Media Hotspots View</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/command-line-interface/generating-command-line-reports/hotspots-report.html" target="_blank">Hotspots Report</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Kernel Execution Time</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">If you have an OpenMP offload program, setting <span class="s18">LIBOMPTARGET_PLUGIN_PROFILE=T[,usec] </span>explicitly reports the total execution time of every offloaded kernel (“Kernel#…”).</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For programs using SYCL to offload kernels:</p></li><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;line-height: 112%;text-align: left;">If Level Zero or OpenCL<span class="s12">™ </span>is your backend, the Device Timing mode of onetrace or ze_tracer will give you the device-side execution time for every kernel.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;">If OpenCL is your backend , you can use onetrace or cl_tracer, or alternatively you may be able to derive the information by setting the <span class="s18">CallLoggingElapsedTime</span>, <span class="s18">DevicePerformanceTiming</span>, <span class="s18">DevicePerformanceTimeKernelInfoTracking</span>, <span class="s18">DevicePerformanceTimeLWSTracking</span>, <span class="s18">DevicePerformanceTimeGWSTracking</span>, <span class="s18">ChromePerformanceTiming</span>, <span class="s18">ChromePerformanceTimingInStages </span>flags when using the Intercept Layer for OpenCL<span class="s12">™ </span>Applications.</p></li></ul><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For details on how Intel<span class="s12">® </span>VTune<span class="s12">™ </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/analyze-performance/accelerators-group.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Profiler can analyze kernel execution time, see </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/analyze-performance/accelerators-group.html" target="_blank">Accelerators Analysis Group</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">When Device Kernels Are Called and Threads Are Created</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">On occasion, offload kernels are created and transferred to the device a long time before they actually start executing (usually only after all data required by the kernel has also been transferred, along with control).</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">You can set a breakpoint in a device kernel using the Intel<span class="s12">® </span>Distribution for GDB* and a compatible GPU. From there, you can query kernel arguments, monitor thread creation and destruction, list the current threads and their current positions in the code (using “info thread”), and so on.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark71">&zwnj;</a>Debug the Offload Process<a name="bookmark162">&zwnj;</a></p><p style="padding-top: 11pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Run with Different Runtimes or Compute Devices</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">When an offload program fails to run correctly or produces incorrect results, a relatively quick sanity check is to run the application on a different runtime (OpenCL<span class="s12">™ </span>vs. Level Zero) or compute device (CPU vs. GPU) using <span class="s18">LIBOMPTARGET_PLUGIN </span>and <span class="s18">OMP_TARGET_OFFLOAD </span>for OpenMP* applications, and <span class="s18">ONEAPI_DEVICE_SELECTOR </span>for SYCL* applications. Errors that reproduce across runtimes mostly eliminate the runtime as being a problem. Errors that reproduce on all available devices mostly eliminates bad hardware as the problem.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Debug CPU Execution</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Offload code has two options for CPU execution: either a “host” implementation, or the CPU version of OpenCL. A “host” implementation is a truly native implementation of the offloaded code, meaning it can be debugged like any of the non-offloaded code. The CPU version of OpenCL, while it goes through the OpenCL runtime and code generation process, eventually ends up as normal parallel code running under a TBB runtime. Again, this provides a familiar debugging environment with familiar assembly and parallelism mechanisms. Pointers have meaning through the entire stack, and data can be directly inspected. There are also no memory limits beyond the usual limits for any operating system process.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Finding and fixing errors in CPU offload execution may solve errors seen in GPU offload execution with less pain, and without requiring use of a system with an attached GPU or other accelerator.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">For OpenMP applications, to get a “host” implementation, remove the “target” or “device” constructs, replacing them with normal host OpenMP code. If <span class="s18">LIBOMPTARGET_PLUGIN=OPENCL </span>and offload to the GPU is disabled, then the offloaded code runs under the OpenMP runtime with TBB providing parallelism.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">For SYCL applications, with <span class="s18">ONEAPI_DEVICE_SELECTOR=host </span>the “host” device is actually single-threaded, which may help you determine if threading issues, such as data races and deadlocks, are the source of execution errors. Setting <span class="s18">ONEAPI_DEVICE_SELECTOR=opencl:cpu </span>uses the CPU OpenCL runtime, which also uses TBB for parallelism.</p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Debug GPU Execution Using Intel® Distribution for GDB* on Compatible GPUs</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">Intel<span class="s12">® </span>Distribution for GDB* is extensively documented in <i>Get Started with Intel</i><span class="s24">® </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-debugging-dpcpp-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Distribution for GDB on</a><span style=" color: #075FA7;">Linux* Host</span><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-debugging-dpcpp-windows/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">|</a><span style=" color: #075FA7;">Windows* Host</span>. Useful commands are briefly described in the <i>Intel</i><span class="s24">® </span><a href="https://cdrdv2.intel.com/v1/dl/getContent/671558" style=" color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Distribution for GDB</a><span style=" color: #075FA7;">Reference Sheet</span>. However, since debugging applications with GDB* on a GPU differs slightly from the process on a host (some commands are used differently and you might see some unfamiliar output), some of those differences are summarized here.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/debugging-dpcpp-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/debugging-dpcpp-linux/top.html" class="a" target="_blank">Debugging with Intel</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/debugging-dpcpp-linux/top.html" class="s16" target="_blank">® </a>Distribution for GDB on Linux OS Host Tutorial <span style=" color: #000;">shows a sample debug session where we start a debug session of a SYCL program, define a breakpoint inside the kernel, run the program to offload to the GPU, print the value of a local variable, switch to the SIMD lane 5 of the current thread, and print the variable again.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">As in normal GDB*, for a command <span class="s18">&lt;CMD&gt;</span>, use the <span class="s18">help &lt;CMD&gt; </span>command of GDB to read the information text for <span class="s18">&lt;CMD&gt;</span>. For example:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:112.1pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">(gdb) help info threads</p><p class="s19" style="text-indent: 0pt;text-align: left;">Display currently known threads.</p><p class="s19" style="text-indent: 0pt;text-align: left;">Usage: info threads [OPTION]... [ID]...</p><p class="s19" style="text-indent: 0pt;text-align: left;">If ID is given, it is a space-separated list of IDs of threads to display. Otherwise, all threads are displayed.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: center;">Options:</p><p class="s19" style="text-indent: 0pt;text-align: center;">-gid</p><p class="s19" style="text-indent: 0pt;text-align: center;">Show global thread IDs.</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Inferiors, Threads, and SIMD Lanes Referencing in GDB*</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The threads of the application can be listed using the debugger. The printed information includes the thread ids and the locations that the threads are currently stopped at. For the GPU threads, the debugger also prints the active SIMD lanes.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">In the example referenced above, you may see some unfamiliar formatting used when threads are displayed via the GDB “info threads” command:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:11.6929pt" cellspacing="0"><tr style="height:11pt"><td style="width:60pt" bgcolor="#F0F0F0"><p class="s19" style="padding-left: 9pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Id</p></td><td style="width:125pt" bgcolor="#F0F0F0"><p class="s19" style="padding-left: 24pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Target Id</p></td><td style="width:302pt" bgcolor="#F0F0F0"><p class="s19" style="padding-left: 4pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Frame</p></td></tr><tr style="height:12pt"><td style="width:60pt" bgcolor="#F0F0F0"><p class="s19" style="padding-left: 9pt;text-indent: 0pt;line-height: 10pt;text-align: left;">1.1</p></td><td style="width:125pt" bgcolor="#F0F0F0"><p class="s19" style="padding-left: 24pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Thread &lt;id omitted&gt;</p></td><td style="width:302pt" bgcolor="#F0F0F0"><p class="s19" style="padding-left: 4pt;text-indent: 0pt;line-height: 10pt;text-align: left;">&lt;frame omitted&gt;</p></td></tr><tr style="height:12pt"><td style="width:60pt" bgcolor="#F0F0F0"><p class="s19" style="padding-left: 9pt;text-indent: 0pt;line-height: 10pt;text-align: left;">1.2</p></td><td style="width:125pt" bgcolor="#F0F0F0"><p class="s19" style="padding-left: 24pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Thread &lt;id omitted&gt;</p></td><td style="width:302pt" bgcolor="#F0F0F0"><p class="s19" style="padding-left: 4pt;text-indent: 0pt;line-height: 10pt;text-align: left;">&lt;frame omitted&gt;</p></td></tr><tr style="height:12pt"><td style="width:60pt" bgcolor="#F0F0F0"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">* 2.1:1</p></td><td style="width:125pt" bgcolor="#F0F0F0"><p class="s19" style="padding-left: 24pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Thread 1073741824</p></td><td style="width:302pt" bgcolor="#F0F0F0"><p class="s19" style="padding-left: 9pt;text-indent: 0pt;line-height: 10pt;text-align: left;">&lt;frame&gt; at array-transform.cpp:61</p></td></tr><tr style="height:35pt"><td style="width:487pt" colspan="3" bgcolor="#F0F0F0"><ol id="l92"><ol id="l93"><li data-list-text="2.1"><p class="s19" style="padding-left: 24pt;text-indent: -14pt;text-align: left;">:[3 5 7]  Thread 1073741824  &lt;frame&gt; at array-transform.cpp:61</p></li><li data-list-text="2.2"><p class="s19" style="padding-left: 24pt;text-indent: -14pt;text-align: left;">:[1 3 5 7] Thread 1073741888  &lt;frame&gt; at array-transform.cpp:61</p></li><li data-list-text="2.3"><p class="s19" style="padding-left: 24pt;text-indent: -14pt;line-height: 11pt;text-align: left;">:[1 3 5 7] Thread 1073742080  &lt;frame&gt; at array-transform.cpp:61</p></li></ol></ol></td></tr></table><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Here, GDB is displaying the threads with the following format:</p><p class="s18" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">&lt;inferior_number&gt;.&lt;thread_number&gt;:&lt;SIMD Lane/s&gt;</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">So, for example, the thread id “<span class="s18">2.3:[1 3 5 7]</span>” refers to SIMD lanes 1, 3, 5, and 7 of thread 3 running on</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">inferior 2.</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">An “inferior” in the GDB terminology is the process that is being debugged. In the debug session of a program that offloads to the GPU, there will typically be two inferiors; one “native” inferior representing a host part of the program (inferior 1 above), and another “remote” inferior representing the GPU device (inferior 2 above). Intel<span class="s12">® </span>Distribution for GDB automatically creates the GPU inferior - no extra steps are required.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">When you print the value of an expression, the expression is evaluated in the context of the current thread’s current SIMD lane. You can switch the thread as well as the SIMD lane to change the context using the “thread” command such as “<span class="s18">thread 3:4 </span>“, “<span class="s18">thread :6 </span>“, or “<span class="s18">thread 7 </span>“. The first command makes a</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">switch to the thread 3 and SIMD lane 4. The second command switches to SIMD lane 6 within the current thread. The third command switches to thread 7. The default lane selected will either be the previously selected lane, if it is active, or the first active lane within the thread.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/debugging-dpcpp-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">The “thread apply command” may be similarly broad or focused (which can make it easier to limit the output from, for example, a command to inspect a variable). For more details and examples about debugging with SIMD lanes, see the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/debugging-dpcpp-linux/top.html" class="a" target="_blank">Debugging with Intel</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/debugging-dpcpp-linux/top.html" class="s16" target="_blank">® </a>Distribution for GDB on Linux OS Host Tutorial<span style=" color: #000;">.</span></p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;"><a href="https://sourceware.org/gdb/current/onlinedocs/gdb/Threads.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">More information about threads and inferiors in GDB can be found from </a><a href="https://sourceware.org/gdb/current/onlinedocs/gdb/Threads.html" class="a" target="_blank">https://sourceware.org/gdb/current/ </a>onlinedocs/gdb/Threads.html <a href="https://sourceware.org/gdb/current/onlinedocs/gdb/Inferiors-Connections-and-Programs.html#Inferiors-Connections-and-Programs" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">and </a><a href="https://sourceware.org/gdb/current/onlinedocs/gdb/Inferiors-Connections-and-Programs.html#Inferiors-Connections-and-Programs" class="a" target="_blank">https://sourceware.org/gdb/current/onlinedocs/gdb/Inferiors-Connections- </a>and-Programs.html#Inferiors-Connections-and-Programs<span style=" color: #000;">.</span></p><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Controlling the Scheduler</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">By default, when a thread hits a breakpoint, the debugger stops all the threads before displaying the breakpoint hit event to the user. This is the all-stop mode of GDB. In the non-stop mode, the stop event of a thread is displayed while the other threads run freely.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">In all-stop mode, when a thread is resumed (for example, to resume normally with the <span class="s18">continue </span>command, or for stepping with the <span class="s18">next </span>command), all the other threads are also resumed. If you have some breakpoints set in threaded applications, this can quickly get confusing, as the next thread that hits the breakpoint may not be the thread you are following.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">You can control this behavior using the <span class="s18">set scheduler-locking </span>command to prevent resuming other threads when the current thread is resumed. This is useful to avoid intervention of other threads while only the current thread executes instructions. Type <span class="s18">help set scheduler-locking </span><a href="https://sourceware.org/gdb/current/onlinedocs/gdb/Thread-Stops.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">for the available options, and see </a><span style=" color: #075FA7;">https://sourceware.org/gdb/current/onlinedocs/gdb/Thread-Stops.html </span>for more information. Note that SIMD lanes cannot be resumed individually; they are resumed together with their underlying thread.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">In non-stop mode, by default, only the current thread is resumed. To resume all threads, pass the “<span class="s18">-a</span>” flag to the <span class="s18">continue </span>command.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Dumping Information on One or More Threads/Lanes (Thread Apply)</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Commands for inspecting the program state are typically executed in the context of the current thread’s current SIMD lane. Sometimes it is desired to inspect a value in multiple contexts. For such needs, the <span class="s18">thread apply </span>command can be used. For instance, the following executes the <span class="s18">print element </span>command for the SIMD lanes 3-5 of Thread 2.5:</p><p style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">(gdb)    thread    apply    2.5:3-5    print    element                </span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Similarly, the following runs the same command in the context of SIMD lane 3, 5, and 6 of the current thread:</p><p style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">(gdb)   thread   apply   :3   :5   :6   print   element               </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Stepping GPU Code After a Breakpoint</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">To stop inside the kernel that is offloaded to the GPU, simply define a breakpoint at a source line inside the kernel. When a GPU thread hits that source line, the debugger stops the execution and shows the breakpoint hit. To single-step a thread over a source-line, use the <span class="s18">step </span>or <span class="s18">next </span>commands. The <span class="s18">step </span>commands steps into functions while <span class="s18">next </span>steps over calls. Before stepping, we recommend to <span class="s18">set scheduler-locking step </span>to prevent intervention of other threads.</p><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Building a SYCL Executable for Use with Intel<span class="s12">® </span>Distribution for GDB*</p><p class="s13" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-debugging-dpcpp-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Much like when you want to debug a host application, you need to set some additional flags to create a binary that can be debugged on the GPU. See </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-debugging-dpcpp-linux/top.html" class="a" target="_blank">Get Started with Intel</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-debugging-dpcpp-linux/top.html" class="s16" target="_blank">® </a>Distribution for GDB on Linux* Host <span style=" color: #000;">for details.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: justify;">For a smooth debug experience when using the just-in-time (JIT) compilation flow, enable debug information emission from the compiler via the <span class="s18">-g </span>flag, and disable optimizations via the <span class="s18">-O0 </span>flag for both a host and JIT- compiled kernel of the application. The flags for the kernel are taken during link time. For example:</p><ul id="l94"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Compile your program using: <span class="s18">icpx -fsycl -g -O0 -c myprogram.cpp</span></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Link your program using: <span class="s18">icpx -fsycl -g -O0 myprogram.o</span></p></li></ul><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;">If you are using CMake to configure the build of your program, use the <span class="s18">Debug </span>type for the <span class="s18">CMAKE_BUILD_TYPE</span>, and append <span class="s18">-O0 </span>to the <span class="s18">CMAKE_CXX_FLAGS_DEBUG </span>variable. For example: <span class="s18">set (CMAKE_CXX_FLAGS_DEBUG &quot;${CMAKE_CXX_FLAGS_DEBUG} -O0&quot;)</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Applications that are built for debugging may take a little longer to start up than when built with the usual “release” level of optimization. Thus, your program may appear to run a little more slowly when started in the debugger. If this causes problems, developers of larger applications may want to use ahead-of-time (AOT) compilation to JIT the offload code when their program is built, rather than when it is run (warning, this may also take longer to build when using <span class="s18">-g -O0</span><a href="#bookmark114" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">). For more information, see </a><a href="#bookmark114" class="a">Compilation Flow </a><span style=" color: #075FA7;">Overview</span>.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">When doing ahead-of-time compilation for GPU, you must use a device type that fits your target device. Run the following command to see the available GPU device options on your current machine: <span class="s18">ocloc compile</span></p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">--help</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Additionally, the debug mode for the kernel must be enabled. The following example AoT compilation command targets the KBL device:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">dpcpp -g -O0 -fsycl-targets=spir64_gen-unknown-unknown-sycldevice \</p><p class="s19" style="text-indent: 0pt;text-align: left;">-Xs &quot;-device kbl -internal_options -cl-kernel-debug-enable -options -cl-opt-disable&quot; myprogram.cpp</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 9pt;padding-bottom: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 160%;text-align: left;">Building an OpenMP* Executable for use with Intel<span class="s12">® </span>Distribution for GDB* Compile and link your program using the <span class="s18">-g -O0 </span>flags. For example:</p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">icpx -fiopenmp -O0 -fopenmp-targets=spir64 -c -g myprogram.cpp icpx -fiopenmp -O0 -fopenmp-targets=spir64 -g myprogram.o</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Set the following environment variables to disable optimizations and enable debug info for the kernel:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:22.4pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">export LIBOMPTARGET_OPENCL_COMPILATION_OPTIONS=&quot;-g -cl-opt-disable&quot; export LIBOMPTARGET_LEVEL0_COMPILATION_OPTIONS=&quot;-g -cl-opt-disable&quot;</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s17" style="padding-top: 12pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Debugging GPU Execution</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">A common issue with offload programs is that they may to fail to run at all, instead giving a generic OpenCL<span class="s12">™ </span>error with little additional information. The Intercept Layer for OpenCL<span class="s12">™ </span>Applications along with onetrace, ze_tracer, and cl_tracer can be used to get more information about these errors, often helping the developer identify the source of the problem.</p><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Intercept Layer for OpenCL<span class="s12">™ </span>Applications</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Using this library, in particular the <span class="s18">Buildlogging</span>, <span class="s18">ErrorLogging</span>, and <span class="s18">USMChecking=1 </span>options, you can often find the source of the error.</p><ol id="l95"><li data-list-text="1."><p style="padding-top: 5pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">Create a <span class="s18">clintercept.conf </span>file in the home directory with the following content:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:78.5pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">SimpleDumpProgramSource=1 CallLogging=1</p><p class="s19" style="text-indent: 0pt;text-align: left;">LogToFile=1</p><p class="s19" style="text-indent: 0pt;text-align: left;">//KernelNameHashTracking=1 BuildLogging=1 ErrorLogging=1 USMChecking=1</p></div></li></ol><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 11pt;text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:67.3pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">//ContextCallbackLogging=1</p><p class="s19" style="text-indent: 0pt;text-align: left;">// Profiling knobs KernelInfoLogging=1 DevicePerformanceTiming=1 DevicePerformanceTimeLWSTracking=1 DevicePerformanceTimeGWSTracking=1</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><ol id="l96"><li data-list-text="2."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Run the application with cliloader as follows:</p><p style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">&lt;OCL_Intercept_Install_Dir&gt;/bin/cliloader/cliloader  -d  ./&lt;app_name&gt;  &lt;app_args&gt;      </span></p></li><li data-list-text="3."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Review the following results in the ~CLIntercept_Dump/&lt;app_name&gt; directory:</p><ul id="l97"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 44pt;text-indent: -14pt;text-align: left;">clintercept_report.txt: Profiling results</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 44pt;text-indent: -14pt;text-align: left;">clintercept_log.txt: Log of OpenCL<span class="s12">™ </span>calls used to debug OpenCL issues</p></li></ul></li></ol><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following snippet is from an example log file generated by a program that returned the runtime error:</p><p class="s18" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">CL_INVALID_ARG_VALUE (-50)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:156.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">...</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; clSetKernelArgMemPointerINTEL -&gt; CL_SUCCESS</p><p class="s19" style="text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt;</p><p class="s19" style="text-indent: 0pt;text-align: left;">clGetKernelInfo( _ZTSZZ10outer_coreiP5mesh_i16dpct_type_1c0e3516dpct_type_60257cS2_S2_S2_S2_S2_S2</p><p class="s19" style="text-indent: 0pt;text-align: left;">_S2_S2_fS2_S2_S2_S2_iENKUlRN2cl4sycl7handlerEE197-&gt;45clES6_EUlNS4_7nd_itemILi3EEEE225-&gt;13 ): param_name = CL_KERNEL_CONTEXT (1193)</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; clGetKernelInfo -&gt; CL_SUCCESS</p><p class="s19" style="text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt;</p><p class="s19" style="text-indent: 0pt;text-align: left;">clSetKernelArgMemPointerINTEL( _ZTSZZ10outer_coreiP5mesh_i16dpct_type_1c0e3516dpct_type_60257cS2_ S2_S2_S2_S2_S2_S2_S2_fS2_S2_S2_S2_iENKUlRN2cl4sycl7handlerEE197-</p><p class="s19" style="text-indent: 0pt;text-align: left;">&gt;45clES6_EUlNS4_7nd_itemILi3EEEE225-&gt;13 ): kernel = 0xa2d51a0, index = 3, value = 0x41995e0 mem pointer 0x41995e0 is an UNKNOWN pointer and no device support shared system pointers! ERROR! clSetKernelArgMemPointerINTEL returned CL_INVALID_ARG_VALUE (-50)</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; clSetKernelArgMemPointerINTEL -&gt; CL_INVALID_ARG_VALUE</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">In this example, the following values help with debugging the error:</p><ul id="l98"><li data-list-text="•"><p class="s18" style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">ZTSZZ10outer_coreiP5mesh</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">index = 3, value = 0x41995e0</p></li></ul><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Using this data, you can identify which kernel had the problems, what argument was problematic, and why.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">onetrace, ze_tracer, and cl_tracer</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;">Similar to Intercept Layer for OpenCL<span class="s12">™ </span>Applications, the onetrace, ze_tracer and cl_tracer tools can help find the source of errors detected by the Level Zero and OpenCL<span class="s12">™ </span>runtimes.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">To use the onetrace or ze_tracer tools to root-cause Level Zero issues (cl_tracer would be used the same way to root-cause OpenCL issues):</p><p class="s14" style="padding-top: 5pt;padding-left: 30pt;text-indent: -25pt;line-height: 110%;text-align: left;">1.  <span class="p">Use Call Logging mode to run the application. Redirecting the tool output to a file is optional, but recommended.</span></p><p style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s21" style=" background-color: #F0F0F0;">./onetrace   -c   ./&lt;app_name&gt;   &lt;app_args&gt;   [2&gt;   log.txt]             </span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The command for ze_tracer is the same - just substitute “ze_tracer” for “onetrace”.</p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">1.  <span class="p">Review the call trace to figure out the error (log.txt). For example:</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:78.5pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [102032049] zeKernelCreate: hModule = 0x55a68c762690 desc = 0x7fff865b5570 {29 0 0 GEMM} phKernel = 0x7fff865b5438 (hKernel = 0)</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [102060428] zeKernelCreate [28379 ns] hKernel = 0x55a68c790280 -&gt; ZE_RESULT_SUCCESS (0)</p><p class="s19" style="text-indent: 0pt;text-align: left;">...</p><p class="s19" style="text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [102249951] zeKernelSetGroupSize: hKernel = 0x55a68c790280 groupSizeX = 256 groupSizeY = 1 groupSizeZ = 1</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [102264632] zeKernelSetGroupSize [14681 ns] -&gt; ZE_RESULT_SUCCESS (0)</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:156.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [102278558] zeKernelSetArgumentValue: hKernel = 0x55a68c790280 argIndex = 0 argSize = 8 pArgValue = 0x7fff865b5440</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [102294960] zeKernelSetArgumentValue [16402 ns] -&gt; ZE_RESULT_SUCCESS (0)</p><p class="s19" style="text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [102308273] zeKernelSetArgumentValue: hKernel = 0x55a68c790280 argIndex = 1 argSize = 8 pArgValue = 0x7fff865b5458</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [102321981] zeKernelSetArgumentValue [13708 ns] -&gt; ZE_RESULT_ERROR_INVALID_ARGUMENT (2013265924)</p><p class="s19" style="text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [104428764] zeKernelSetArgumentValue: hKernel = 0x55af5f3ca600 argIndex = 2 argSize = 8 pArgValue = 0x7ffe289c7e60</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [104442529] zeKernelSetArgumentValue [13765 ns] -&gt; ZE_RESULT_SUCCESS (0)</p><p class="s19" style="text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [104455176] zeKernelSetArgumentValue: hKernel = 0x55af5f3ca600 argIndex = 3 argSize = 4 pArgValue = 0x7ffe289c7e2c</p><p class="s19" style="text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [104468472] zeKernelSetArgumentValue [13296 ns] -&gt; ZE_RESULT_SUCCESS (0)</p><p class="s19" style="text-indent: 0pt;text-align: left;">...</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">The example log data shows:</p><ul id="l99"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 44pt;text-indent: -14pt;text-align: left;">A level zero API call that causes the problem (<span class="s18">zeKernelSetArgumentValue</span>)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 44pt;text-indent: -14pt;text-align: left;">The problem reason (<span class="s18">ZE_RESULT_ERROR_INVALID_ARGUMENT</span>)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 44pt;text-indent: -14pt;text-align: left;">The argument index (<span class="s18">argIndex = 1</span>)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 44pt;text-indent: -14pt;text-align: left;">An invalid value location (<span class="s18">pArgValue = 0x7fff865b5458</span>)</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 44pt;text-indent: -14pt;line-height: 108%;text-align: left;">A kernel handle (<span class="s18">hKernel = 0x55a68c790280</span>), which provides the name of the kernel for which this issue is observed (GEMM)</p></li></ul><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">More information could be obtained by omitting the “redirection to file” option and dumping all the output (application output + tool output) into one stream. Dumping to one stream may help determine the source of the error in respect to application output (for example, you can find that the error happens between application initialization and the first phase of computations):</p><p style="text-indent: 0pt;text-align: left;"><span/></p><p class="s18" style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Level Zero Matrix Multiplication (matrix size: 1024 x 1024, repeats 4 times) Target device: Intel<span class="s44">® </span>Graphics [0x3ea5]</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">...</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [104131109] zeKernelCreate: hModule = 0x55af5f39ca10 desc = 0x7ffe289c7f80 {29 0 0 GEMM} phKernel = 0x7ffe289c7e48 (hKernel = 0)</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [104158819] zeKernelCreate [27710 ns] hKernel = 0x55af5f3ca600 -&gt; ZE_RESULT_SUCCESS (0)</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">...</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [104345820] zeKernelSetGroupSize: hKernel = 0x55af5f3ca600 groupSizeX = 256 groupSizeY = 1 groupSizeZ = 1</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [104360082] zeKernelSetGroupSize [14262 ns] -&gt; ZE_RESULT_SUCCESS (0)</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [104373679] zeKernelSetArgumentValue: hKernel = 0x55af5f3ca600 argIndex = 0 argSize = 8 pArgValue = 0x7ffe289c7e50</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [104389443] zeKernelSetArgumentValue [15764 ns] -&gt; ZE_RESULT_SUCCESS (0)</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [104402448] zeKernelSetArgumentValue: hKernel = 0x55af5f3ca600 argIndex = 1 argSize = 8 pArgValue = 0x7ffe289c7e68</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [104415871] zeKernelSetArgumentValue [13423 ns] -&gt; ZE_RESULT_ERROR_INVALID_ARGUMENT (2013265924)</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [104428764] zeKernelSetArgumentValue: hKernel = 0x55af5f3ca600 argIndex = 2 argSize = 8 pArgValue = 0x7ffe289c7e60</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [104442529] zeKernelSetArgumentValue [13765 ns] -&gt; ZE_RESULT_SUCCESS (0)</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&gt;&gt;&gt;&gt; [104455176] zeKernelSetArgumentValue: hKernel = 0x55af5f3ca600 argIndex = 3 argSize = 4 pArgValue = 0x7ffe289c7e2c</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">&lt;&lt;&lt;&lt; [104468472] zeKernelSetArgumentValue [13296 ns] -&gt; ZE_RESULT_SUCCESS (0)</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">...</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">Matrix multiplication time: 0.0427564 sec Results are INCORRECT with accuracy: 1</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">...</p><p class="s18" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">Matrix multiplication time: 0.0430995 sec</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">Results are INCORRECT with accuracy: 1</p><p class="s19" style="text-indent: 0pt;text-align: left;">...</p><p class="s19" style="text-indent: 0pt;text-align: left;">Total execution time: 0.381558 sec</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s17" style="padding-top: 12pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Correctness</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Offload code is often used for kernels that can efficiently process large amounts of information on the attached compute device, or to generate large amounts of information from some input parameters. If these kernels are running without crashing, this can often mean that you learn that they are not producing the correct results much later in program execution.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">In these cases, it can be difficult to identify which kernel is producing incorrect results. One technique for finding the kernel producing incorrect data is to run the program twice, once using a purely host-based implementation, and once using an offload implementation, capturing the inputs and outputs from every kernel (often to individual files). Now compare the results and see which kernel call is producing unexpected results (within a certain epsilon - the offload hardware may have a different order of operation or native precision that causes the results to differ from the host code in the last digit or two).</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/debugging-dpcpp-linux/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Once you know which kernel is producing incorrect results, and you are working with a compatible GPU, use Intel Distribution for GDB to determine the reason. See the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/debugging-dpcpp-linux/top.html" class="a" target="_blank">Debugging with Intel</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/debugging-dpcpp-linux/top.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/debugging-dpcpp-linux/top.html" class="a" target="_blank">Distribution for GDB on </a>Linux OS Host Tutorial <span style=" color: #000;">for basic information and links to more detailed documentation.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">Both SYCL and OpenMP* also allow for the use of standard language print mechanisms (<span class="s18">printf </span>for SYCL and C++ OpenMP offload, <span class="s18">print *, ... </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-gpu-optimization-guide/top/tools/io-kernel.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">for Fortran OpenMP offload) within offloaded kernels, which you can use to verify correct operation while they run. Print the thread and SIMD lane the output is coming from and consider adding synchronization mechanisms to ensure printed information is in a consistent state when printed. Examples for how to do this in SYCL using the stream class can be found in the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-gpu-optimization-guide/top/tools/io-kernel.html" class="a" target="_blank">Intel oneAPI GPU </a><span style=" color: #075FA7;">Optimization Guide</span>. You could use a similar approach to the one described for SYCL for OpenMP offload.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">For more information about using OpenMP directives to add parallelism to your application, see <a href="http://www.intel.com/content/www/us/en/" class="s45" target="_blank">Offload and Optimize OpenMP* Applications with Intel Tools </a><b>&lt;https://www.intel.com/content/www/us/en/ developer/tools/oneapi/training/offload-optimize-openmp-applications.html&gt;`_</b></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 1pt;padding-left: 35pt;text-indent: 0pt;text-align: left;"><b>Tip </b>Using <span class="s18">printf </span>can be verbose in SYCL kernels. To simplify, add the following macro:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:89.7pt;width:456.7pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">#ifdef <span class="s46">&nbsp;&nbsp;&nbsp; </span>SYCL_DEVICE_ONLY<span class="s46"> &nbsp;&nbsp;&nbsp;</span></p><p class="s19" style="text-indent: 9pt;text-align: left;">#define CL_CONSTANT <span class="s46">&nbsp;</span>attribute<span class="s46"> </span>((opencl_constant)) #else</p><p class="s19" style="text-indent: 9pt;text-align: left;">#define CL_CONSTANT #endif</p><p class="s19" style="text-indent: 0pt;text-align: left;">#define PRINTF(format, ...) { \</p><p class="s19" style="padding-left: 59pt;text-indent: 0pt;text-align: left;">static const CL_CONSTANT char _format[] = format; \ sycl::ONEAPI::experimental::printf(_format, ## <span class="s46">&nbsp; </span>VA_ARGS<span class="s46">&nbsp; </span>); }</p></div><p style="padding-left: 41pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-bottom: 3pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">Usage example: <span class="s18">PRINTF(&quot;My integer variable:%d\n&quot;, (int) x);</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Failures</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Just-in-time (JIT) compilation failures that occur at runtime due to incorrect use of the SYCL or OpenMP* offload languages will cause your program to exit with an error.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">In the case of SYCL, if you cannot find these using ahead-of-time compilation of your SYCL code, selecting the OpenCL backend, setting SimpleDumpProgramSource and BuildLogging, and using the Intercept Layer for OpenCL<span class="s12">™ </span>Applications may help identify the kernel with the syntax error.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Logic errors can also result in crashes or error messages during execution. Such issues can include:</p><ul id="l100"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Passing a buffer that belongs to the wrong context to a kernel</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Passing the “this” pointer to a kernel rather than a class element</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Passing a host buffer rather than a device buffer</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Passing an uninitialized pointer, even if it is not used in the kernel</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Using the Intel<span class="s12">® </span>Distribution for GDB* (or even the native GDB), if you watch carefully, you can record the addresses of all contexts created and verify that the address being passed to an offload kernel belongs to the correct context. Likewise, you can verify that the address of a variable passed matches that of the variable itself, and not its containing class.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">It may be easier to track buffers and addresses using the Intercept Layer for OpenCL<span class="s12">™ </span>allocation or onetrace/ cl_tracer and choosing the appropriate backend. When using the OpenCL backend, setting <span class="s18">CallLogging</span>, <span class="s18">BuildLogging</span>, <span class="s18">ErrorLogging</span>, and <span class="s18">USMChecking </span>and running your program should produce output that explains what error in your code caused the generic OpenCL error to be produced.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Using onetrace or ze_tracer’s Call Logging or Device Timeline should give additional enhanced error information to help you better understand the source of generic errors from the Level Zero backend. This can help locate many of the logic errors mentioned above.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">If the code is giving an error when offloading to a device using the Level Zero backend, try using the OpenCL backend. If the program works, report an error against the Level Zero backend. If the error reproduces in the OpenCL backend to the device, try using the OpenCL CPU backend. In OpenMP offload, this can be specified by setting <span class="s18">OMP_TARGET_OFFLOAD </span>to <span class="s18">CPU</span>. For SYCL, this can be done by setting <span class="s18">ONEAPI_DEVICE_SELECTOR=opencl:cpu</span>. Debugging with everything on the CPU can be easier, and removes complications caused by data copies and translation of the program to a non-CPU device.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">As an example of a logic issue that can get you in trouble, consider what is captured by the lambda function used to implement the <span class="s18">parallel_for </span>in this SYCL code snippet.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:257.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">class MyClass { private:</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">int *data; int factor;</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">:</p><p class="s19" style="text-indent: 0pt;text-align: left;">void run() {</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">:</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">auto data2 = data; auto factor2 = factor;</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">{</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">dpct::get_default_queue_wait().submit([&amp;](cl::sycl::handler &amp;cgh)</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">{</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">auto dpct_global_range = grid * block; auto dpct_local_range = block;</p><p class="s19" style="padding-left: 54pt;text-indent: -19pt;text-align: left;">cgh.parallel_for&lt;dpct_kernel_name&lt;class kernel_855a44&gt;&gt;( cl::sycl::nd_range&lt;1&gt;(</p><p class="s19" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">cl::sycl::range&lt;1&gt; dpct_global_range.get(0)), cl::sycl::range&lt;1&gt;( dpct_local_range.get(0))), [=](cl::sycl::nd_item&lt;3&gt; item_ct1)</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">{</p><p class="s19" style="padding-left: 54pt;text-indent: 0pt;text-align: left;">kernel(data, b, factor, LEN, item_ct1); // This blows up</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">});</p><p class="s19" style="padding-left: 24pt;text-indent: 0pt;text-align: left;">});</p></div></li></ul><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:33.6pt;width:486.6pt;"><p class="s19" style="padding-left: 14pt;text-indent: 0pt;line-height: 10pt;text-align: left;">}</p><p class="s19" style="text-indent: 0pt;text-align: left;">} // run</p><p class="s19" style="text-indent: 0pt;text-align: left;">} // MyClass</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">In the above code snippet, the program crashes because <span class="s18">[=] </span>will copy by value all variables used inside the lambda. In the example it may not be obvious that “<span class="s18">factor</span>” is really “<span class="s18">this-&gt;factor</span>” and “<span class="s18">data</span>” is really “<span class="s18">this-&gt;data,</span>” so “<span class="s18">this</span>” is the variable that is captured for the use of “<span class="s18">data</span>” and “<span class="s18">factor</span>” above. OpenCL or Level Zero will crash with an illegal arguments error in the “<span class="s18">kernel(data, b, factor, LEN, item_ct1)</span>” call.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The fix is the use of local variables <span class="s18">auto data2 </span>and <span class="s18">auto factor2</span>. “<span class="s18">auto factor2 = factor</span>” becomes “<span class="s18">int factor2 = this-&gt;factor</span>” so using <span class="s18">factor2 </span>inside the lambda with <span class="s18">[=] </span>would capture an “<span class="s18">int</span>”. We would rewrite the inner section as “<span class="s18">kernel(data2, b, factor2, LEN, item_ct1);</span>” .</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 110%;text-align: left;">NOTE <span class="p">This issue is commonly seen when migrating CUDA* kernels. You can also resolve the issue by keeping the same CUDA kernel launch signature and placing the command group and lambda inside the kernel itself.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">Using the Intercept Layer for OpenCL<span class="s12">™ </span>allocation or onetrace or ze_tracer, you would see that the kernel was called with two identical addresses, and the extended error information would tell you that you are trying to copy a non-trivial data structure to the offload device.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">Note that if you are using unified shared memory (USM), and “<span class="s18">MyClass</span>” is allocated in USM, the above code will work. However, if only “<span class="s18">data</span>” is allocated in USM, then the program will crash for the above reason.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">In this example, note that you can also re-declare the variables in local scope with the same name so that you don’t need to change everything in the kernel call.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">Intel<span class="s12">® </span>Inspector can also help diagnose these sorts of failures. If you set the following environment variables and then run Memory Error Analysis on offload code using the CPU device, Intel Inspector will flag many of the above issues:</p><ul id="l101"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">OpenMP*</p><ul id="l102"><li data-list-text="•"><p class="s18" style="padding-top: 6pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">export OMP_TARGET_OFFLOAD=CPU</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">export OMP_TARGET_OFFLOAD=MANDATORY</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">export LIBOMPTARGET_PLUGIN=OPENCL</p></li></ul></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">SYCL</p><ul id="l103"><li data-list-text="•"><p class="s18" style="padding-top: 6pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">export ONEAPI_DEVICE_SELECTOR=opencl:cpu</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 34pt;text-indent: -14pt;line-height: 118%;text-align: left;">Or initialize your queue with a CPU selector to force use of the OpenCL CPU device: <span class="s18">cl::sycl::queue Queue(cl::sycl::cpu_selector{});</span></p></li></ul></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 10pt;text-align: left;">Both</p><ul id="l104"><li data-list-text="•"><p class="s18" style="padding-top: 6pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">export CL_CONFIG_USE_VTUNE=True</p></li><li data-list-text="•"><p class="s18" style="padding-top: 1pt;padding-left: 34pt;text-indent: -14pt;text-align: left;">export CL_CONFIG_USE_VECTORIZER=false</p></li></ul></li></ul><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;line-height: 109%;text-align: left;"><b>NOTE </b>A crash can occur when optimizations are turned on during the compilation process. If turning off optimizations causes your crash to disappear, use <span class="s18">-g -[optimization level] </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compiler-reference/compiler-options/compiler-option-details/output-debug-and-precompiled-header-pch-options/g.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">for debugging. For more information, see the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compiler-reference/compiler-options/compiler-option-details/output-debug-and-precompiled-header-pch-options/g.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-dpcpp-cpp-compiler-dev-guide-and-reference/top/compiler-reference/compiler-options/compiler-option-details/output-debug-and-precompiled-header-pch-options/g.html" class="s16" target="_blank">® </a><span style=" color: #075FA7;">oneAPI DPC++/C++ Compiler Developer Guide and Reference</span>.</p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark72">&zwnj;</a>Using the SYCL* Exception Handler</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://link.springer.com/book/10.1007%2F978-1-4842-5574-2" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">As explained in the book </a><a href="https://link.springer.com/book/10.1007%2F978-1-4842-5574-2" class="a" target="_blank">Data Parallel C++ Mastering DPC++ for Programming of Heterogeneous Systems </a>using C++ and SYCL<span style=" color: #000;">:</span></p><p style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The C++ exception features are designed to cleanly separate the point in a program where an error is detected from the point where it may be handled, and this concept fits very well with both synchronous and asynchronous errors in SYCL.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Using the methods from this book, C++ exception handling can help terminate a program when an error is encountered instead of allowing the program to silently fail.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><b>Note</b>: the <i>italicized </i>text in this section is copied directly from Chapter 5 “Error Handling” in the book <i>Data Parallel C++ Mastering DPC++ for Programming of Heterogeneous Systems using C++ and SYCL. </i>In some places, text has been removed for brevity. See the book for full details.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Ignoring Error Handling</p><p class="s20" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">C++ and SYCL are designed to tell us that something went wrong even when we don’t handle errors explicitly. The default result of unhandled synchronous or asynchronous errors is abnormal program termination which an operating system should tell us about. The following two examples mimic the behavior that will occur if we do not handle a synchronous and an asynchronous error, respectively.The figure below shows the result of an unhandled C++ exception, which could be an unhandled SYCL synchronous error, for example. We can use this code to test what a particular operating system will report in such a case.</p><p class="s20" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Unhandled exception in C++</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:112.1pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">#include &lt;iostream&gt;</p><p class="s19" style="text-indent: 0pt;text-align: left;">class something_went_wrong {}; int main() {</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Hello\n&quot;; throw(something_went_wrong{});</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p><p class="s19" style="text-indent: 0pt;text-align: left;">Example output in Linux:</p><p class="s19" style="text-indent: 0pt;text-align: left;">Hello</p><p class="s19" style="text-indent: 0pt;text-align: left;">terminate called after throwing an instance of &#39;something_went_wrong&#39; Aborted (core dumped)</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s20" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The next figure shows example output from std::terminate being called, which will be the result of an unhandled SYCL asynchronous error in our application. We can use this code to test what a particular operating system will report in such a case.Although we probably should handle errors in our programs, since uncaught errors will be caught and the program terminated, we do not need to worry about a program silently failing!</p><p class="s18" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">std::terminate<span class="s20">is called when a SYCL asynchronous exception isn’t handled</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:100.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#include &lt;iostream&gt; int main() {</p><p class="s19" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Hello\n&quot;; std::terminate();</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p><p class="s19" style="text-indent: 0pt;text-align: left;">Example output in Linux:</p><p class="s19" style="text-indent: 0pt;text-align: left;">Hello</p><p class="s19" style="text-indent: 0pt;text-align: left;">terminate called without an active exception Aborted (core dumped)</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The book details reasons for why synchronous errors can be handled by the C++ exceptions. However, to handle asynchronous errors at controlled points in an application, one must be aware of the situations where a SYCL throw is invoked, and accordingly, SYCL exceptions must be used.</p><p class="s20" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Synchronous errors defined by SYCL are a derived class from std::exception of type ``sycl::exception``, which allows us to catch the SYCL errors specifically though a try-catch structure such as what we see in the figure below.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Pattern to catch<span class="s18">sycl::exception</span>specifically</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:78.5pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">try{</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">// Do some SYCL work</p><p class="s19" style="text-indent: 0pt;text-align: left;">} catch (sycl::exception &amp;e) {</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">// Do something to output or handle the exception</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Caught sync SYCL exception: &quot; &lt;&lt; e.what() &lt;&lt; &quot;\n&quot;; return 1;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s20" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">On top of the C++ error handling mechanisms, SYCL adds a * ``sycl::exception`` *type for the exceptions thrown by the runtime. Everything else is standard C++ exception handling, so will be familiar to most developers. A slightly more complete example is provided in the figure below, where additional classes of exception are handled, as well as the program being ended by returning from main(). On top of the C++ error handling mechanisms, SYCL adds a * ``sycl::exception`` *type for the exceptions thrown by the runtime. Everything else is standard C++ exception handling, so will be familiar to most developers. A slightly more complete example is provided in the figure below, where additional classes of exception are handled, as well as the program being ended by returning from main().</p><p class="s20" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Pattern to catch exceptions from a block of code</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:224.2pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">try{</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">buffer&lt;int&gt; B{ range{16} };</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">// ERROR: Create sub-buffer larger than size of parent buffer</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">// An exception is thrown from within the buffer constructor buffer&lt;int&gt; B2(B, id{8}, range{16});</p><p class="s19" style="text-indent: 0pt;text-align: left;">} catch (sycl::exception &amp;e) {</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">// Do something to output or handle the exception</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Caught sync SYCL exception: &quot; &lt;&lt; e.what() &lt;&lt; &quot;\n&quot;; return 1;</p><p class="s19" style="text-indent: 0pt;text-align: left;">} catch (std::exception &amp;e) {</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Caught std exception: &quot; &lt;&lt; e.what() &lt;&lt; &quot;\n&quot;; return 2;</p><p class="s19" style="text-indent: 0pt;text-align: left;">} catch (...) {</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;Caught unknown exception\n&quot;; return 3;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p><p class="s19" style="text-indent: 0pt;text-align: left;">return 0; Example output:</p><p class="s19" style="text-indent: 0pt;text-align: left;">Caught sync SYCL exception: Requested sub-buffer size exceeds the size of the parent buffer -30 (CL_INVALID_VALUE)</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Asynchronous Error Handling</p><p class="s20" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Asynchronous errors are detected by the SYCL runtime (or an underlying backend), and the errors occur independently of execution of commands in the host program. The errors are stored in lists internal to the SYCL runtime and only released for processing at specific points that the programmer can control. There are two topics that we need to discuss to cover handling of asynchronous errors <span class="p">1. </span><b>The asynchronous handler</b>that is invoked when there are outstanding asynchronous errors to process <span class="p">2. </span><b>When</b>the asynchronous handler is invoked The Asynchronous HandleThe asynchronous handler is a function that the application defines, which is registered with SYCL contexts and/or queues. At the times defined by the next section, if there are any unprocessed asynchronous exceptions that are available to be handled, then the asynchronous handler is invoked by the SYCL runtime and passed a list of these exceptions. The asynchronous handler is passed to a context or queue constructor as a<span class="s18">std::function</span>and can be defined in ways such as a regular function, lambda, or functor, depending on our preference. The handler must accept a<span class="s18">sycl::exception_list</span>argument, such as in the example handler shown in the figure below</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Example asynchronous handler implementation defined as a lambda</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:112.1pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">// Our simple asynchronous handler function</p><p class="s19" style="padding-left: 9pt;text-indent: -10pt;text-align: left;">auto handle_async_error = [](exception_list elist) { for (auto &amp;e : elist) {</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">try{ std::rethrow_exception(e); } catch ( sycl::exception&amp; e ) {</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;ASYNC EXCEPTION!!\n&quot;;</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; e.what() &lt;&lt; &quot;\n&quot;;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="text-indent: 0pt;text-align: right;">}</p><p class="s19" style="text-indent: 0pt;text-align: right;">};</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s20" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">In the figure above, the<span class="s18">std::rethrow_exception</span>followed by catch of a specific exception type provides filtering of the type of exception, in this case to the only<span class="s18">sycl::exception</span><span class="p">. </span><a href="https://link.springer.com/book/10.1007/978-1-4842-5574-2" style=" color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">We can also use alternative filtering approaches in C++ or just choose to handle all exceptions regardless of the type The handler is associated with a queue or context (low-level detail covered more in</a><span class="s13">Chapter 6</span><span class="p">) </span>at construction time. For example, to register the handler defined in the figure above with a queue that we are creating, we could write<span class="s18">queue my_queue{ gpu_selector{}, handle_async_error }</span>Likewise, to register the handler defined in the figure above with a context that we are creating, we could write<span class="s18">context</span></p><p class="s18" style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">my_context{ handle_async_error }<span class="s20">Most applications do not need contexts to be explicitly created or managed (they are created behind the scenes for us automatically), so if an asynchronous handler is going to be used, most developers should associate such handlers with queues that are being constructed for specific devices (and not explicit contexts).</span></p><p class="s14" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">NOTE<span class="p">: </span><i>In defining asynchronous handlers, most developers should define them on queues unless already explicitly managing contexts for other reasons.If an asynchronous handler is not defined for a queue or the queue’s parent context and an asynchronous error occurs on that queue (or in the context) that must be processed, then the default asynchronous handler is invoked. The default handler operates as if it was coded as shown in the figure below.</i></p><p class="s20" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Example of how the default asynchronous handler behaves</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:134.6pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">// Our simple asynchronous handler function</p><p class="s19" style="padding-left: 9pt;text-indent: -10pt;text-align: left;">auto handle_async_error = [](exception_list elist) { for (auto &amp;e : elist) {</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">try{ std::rethrow_exception(e); } catch ( sycl::exception&amp; e ) {</p><p class="s19" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">// Print information about the asynchronous exception</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">// Terminate abnormally to make clear to user</p><p class="s19" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">// that something unhandled happened std::terminate();</p><p class="s19" style="text-indent: 0pt;text-align: left;">};</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p class="s20" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The default handler should display some information to the user on any errors in the exception list and then will terminate the application abnormally, which should also cause the operating system to report that termination was abnormal.What we put within an asynchronous handler is up to us. It can range from logging of an error to application termination to recovery of the error condition so that an application can continue executing normally.The common case is to report any details of the error available by calling<span class="s18">sycl::exception::what()</span><span class="p">, </span>followed by termination of the application. Although it’s up to us to decide what an asynchronous handler does internally, a common mistake is to print an error message (that may be missed in the noise of other messages from the program), followed by completion of the handler function. Unless we have error management principles in place that allow us to recover known program state and to be confident that it’s safe to continue execution, we should consider terminating the application within our asynchronous handler function(s).This reduces the chance that incorrect results will appear from a</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">program where an error was detected, but where the application was inadvertently allowed to continue with execution regardless. In many programs, abnormal termination is the preferred result once we have experienced asynchronous exceptions.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Example: SYCL Throw on Zero Sized Object</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The source code below shows how the SYCL handler will produce an error when a zero-sized object is passed.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:336.3pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#include &lt;cstdio&gt; #include &lt;CL/sycl.hpp&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">template &lt;bool non_empty&gt;</p><p class="s19" style="padding-left: 19pt;text-indent: -19pt;text-align: left;">static void fill(sycl::buffer&lt;int&gt; buf, sycl::queue &amp; q) { q.submit([&amp;](sycl::handler &amp; h) {</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">auto acc = sycl::accessor { buf, h, sycl::read_write }; h.single_task([=]() {</p><p class="s19" style="padding-left: 79pt;text-indent: -19pt;text-align: left;">if constexpr(non_empty) { acc[0] = 1;</p><p class="s19" style="padding-left: 59pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">);</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">);</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">q.wait();</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: -19pt;text-align: left;">int main(int argc, char *argv[]) { sycl::queue q;</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">sycl::buffer&lt;int, 1&gt; buf_zero ( 0 );</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">fprintf(stderr, &quot;buf_zero.count() = %zu\n&quot;, buf_zero.get_count()); fill&lt;false&gt;(buf_zero, q);</p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">fprintf(stdout, &quot;PASS\n&quot;);</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">return 0;</p><p class="s19" style="text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">When the application encounters the zero-sized object at runtime, the program aborts and produces an error message:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:89.7pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">$ dpcpp zero.cpp</p><p class="s19" style="text-indent: 0pt;text-align: left;">$ ./a.out buf_zero.count() = 0 submit...</p><p class="s19" style="text-indent: 0pt;text-align: left;">terminate called after throwing an instance of &#39;cl::sycl::invalid_object_error&#39;</p><p class="s19" style="text-indent: 9pt;text-align: left;">what(): SYCL buffer size is zero. To create a device accessor, SYCL buffer size must be greater than zero. -30 (CL_INVALID_VALUE)</p><p class="s19" style="text-indent: 0pt;text-align: left;">Aborted (core dumped)</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The programmer can then locate the programming error by catching the exception in the debugger and looking at the backtrace for the source line that triggered the error.</p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Example: SYCL Throw on Illegal Null Pointer</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Consider code that does the following:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:44.9pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">deviceQueue.memset(mdlReal, 0, mdlXYZ \* sizeof(XFLOAT));</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">deviceQueue.memcpy(mdlImag, 0, mdlXYZ \* sizeof(XFLOAT)); // coding error</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: left;">The compiler will not flag the bad (null pointer) value specified in <span class="s18">deviceQueue.memcpy</span>. This error will not be caught until runtime.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:67.3pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">terminate called after throwing an instance of &#39;cl::sycl::runtime_error&#39;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">what(): NULL pointer argument in memory copy operation. -30 (CL_INVALID_VALUE)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">Aborted (core dumped)</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The example code that follows shows a way the user can control the format of the exception output when it is detected at runtime on a given queue, implemented in a standalone program that demonstrates the null pointer error.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:426.0pt;width:486.6pt;"><p class="s19" style="text-indent: 0pt;text-align: left;">#include &quot;stdlib.h&quot; #include &quot;stdio.h&quot; #include &lt;cmath&gt; #include &lt;signal.h&gt; #include &lt;fstream&gt; #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;CL/sycl.hpp&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">#define XFLOAT float #define mdlXYZ 1000</p><p class="s19" style="text-indent: 0pt;text-align: left;">#define MEM_ALIGN 64</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;text-align: left;">int main(int argc, char *argv[])</p><p class="s19" style="text-indent: 0pt;text-align: left;">{</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">XFLOAT *mdlReal, *mdlImag;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 29pt;text-align: left;">cl::sycl::property_list propList = cl::sycl::property_list{cl::sycl::property::queue::enable_profiling()};</p><p class="s19" style="text-indent: 0pt;text-align: left;">cl::sycl::queue deviceQueue(cl::sycl::gpu_selector { }, [&amp;](cl::sycl::exception_list eL)</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">{</p><p class="s19" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">bool error = false; for (auto e : eL)</p><p class="s19" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">{</p><p class="s19" style="padding-left: 89pt;text-indent: 0pt;text-align: left;">try</p><p class="s19" style="padding-left: 89pt;text-indent: 0pt;text-align: left;">{</p><p class="s19" style="text-indent: 0pt;text-align: center;">std::rethrow_exception(e);</p><p class="s19" style="text-indent: 0pt;text-align: center;">} catch (const cl::sycl::exception&amp; e)</p><p class="s19" style="text-indent: 0pt;text-align: center;">{</p><p class="s19" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">auto clError = e.get_cl_code(); bool hascontext = e.has_context();</p><p class="s19" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; e.what() &lt;&lt; &quot;CL ERROR CODE : &quot; &lt;&lt; clError &lt;&lt; std::endl; error = true;</p><p class="s19" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">if (hascontext)</p><p class="s19" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">{</p><p class="s19" style="padding-left: 149pt;text-indent: 0pt;text-align: left;">std::cout &lt;&lt; &quot;We got a context with this exception&quot; &lt;&lt; std::endl;</p><p class="s19" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 89pt;text-indent: 0pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><div class="textbox" style="background:#F0F0F0;display:block;min-height:179.4pt;width:486.6pt;"><p class="s19" style="padding-left: 64pt;text-indent: 0pt;line-height: 10pt;text-align: left;">}</p><p class="s19" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">if (error) {</p><p class="s19" style="padding-left: 89pt;text-indent: 0pt;text-align: left;">throw std::runtime_error(&quot;SYCL errors detected&quot;);</p><p class="s19" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">}</p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">}, propList);</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">mdlReal = sycl::malloc_device&lt;XFLOAT&gt;(mdlXYZ, deviceQueue); mdlImag = sycl::malloc_device&lt;XFLOAT&gt;(mdlXYZ, deviceQueue);</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">deviceQueue.memset(mdlReal, 0, mdlXYZ * sizeof(XFLOAT)); deviceQueue.memcpy(mdlImag, 0, mdlXYZ * sizeof(XFLOAT)); // coding error</p><p class="s19" style="padding-top: 1pt;padding-left: 29pt;text-indent: 0pt;line-height: 22pt;text-align: left;">deviceQueue.wait(); exit(0);</p><p class="s19" style="text-indent: 0pt;line-height: 10pt;text-align: left;">}</p></div><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Resources</p><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/Tools/ApplicationDebugger/guided_matrix_mult_Exceptions" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">For a a guided approach to debugging SYCL exceptions from incorrect use of the SYCL* API, see the </a><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/Tools/ApplicationDebugger/guided_matrix_mult_Exceptions" class="a" target="_blank">Guided </a>Matrix Multiplication Exception Sample<span style=" color: #000;">.</span></p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/training/troubleshoot-highly-parallel-applications.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To troubleshoot your applications that use OpenMP* or the SYCL* API with extensions to offload resources, see </a>Troubleshoot Highly Parallel Applications<span style=" color: #000;">.</span></p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark73">&zwnj;</a>Optimize Offload Performance<a name="bookmark163">&zwnj;</a></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Offload performance optimization basically boils down to three tasks:</p><ol id="l105"><li data-list-text="1."><p style="padding-top: 5pt;padding-left: 30pt;text-indent: -25pt;text-align: left;">Minimize the number and size of data transfers to and from the device while maximizing execution time of the kernel on the device.</p></li><li data-list-text="2."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">When possible, overlap data transfers to/from the device with computation on the device.</p></li><li data-list-text="3."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Maximize the performance of the kernel on the device.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">While it is possible to take explicit control of data transfers in both OpenMP* offload and SYCL*, you also can allow this to happen automatically. In addition, because the host and offload device operate mostly asynchronously, even if you try to take control over data transfers, the transfers may not happen in the expected order, and may take longer than anticipated. When data used by both the device and the host is stored in unified shared memory (USM), there is another transparent layer of data transfers happening that also can affect performance.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Resources:</p><ul id="l106"><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-gpu-optimization-guide/top.html">oneAPI GPU Optimization Guide</a></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-fpga-optimization-guide/top.html" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-fpga-optimization-guide/top.html" class="s16" target="_blank">® </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-fpga-optimization-guide/top.html" target="_blank">oneAPI FPGA Optimization Guide</a></p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Buffer Transfer Time Versus Execution Time</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Transferring any data to or from an offload device is relatively expensive, requiring memory allocations in user space, system calls, and interfacing with hardware controllers. Unified shared memory (USM) adds to these costs by requiring that some background process keeps memory being modified on either the host or offload device in sync. Furthermore, kernels on the offload device must wait to run until all the input or output buffers they need to run are set up and ready to use.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">All this overhead is roughly the same no matter how much information you need to transfer to or from the offload device in a single data transfer. Thus, it is much more efficient to transfer 10 numbers in bulk rather than one at a time. Still, every data transfer is expensive, so minimizing the total number of transfers is also very important. If, for example, you have some constants that are needed by multiple kernels, or during multiple invocations of the same kernel, transfer them to the offload device once and reuse them, rather than sending them with every kernel invocation. Finally, as might be expected, single large data transfers take more time than single small data transfers.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">The number and size of buffers sent is only part of the equation. Once the data is at the offload device, consider how long the resulting kernel executes. If it runs for less time than it takes to transfer the data to the offload device, it may not be worthwhile to offload the data in the first place unless the time to do the same operation on the host is longer than the combined kernel execution and data transfer time.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Finally, consider how long the offload device is idle between the execution of one kernel and the next. A long wait could be due data transfer or just the nature of the algorithm on the host. If the former, it may be worthwhile to overlap data transfer and kernel execution, if possible.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">In short, execution of code on the host, execution of code on the offload device, and data transfer is quite complex. The order and time of such operations isn’t something you can gain through intuition, even in the simplest code. You need to make use of tools like those listed below to get a visual representation of these activities and use that information to optimize your offload code.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Intel® VTune™ Profiler</p><p class="s13" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/installation/set-up-system-for-gpu-analysis.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">In addition to giving you detailed performance information on the host, VTune can also provide detailed information about performance on a connected GPU. Setup information for GPUs is available from the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/installation/set-up-system-for-gpu-analysis.html" class="a" target="_blank">Intel </a>VTune Profiler User Guide<span style=" color: #000;">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Intel VTune Profiler’s GPU Offload view gives you an overview of the hotspots on the GPU, including the amount of time spent for data transfer to and from each kernel. The GPU Compute/Media Hotspots view allows you to dive more deeply into what is happening to your kernels on the GPU, such as by using the <b>Dynamic Instruction Count </b>to view a micro analysis of the GPU kernel performance. With these profiling modes, you can observe how data transfer and compute occur over time, determine if there is enough work for a kernel to run effectively, learn how your kernels use the GPU memory hierarchy, and so on.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/analyze-performance/accelerators-group.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Additional details about these analysis types is available from the </a>Intel VTune Profiler User Guide<a href="https://www.intel.com/content/www/us/en/developer/articles/technical/optimize-applications-for-intel-gpus-with-intel-vtune-profiler.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">. A detailed look at optimizing for GPU using VTune Profiler is available from the </a><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/optimize-applications-for-intel-gpus-with-intel-vtune-profiler.html" class="a" target="_blank">Optimize Applications for Intel GPUs with </a>Intel VTune Profiler <span style=" color: #000;">page.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">You can also use Intel VTune Profiler to capture kernel execution time. The following commands provide light- weight profiling results:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Collect</p><ul id="l107"><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 34pt;text-indent: -14pt;line-height: 118%;text-align: left;">Level zero backend: <span class="s18">vtune -collect-with runss -knob enable-gpu-level-zero=true - finalization-mode=none -app-working-dir &lt;app_working_dir&gt; &lt;app&gt;</span></p></li><li data-list-text="•"><p style="padding-left: 34pt;text-indent: -14pt;line-height: 11pt;text-align: left;">OpenCL<span class="s12">™ </span>backend: <span class="s18">vtune -collect-with runss -knob collect-programming-api=true -</span></p><p class="s18" style="padding-top: 2pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">finalization-mode=none -r &lt;result_dir_name&gt; -app-working-dir &lt;app_working_dir&gt;</p><p class="s18" style="padding-top: 2pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">&lt;app&gt;</p></li></ul></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;line-height: 118%;text-align: left;">Report: <span class="s18">vtune --report hotspots --group-by=source-computing-task --sort-desc=&quot;Total Time&quot; -r &lt;result_dir_name&gt;</span></p><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Intel® Advisor</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: left;">Intel<span class="s12">® </span>Advisor provides two features that can help you get the improved performance when offloading computation to GPU:</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Offload Modeling can watch your host OpenMP* program and recommend parts of it that would be profitably offloaded to the GPU. It also allows you to model a variety of different target GPUs, so that you can learn if offload will be profitable on some but not others. Offload Advisor gives detailed information on what factors may bound offload performance.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">GPU Roofline analysis can watch your application when it runs on the GPU, and graphically show how well each kernel is making use of the memory subsystem and compute units on the GPU. This can let you know how well your kernel is optimized for the GPU.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">To run these modes on an application that already does some offload, you need to set up your environment to use the OpenCL<span class="s12">™ </span><a href="https://www.intel.com/content/www/us/en/develop/documentation/advisor-user-guide/top/install-and-launch/set-up-environment-for-dpcpp-openmp-opencl.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">device on the CPU for analysis. Instructions are available from the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/advisor-user-guide/top/install-and-launch/set-up-environment-for-dpcpp-openmp-opencl.html" class="a" target="_blank">Intel Advisor User </a><span style=" color: #075FA7;">Guide</span>.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Offload modeling does not require that you have already modified your application to use a GPU - it can work entirely on host code.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Resources:</p></li><li data-list-text="•"><p style="padding-top: 6pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/advisor-cookbook/top/identify-code-regions-to-offload-to-gpu.html">Intel Advisor Cookbook: GPU Offload</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-advisor/top/identify-opportunities-to-offload-to-gpu.html">Get Started with Offload Modeling</a></p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-advisor/top/identify-bottlenecks-using-cpu-roofline.html">Get Started with GPU Roofline</a></p></li></ul></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Offload API Call Timelines</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">If you do not want to use Intel<span class="s12">® </span>VTune<span class="s12">™ </span>Profiler to understand when data is being copied to the GPU, and when kernels run, onetrace, ze_tracer, cl_tracer, and the Intercept Layer for OpenCL<span class="s12">™ </span><a href="#bookmark160" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">Applications give you a way to observe this information /(although, if you want a graphical timeline, you’ll need to write a script to visualize the output/). For more information, see </a><a href="#bookmark160" class="a">oneAPI Debug </a><span style=" color: #075FA7;">Tools</span><a href="#bookmark161" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">, </a><a href="#bookmark161" class="a">Trace the Offload </a><span style=" color: #075FA7;">Process</span><a href="#bookmark162" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;">, and </a><a href="#bookmark162" class="a">Debug the Offload </a><span style=" color: #075FA7;">Process</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark74">&zwnj;</a>Performance Tuning Cycle<a name="bookmark164">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The goal of the performance tuning cycle is to improve the time to solution whether that be interactive response time or elapsed time of a batch job. In the case of a heterogeneous platform, there are compute cycles available on the devices that execute independently from the host. Taking advantage of these resources offers a performance boost.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The performance tuning cycle includes the following steps detailed in the next sections:</p><ol id="l108"><li data-list-text="1."><p style="padding-top: 5pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">Establish a baseline</p></li><li data-list-text="2."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Identify kernels to offload</p></li><li data-list-text="3."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Offload the kernels</p></li><li data-list-text="4."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Optimize</p></li><li data-list-text="5."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Repeat until objectives are met</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark75">&zwnj;</a>Establish Baseline<a name="bookmark165">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Establish a baseline that includes a metric such as elapsed time, time in a compute kernel, or floating-point operations per second that can be used to measure the performance improvement and that provides a means to verify the correctness of the results.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">A simple method is to employ the chrono library routines in C++, placing timer calls before and after the workload executes.</p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark76">&zwnj;</a>Identify Kernels to Offload<a name="bookmark166">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/advisor.html#gs.etworl" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">To best utilize the compute cycles available on the devices of a heterogeneous platform, it is important to identify the tasks that are compute intensive and that can benefit from parallel execution. Consider an application that executes solely on a CPU, but there may be some tasks suitable to execute on a GPU. This can be determined using the Offload Modeling perspective of the </a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/advisor.html#gs.etworl" class="a" target="_blank">Intel</a><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/advisor.html#gs.etworl" class="s16" target="_blank">® </a>Advisor<span style=" color: #000;">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Intel Advisor estimates performance characterizations of the workload as it may execute on an accelerator. It consumes the information from profiling the workload and provides performance estimates, speedup, bottleneck characterization, and offload data transfer estimates and recommendations.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Typically, kernels with high compute, a large dataset, and limited memory transfers are best suited for offload to a device.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-advisor/top/identify-opportunities-to-offload-to-gpu.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">See </a>Get Started: Identify High-impact Opportunities to Offload to GPU <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/offload-modeling-resources-for-intel-advisor-users.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">for quick steps to ramp up with the Offload Modeling perspective. For more resources about modeling performance of your application on GPU platforms, see </a><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/offload-modeling-resources-for-intel-advisor-users.html" class="a" target="_blank">Offload Modeling Resources for Intel</a><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/offload-modeling-resources-for-intel-advisor-users.html" class="s16" target="_blank">® </a>Advisor Users<span style=" color: #000;">.</span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark77">&zwnj;</a>Offload Kernels<a name="bookmark167">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">After identifying kernels that are suitable for offload, employ SYCL* or OpenMP* to offload the kernel onto the device. Consult the previous chapters as an information resource.</p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark78">&zwnj;</a>Optimize Your SYCL* Applications<a name="bookmark168">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">oneAPI enables functional code that can execute on multiple accelerators such as CPU, GPU, and FPGA. However, the code may not be the most optimal across the accelerators. A three-step optimization strategy is recommended to meet performance needs:</p><ol id="l109"><li data-list-text="1."><p style="padding-top: 5pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">Pursue general optimizations that apply across accelerators.</p></li><li data-list-text="2."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Optimize aggressively for the prioritized accelerators.</p></li><li data-list-text="3."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Optimize the host code in conjunction with step 1 and 2.</p></li></ol><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Optimization is a process of eliminating bottlenecks, i.e., the sections of code that are taking more execution time relative to other sections of the code. These sections could be executing on the devices or the host.</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">During optimization, employ a profiling tool such as Intel<span class="s12">® </span>VTune<span class="s12">™ </span>Profiler to find these bottlenecks in the code.</p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-fpga-optimization-guide/top.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">This section discusses the first step of the strategy - Pursue general optimizations that apply across accelerators. Device specific optimizations and best practices for specific devices (step 2) and optimizations between the host and devices (step 3) are detailed in device-specific optimization guides, such as the </a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-fpga-optimization-guide/top.html" class="a" target="_blank">FPGA Optimization Guide for Intel</a><a href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-fpga-optimization-guide/top.html" class="s16" target="_blank">® </a>oneAPI Toolkits<span style=" color: #000;">. This section assumes that the kernel to offload to the accelerator is already determined. It also assumes that work will be accomplished on one accelerator. This guide does not speak to division of work between host and accelerator or between host and potentially multiple and/or different accelerators.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">General optimizations that apply across accelerators can be classified into four categories:</p><ol id="l110"><li data-list-text="1."><p style="padding-top: 5pt;padding-left: 30pt;text-indent: -24pt;text-align: left;">High-level optimizations</p></li><li data-list-text="2."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Loop-related optimizations</p></li><li data-list-text="3."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">Memory-related optimizations</p></li><li data-list-text="4."><p style="padding-left: 30pt;text-indent: -24pt;text-align: left;">SYCL-specific optimizations</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following sections summarize these optimizations only; specific details on how to code most of these optimizations can be found online or in commonly available code optimization literature. More detail is provided for the SYCL-specific optimizations.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">High-Level Optimization Tips</p><ul id="l111"><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Increase the amount of parallel work. More work than the number of processing elements is desired to help keep the processing elements more fully utilized.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Minimize the code size of kernels. This helps keep the kernels in the instruction cache of the accelerator, if the accelerator contains one.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Load balance kernels. Avoid significantly different execution times between kernels as the long-running kernels may become bottlenecks and affect the throughput of the other kernels.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Avoid expensive functions. Avoid calling functions that have high execution times as they may become bottlenecks.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Loop-Related Optimizations</p></li><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Prefer well-structured, well-formed, and simple exit condition loops – these are loops that have a single exit and a single condition when comparing against an integer bound.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Prefer loops with linear indexes and constant bounds – these are loops that employ an integer index into an array, for example, and have bounds that are known at compile-time.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Declare variables in deepest scope possible. Doing so can help reduce memory or stack usage.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Minimize or relax loop-carried data dependencies. Loop-carried dependencies can limit parallelization. Remove dependencies if possible. If not, pursue techniques to maximize the distance between the dependency and/or keep the dependency in local memory.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Unroll loops with pragma unroll.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Memory-Related Optimizations</p></li><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">When possible, favor greater computation over greater memory use. The latency and bandwidth of memory compared to computation can become a bottleneck.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">When possible, favor greater local and private memory use over global memory use.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Avoid pointer aliasing.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 110%;text-align: left;">Coalesce memory accesses. Grouping memory accesses helps limit the number of individual memory requests and increases utilization of individual cache lines.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">When possible, store variables and arrays in private memory for high-execution areas of code.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Beware of loop unrolling effects on concurrent memory accesses.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Avoid a write to a global that another kernel reads. Use a pipe instead.</p></li><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 19pt;text-indent: -14pt;line-height: 109%;text-align: left;">Consider employing the <span class="s18">[[intel::kernel_args_restrict]] </span>attribute to a kernel. The attribute allows the compiler to ignore dependencies between accessor arguments in the kernel. In turn, ignoring accessor argument dependencies allows the compiler to perform more aggressive optimizations and potentially improve the performance of the kernel.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL-Specific Optimizations</p></li><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 19pt;text-indent: -14pt;line-height: 109%;text-align: left;">When possible, specify a work-group size. The attribute, <span class="s18">[[cl::reqd_work_group_size(X, Y, Z)]]</span>, where X, Y, and Z are integer dimension in the ND-range, can be employed to set the work-group size. The compiler can take advantage of this information to optimize more aggressively.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;">Consider use of the <span class="s18">-Xsfpc </span>option when possible. This option removes intermediary floating-point rounding operations and conversions whenever possible and carries additional bits to maintain precision.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;line-height: 108%;text-align: left;">Consider use of the <span class="s18">-Xsno-accessor-aliasing </span>option. This option ignores dependencies between accessor arguments in a SYCL* kernel.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark79">&zwnj;</a>Recompile, Run, Profile, and Repeat<a name="bookmark169">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Once the code is optimized, it is important to measure the performance. The questions to be answered include:</p></li><li data-list-text="•"><p style="padding-top: 5pt;padding-left: 19pt;text-indent: -14pt;text-align: left;">Did the metric improve?</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Is the performance goal met?</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Are there any more compute cycles left that can be used?</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">Confirm the results are correct. If you are comparing numerical results, the numbers may vary depending on how the compiler optimized the code or the modifications made to the code. Are any differences acceptable? If not, go back to optimization step.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark80">&zwnj;</a>oneAPI Library Compatibility<a name="bookmark170">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">oneAPI applications may include dynamic libraries at runtime that require compatibility across release versions of Intel tools. Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/developer/articles/license/oneapi-toolkit-and-component-versioning-schema.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI Toolkits and component products use </a><span style=" color: #075FA7;">semantic versioning </span>to support compatibility.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The following policies apply to APIs and ABIs delivered with Intel oneAPI Toolkits.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p class="s14" style="padding-bottom: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">NOTE <span class="p">oneAPI applications are supported on 64-bit target devices.</span></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span/></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: justify;">New Intel oneAPI device drivers, oneAPI dynamic libraries, and oneAPI compilers will not break previously deployed applications built with oneAPI tools. Current APIs will not be removed or modified without notice and an iteration of the major version.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: justify;">Developers of oneAPI applications should ensure that the header files and libraries have the same release version. For example, an application should not use 2021.2 Intel<span class="s12">® </span>oneAPI Math Kernel Library header files with 2021.1 Intel oneAPI Math Kernel Library.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">New dynamic libraries provided with the Intel compilers will work with applications built by older versions of the compilers (this is commonly referred to as <i>backward compatibility</i>). However, the converse is not true: newer versions of the oneAPI dynamic libraries may contain routines that are not available in earlier versions of the library.</p></li><li data-list-text="•"><p style="padding-left: 19pt;text-indent: -14pt;text-align: left;">Older dynamic libraries provided with the oneAPI Intel compilers will not work with newer versions of the oneAPI compilers.</p></li></ul></li></ol><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Developers of oneAPI applications should ensure that thorough application testing is conducted to ensure that a oneAPI application is deployed with a compatible oneAPI library.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark81">&zwnj;</a>SYCL* Extensions<a name="bookmark171">&zwnj;</a></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL extensions allow developers to quickly experiment, innovate, and create new solutions. They help foster a continuous improvement cycle within open standards organizations, such as the Khronos Group, which support the development of cross-architecture systems.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">For a list of SYCL extensions supported by the Intel<span class="s12">® </span><a href="https://www.intel.com/content/www/us/en/docs/dpcpp-cpp-compiler/developer-guide-reference/2025-0/sycl-extensions.html" style=" color: black; font-family:Verdana, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">oneAPI DPC++ Compiler, refer to </a><span style=" color: #075FA7;">SYCL Extensions</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark82">&zwnj;</a>Glossary &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a name="bookmark172">&zwnj;</a></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark173">&zwnj;</a>Accelerator</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Specialized component containing compute resources that can quickly execute a subset of operations. Examples include CPU, FPGA, GPU.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">See also: Device</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Accessor</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Communicates the desired location (host, device) and mode (read, write) of access.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Application Scope</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Code that executes on the host.</p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Buffers</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Memory object that communicates the type and number of items of that type to be communicated to the device for computation.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Command Group Scope</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Code that acts as the interface between the host and device.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Command Queue</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Issues command groups concurrently.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Compute Unit</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">A grouping of processing elements into a ‘core’ that contains shared elements for use between the processing elements and with faster access than memory residing on other compute units on the device.</p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark174">&zwnj;</a>Device</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">An accelerator or specialized component containing compute resources that can quickly execute a subset of operations. A CPU can be employed as a device, but when it is, it is being employed as an accelerator.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 159%;text-align: left;">Examples include CPU, FPGA, GPU. See also: Accelerator</p><p class="s17" style="padding-top: 8pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Device Code</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Code that executes on the device rather than the host. Device code is specified via lambda expression, functor, or kernel class.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">DPC++</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">An open source project is adding SYCL* support to the LLVM C++ compiler.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Fat Binary</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Application binary that contains device code for multiple devices. The binary includes both the generic code (SPIR-V representation) and target specific executable code.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Fat Library</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Archive or library of object code that contains object code for multiple devices. The fat library includes both the generic object (SPIR-V representation) and target specific object code.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Fat Object</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">File that contains object code for multiple devices. The fat object includes both the generic object (SPIR-V representation) and target specific object code.</p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark175">&zwnj;</a>Host</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">A CPU-based system (computer) that executes the primary portion of a program, specifically the application scope and command group scope.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Host Code</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Code that is compiled by the host compiler and executes on the host rather than the device.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Images</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Formatted opaque memory object that is accessed via built-in function. Typically pertains to pictures comprised of pixels stored in format like RGB.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Kernel Scope</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Code that executes on the device.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">ND-Range</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Short for N-Dimensional Range, a group of kernel instances, or work item, across one, two, or three dimensions.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Processing Element</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Individual engine for computation that makes up a compute unit.</p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark176">&zwnj;</a>Single Source</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Code in the same file that can execute on a host and accelerator(s).</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">SPIR-V</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Binary intermediate language for representing graphical-shader stages and compute kernels.</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">SYCL</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">A standard for a cross-platform abstraction layer that enables code for heterogeneous processors to be written using standard ISO C++ with the host and kernel code for an application contained in the same source file.</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Work-Groups</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Collection of work-items that execute on a compute unit.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s17" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Work-Item</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">Basic unit of computation in the oneAPI programming model. It is associated with a kernel which executes on the processing element.</p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark83">&zwnj;</a>Notices &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; and &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Disclaimers &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a name="bookmark177">&zwnj;</a></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Intel technologies may require enabled hardware, software or service activation.</p><p style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 148%;text-align: left;">No product or component can be absolutely secure. Your costs and results may vary.</p><p class="s12" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">© <span class="p">Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.</span></p><p class="s25" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Product and Performance Information</p><div class="textbox" style="border:1.0pt solid #000000;display:block;min-height:47.2pt;width:498.6pt;"><p class="s28" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a href="http://www.Intel.com/" class="s47" target="_blank">Performance varies by use, configuration and other factors. Learn more at </a>www.Intel.com/ PerformanceIndex.</p><p class="s28" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Notice revision #20201201</p></div><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Unless stated otherwise, the code examples in this document are provided to you under an MIT license, the terms of which are as follows:</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Copyright Intel Corporation</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p></body></html>
